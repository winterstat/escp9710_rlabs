[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESCP 9710 R Labs",
    "section": "",
    "text": "Preface\nWelcome to the R Labs page for ESCP 9710: Structural Equation Modeling. Although these labs were created for use in a classroom setting, they are available to all who happen to find them and find use in them. Please don’t hesitate to let me know about any bugs or errors you notice, by contacting me at sdwinter@missouri.edu"
  },
  {
    "objectID": "gettingstarted.html#installing-new-software",
    "href": "gettingstarted.html#installing-new-software",
    "title": "1  Getting Started",
    "section": "1.1 Installing New Software",
    "text": "1.1 Installing New Software\nAs the title of this page suggests, all labs will be done using R (and RStudio). To use these programs, you’ll need to install both R and RStudio. Follow the instructions below to install them.\n\nStep 1: Install R\nR is a programming language and computing environment specialized for statistical analysis and data manipulation. It’s commonly used for performing statistical tests, creating data visualizations, and writing data analysis reports.\n\nInstalling R for Windows Computers\nGo to https://cloud.r-project.org/bin/windows/base/ and click the link titled Download R-4.3.2 for Windows (note: the version number might be different, but the remainder of the link will be the same). This will download the R Installer into your Downloads folder, where you can double click on it and follow the prompts on the screen to finish installing R. You can accepts all default settings.\n\n\nInstalling R for Mac Computers\nYou will need to figure out if you have an Intel Processor or an Apple M Processor. You can do so by clicking on the Apple icon in the top-left corner of your screen and clicking on About this Mac. The window that will pop up will show you an overview of your computer, including the processor/chip used.\nOnce you know what processor your computer has, go to https://cloud.r-project.org/bin/macosx/, and:\n\nIf your computer has an Intel Processor, click on the file titled R-4.3.2-x86_64.pkg\nIf your computer has an Apple M Processor, click on the file titled R-4.3.2-arm64.pkg\n\nNote: the version number might be different, but the remainder of the link will be the same. This will download the R Installer into your Downloads folder, where you can double click on it and follow the prompts on the screen to finish installing R. You can accepts all default settings.\n\n\nInstalling R for Linux Computers\nIf you are using a Linux-based operating system, use your system’s package manager to install R. For example, here are the instructions for installing R on Ubuntu.\n\n\n\n\n\n\nNote\n\n\n\nR cannot be installed on Chromebooks, so you’ll need to use the computers available in the classroom/computer labs.\n\n\n\n\n\nStep 2: Install RStudio\nRStudio is an integrated development environment (IDE) for reproducible scientific computing that is developed for the R programming language. An IDE is basically a nicer-looking user interface that can be customized to suit the preferences of the user. This is the actual program that we will use in class!\n\nDownload the latest, free version of RStudio Desktop. Be sure to get the version that is appropriate for your operating system.\nInstall RStudio Desktop by launching the installer after it downloads. You can accept all the defaults during installation.\n\n\n\n\n\n\n\nTip\n\n\n\nFor more detailed instructions for downloading and installing R and RStudio, you can watch this video tutorial on YouTube. To learn about (or review) R basics, you can skim this (free!) book by Navarro (2015): Learning Statistics with R. There is also the SWIRL Interactive R Tutorial that lets you learn about the basics of R while using R."
  },
  {
    "objectID": "gettingstarted.html#install-necessary-packages",
    "href": "gettingstarted.html#install-necessary-packages",
    "title": "1  Getting Started",
    "section": "1.2 Install Necessary Packages",
    "text": "1.2 Install Necessary Packages\nThroughout these labs, we will rely on a set of R packages, which add functionality to the base R language (like expansion sets of a game). These packages are typically available through CRAN or GitHub. You only need to install packages once (but you may need to update them!), so lets do that now.\nWe will start with a set of packages that we can download from CRAN, using the built-in install.packages function:\n\ninstall.packages(c(\"rio\", \"tidyverse\", \"GGally\", \n                   \"lavaan\", \"semhelpinghands\", \"semPlot\", \"modsem\",\n                   \"semTools\", \"tidySEM\", \"ggdist\"))\n\nRunning the code above will install:\n\nrio: makes importing lots of different data file types easy.\ntidyverse: installs 8 packages that help with data management and visualization.\nGGally: for easy bivariate visualization.\nlavaan: the main structural equation modeling package we will use.\nsemhelpinghands: a collection of functions that makes it easier to examine output from lavaan.\nsemPlot: a package that helps you draw model diagrams.\nmodsem: a package that allows you to easily include interaction effects in SEMs.\nsemTools: a package with functions that extend the utility of lavaan.\ntidySEM: a package that allows you to estimate mixture models\nggdist: an extension of ggplot2 for plotting distributions.\n\nIn addition to these main packages, R might also install additional packages that are needed for these 10 packages to work (so-called dependents). It might take a while!"
  },
  {
    "objectID": "gettingstarted.html#data-used-in-the-r-labs",
    "href": "gettingstarted.html#data-used-in-the-r-labs",
    "title": "1  Getting Started",
    "section": "1.3 Data Used in the R Labs",
    "text": "1.3 Data Used in the R Labs\nSeveral of the R Labs require you to download data files to use for the analyses. Links to these data files are included within each lab, accompanied by an explanation and citation.\nYou are now ready to continue to the second R Lab, where you will learn how to specify, identify, estimate, and interpret a path analysis."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "pathanalysis.html#loading-r-packages",
    "href": "pathanalysis.html#loading-r-packages",
    "title": "2  Path Analysis",
    "section": "2.1 Loading R Packages",
    "text": "2.1 Loading R Packages\nIf you want to use the functionality of a package, you will need to “load” the package into your environment. To do that, we use the library function:\n\nlibrary(rio)\nlibrary(lavaan)\nlibrary(ggplot2)\nlibrary(semPlot)\nlibrary(modsem)"
  },
  {
    "objectID": "pathanalysis.html#loading-data",
    "href": "pathanalysis.html#loading-data",
    "title": "2  Path Analysis",
    "section": "2.2 Loading Data",
    "text": "2.2 Loading Data\nYou can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/meece.csv. Make sure to save it in the folder you are using for this class.\nTypically, you will import some data file into your R environment for further analysis. There are many ways of doing this. I will show you two:\n\nYou can use a point-and-click approach by clicking the Import Dataset button in the right-top window.\nYou can use a function (the one we use is from the rio package).\n\n\nmeece &lt;- import(file = \"data/meece.csv\")\n\nThe function above will attempt to import the file meece.csv from a folder called data, which is located inside your working directory.\nSometimes, running the code above doesn’t work because R thinks you want to import the data from the wrong folder (which R calls the working directory). We can check what the working directory is:\n\ngetwd()\n\nIf the result of this function is not the folder containing your data file, then you can change the working directory in two ways:\n\nUse a point-and-click approach by moving your cursor to the bottom-right window to navigate to the correct folder (in the Files tab).\nUse the following R function to change the working directory:\n\n\n# Mac OS:\nsetwd(\"~/Dropbox/Work/Teaching/Measurement/R Labs\") \n\n# Windows:\nsetwd(\"C:/Users/sonja/Dropbox/Work/Teaching/Measurement/R Labs\") \n\n# Note: the folder that you are using for this class will very \n# likely be in a different location. \n\nTypically, R/RStudio will set the working directory to the folder containing the R file you open. If you start RStudio by itself (instead of opening a file), then the working directory will typically be set to your home folder."
  },
  {
    "objectID": "pathanalysis.html#model-specification-and-identification",
    "href": "pathanalysis.html#model-specification-and-identification",
    "title": "2  Path Analysis",
    "section": "2.3 Model Specification and Identification",
    "text": "2.3 Model Specification and Identification\nNow we can focus on the topic of this module: Path Analysis. We will start by specifying the model that Meece and colleagues specified in their paper. When using lavaan, you need to write out your model as a character string. When specifying a model this way, you can use ~ to mean a one-directional arrow/regression path, and ~~ to mean a bidirectional arrow/covariance.\n\nmod1 &lt;- '\nActiveEn ~ TaskMast \nActiveEn ~ EgoSoc \nActiveEn ~ IntMot\n\nEgoSoc ~ TaskMast \nEgoSoc ~ SciAtt \nEgoSoc ~ IntMot\n\nTaskMast ~ SciAtt \nTaskMast ~ IntMot\n\nSciAtt ~~ IntMot'\n\nThe above model can be written more efficiently by combining all predictors of an endogenous variable in one line with +.\n\nmod1 &lt;- '\nActiveEn ~ TaskMast + EgoSoc + IntMot\n\nEgoSoc ~ TaskMast + SciAtt + IntMot\nTaskMast ~ SciAtt + IntMot\n\nSciAtt ~~ IntMot'\n\nTo ensure that the model is identified, we can figure out the number of known pieces of information (variances and covariances) and compare those to the number of unknown pieces of information. There are five variables in this model, so we can use that to compute the number of known pieces of information:\n\n(5 *(5 + 1)) / 2\n\n[1] 15\n\n\nAs we already figured out in class: there are 15 known pieces of information. The model syntax above can help us figure out the number of unknown regression paths and covariances by counting the number of variables on the right side of the ~ (8) and the number of times we see ~~ (1). Next, each exogenous variable has a variance (2), and each endogenous variable has a residual variance (3). Together, these are 14 unknowns. Thus, this model is over-identified!"
  },
  {
    "objectID": "pathanalysis.html#data-exploration",
    "href": "pathanalysis.html#data-exploration",
    "title": "2  Path Analysis",
    "section": "2.4 Data Exploration",
    "text": "2.4 Data Exploration\nBefore analyzing the data, we can check and make sure that the covariance matrix can be inverted, or if the determinant is zero, preventing us from estimating any model.\n\n# Correlation matrix to get first look at magnitude of associations\ncor(meece)\n\n         IntMot SciAtt TaskMast EgoSoc ActiveEn\nIntMot     1.00   0.56     0.46  -0.20     0.37\nSciAtt     0.56   1.00     0.48  -0.14     0.31\nTaskMast   0.46   0.48     1.00   0.13     0.70\nEgoSoc    -0.20  -0.14     0.13   1.00     0.21\nActiveEn   0.37   0.31     0.70   0.21     1.00\n\n# Find the determinant of the covariance matrix\ndet(cov(meece))\n\n[1] 0.0003633127\n\n# Find the inverse of the covariance matrix\nsolve(cov(meece))\n\n             IntMot     SciAtt   TaskMast     EgoSoc   ActiveEn\nIntMot    5.7667640 -2.0054135 -1.1987449  0.8426144 -1.4368836\nSciAtt   -2.0054135  4.3893196 -1.9705019  0.3240856  0.5191613\nTaskMast -1.1987449 -1.9705019 10.3083634 -0.4772837 -7.9323051\nEgoSoc    0.8426144  0.3240856 -0.4772837  2.0871669 -1.1371441\nActiveEn -1.4368836  0.5191613 -7.9323051 -1.1371441 16.8297529\n\n\nLooks like there are no issues with linear dependence, indicating that each variable adds to the generalized variance present in the data!"
  },
  {
    "objectID": "pathanalysis.html#model-estimation",
    "href": "pathanalysis.html#model-estimation",
    "title": "2  Path Analysis",
    "section": "2.5 Model Estimation",
    "text": "2.5 Model Estimation\nEstimating a path model with lavaan is super simple using the sem() function. You need to specify where the model and data can be found and save the results of running the function into another object (fit1):\n\nfit1 &lt;- sem(model = mod1, data = meece)\n\nNow that we’ve estimated the model, we can use the semPlot package to visualize the model in a diagram, which can help us check if we actually estimated the model we wanted to estimate. In the function below, rotation = 2 ensures that the exogenous variables are on the left side of the plot. This function has MANY options to help customize the diagram (try ?semPaths to look at the help page).\n\nsemPaths(fit1, rotation = 2)\n\n\n\n\nAlthough this function (and similar ones from other packages) can be helpful, they take a lot of time to make them look publication-ready. So, I typically use PowerPoint to make pretty diagrams (just like the creator of the semPlot package does!)."
  },
  {
    "objectID": "pathanalysis.html#model-evaluation",
    "href": "pathanalysis.html#model-evaluation",
    "title": "2  Path Analysis",
    "section": "2.6 Model Evaluation",
    "text": "2.6 Model Evaluation\nWe will learn about model fit evaluation during a later week. For now, we can examine how similar the observed and model-implied covariance matrix are (or are not).\n\n# The observed covariance matrix\nobs_cov &lt;- round(cov(meece[,c(5,4,3,1,2)]), digits = 3)\n\n# The model-implied covariance matrix\nimp_cov &lt;- lavInspect(fit1, what = \"implied\")[[1]]\n\nobs_cov\n\n         ActiveEn EgoSoc TaskMast IntMot SciAtt\nActiveEn    0.122  0.055    0.118  0.070  0.066\nEgoSoc      0.055  0.563    0.047 -0.081 -0.064\nTaskMast    0.118  0.047    0.230  0.119  0.141\nIntMot      0.070 -0.081    0.119  0.292  0.184\nSciAtt      0.066 -0.064    0.141  0.184  0.372\n\nimp_cov\n\n         ActvEn EgoSoc TskMst IntMot SciAtt\nActiveEn  0.122                            \nEgoSoc    0.055  0.560                     \nTaskMast  0.117  0.047  0.230              \nIntMot    0.070 -0.081  0.119  0.290       \nSciAtt    0.073 -0.064  0.140  0.184  0.371\n\n# The difference between observed and implied gives an indication \n# of what parts of the data are well-represented in the model\nobs_cov - imp_cov\n\n         ActvEn EgoSoc TskMst IntMot SciAtt\nActiveEn  0.000                            \nEgoSoc    0.000  0.003                     \nTaskMast  0.001  0.000  0.000              \nIntMot    0.000  0.000  0.000  0.002       \nSciAtt   -0.007  0.000  0.001  0.000  0.001\n\n\nIt can be challenging to interpret covariances, so we can do something similar but using the correlation matrices instead.\n\n# The observed correlation matrix\nobs_cor &lt;- round(cor(meece[,c(5,4,3,1,2)]), digits = 3)\n\n# The model-implied correlation matrix\nimp_cor &lt;- lavInspect(fit1, what = \"cor.ov\")\n\nobs_cor\n\n         ActiveEn EgoSoc TaskMast IntMot SciAtt\nActiveEn     1.00   0.21     0.70   0.37   0.31\nEgoSoc       0.21   1.00     0.13  -0.20  -0.14\nTaskMast     0.70   0.13     1.00   0.46   0.48\nIntMot       0.37  -0.20     0.46   1.00   0.56\nSciAtt       0.31  -0.14     0.48   0.56   1.00\n\nimp_cor\n\n         ActvEn EgoSoc TskMst IntMot SciAtt\nActiveEn  1.000                            \nEgoSoc    0.210  1.000                     \nTaskMast  0.700  0.130  1.000              \nIntMot    0.370 -0.200  0.460  1.000       \nSciAtt    0.343 -0.140  0.480  0.560  1.000\n\n# The difference between observed and implied gives an indication of \n# what parts of the data are well-represented in the model\nobs_cor - imp_cor\n\n         ActvEn EgoSoc TskMst IntMot SciAtt\nActiveEn  0.000                            \nEgoSoc    0.000  0.000                     \nTaskMast  0.000  0.000  0.000              \nIntMot    0.000  0.000  0.000  0.000       \nSciAtt   -0.033  0.000  0.000  0.000  0.000\n\n\nFor which pair of variables is the difference between the observed and model-implied correlation largest? What does that indicate about the model we specified?"
  },
  {
    "objectID": "pathanalysis.html#parameter-interpretation",
    "href": "pathanalysis.html#parameter-interpretation",
    "title": "2  Path Analysis",
    "section": "2.7 Parameter Interpretation",
    "text": "2.7 Parameter Interpretation\nTo examine the parameter estimates, we can use the summary function. The std = TRUE option is included so we also get standardized estimates.\n\nsummary(fit1, std = TRUE)\n\nlavaan 0.6-19 ended normally after 16 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                           256\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.936\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.333\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  ActiveEn ~                                                            \n    TaskMast          0.459    0.037   12.397    0.000    0.459    0.630\n    EgoSoc            0.070    0.021    3.263    0.001    0.070    0.150\n    IntMot            0.072    0.033    2.147    0.032    0.072    0.110\n  EgoSoc ~                                                              \n    TaskMast          0.504    0.109    4.645    0.000    0.504    0.323\n    SciAtt           -0.179    0.092   -1.952    0.051   -0.179   -0.145\n    IntMot           -0.371    0.102   -3.631    0.000   -0.371   -0.267\n  TaskMast ~                                                            \n    SciAtt            0.255    0.050    5.075    0.000    0.255    0.324\n    IntMot            0.248    0.057    4.363    0.000    0.248    0.279\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  IntMot ~~                                                             \n    SciAtt            0.184    0.024    7.818    0.000    0.184    0.560\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .ActiveEn          0.059    0.005   11.314    0.000    0.059    0.487\n   .EgoSoc            0.495    0.044   11.314    0.000    0.495    0.884\n   .TaskMast          0.164    0.015   11.314    0.000    0.164    0.716\n    IntMot            0.290    0.026   11.314    0.000    0.290    1.000\n    SciAtt            0.371    0.033   11.314    0.000    0.371    1.000\n\n\nGuidelines recommend you report both unstandardized and standardized estimates with standard errors. To get standardized estimates with standard errors (which are not included in the summary above), you can use the following function.\n\nstandardizedSolution(fit1, type = \"std.all\")\n\n        lhs op      rhs est.std    se      z pvalue ci.lower ci.upper\n1  ActiveEn  ~ TaskMast   0.630 0.043 14.593  0.000    0.545    0.714\n2  ActiveEn  ~   EgoSoc   0.150 0.046  3.265  0.001    0.060    0.240\n3  ActiveEn  ~   IntMot   0.110 0.051  2.150  0.032    0.010    0.211\n4    EgoSoc  ~ TaskMast   0.323 0.067  4.807  0.000    0.191    0.454\n5    EgoSoc  ~   SciAtt  -0.145 0.074 -1.964  0.050   -0.290    0.000\n6    EgoSoc  ~   IntMot  -0.267 0.072 -3.709  0.000   -0.408   -0.126\n7  TaskMast  ~   SciAtt   0.324 0.062  5.253  0.000    0.203    0.445\n8  TaskMast  ~   IntMot   0.279 0.062  4.471  0.000    0.156    0.401\n9    IntMot ~~   SciAtt   0.560 0.043 13.054  0.000    0.476    0.644\n10 ActiveEn ~~ ActiveEn   0.487 0.044 11.168  0.000    0.401    0.572\n11   EgoSoc ~~   EgoSoc   0.884 0.038 23.521  0.000    0.811    0.958\n12 TaskMast ~~ TaskMast   0.716 0.048 15.021  0.000    0.623    0.810\n13   IntMot ~~   IntMot   1.000 0.000     NA     NA    1.000    1.000\n14   SciAtt ~~   SciAtt   1.000 0.000     NA     NA    1.000    1.000\n\n\nLooking at the estimates above, what is the strongest effect? What is the weakest effect? Are there any negative effects? What about the association between the two exogenous variables? Which estimates helped you most when thinking about these questions?"
  },
  {
    "objectID": "pathanalysis.html#exercise-respecify-the-model-and-evaluate-the-fit-of-said-model",
    "href": "pathanalysis.html#exercise-respecify-the-model-and-evaluate-the-fit-of-said-model",
    "title": "2  Path Analysis",
    "section": "2.8 Exercise: Respecify the model and evaluate the fit of said model",
    "text": "2.8 Exercise: Respecify the model and evaluate the fit of said model\nUse the code below to specify and estimate a second model. You can modify the model above, or start from scratch and come up with a whole new model (maybe the one you drew during Week 1 of the semester).\n\nmod2 &lt;- '\n\n'\n\nfit2 &lt;- sem(model = mod2, data = meece)\n\nsummary(fit2, std = TRUE)"
  },
  {
    "objectID": "pathanalysis.html#including-interaction-effects",
    "href": "pathanalysis.html#including-interaction-effects",
    "title": "2  Path Analysis",
    "section": "2.9 Including Interaction Effects",
    "text": "2.9 Including Interaction Effects\nWe will now use the meece data to practice including an interaction effect in our path analysis model. Lets say we are interested in a simple model, in which Ego-Social Goal Orientation and Intrinsic Motivation both predict Active Cognitive Engagement. In addition, we’re interested in understanding to what extent Intrinsic Motivation moderates the association between Ego-Social Goals and Active Engagement.\nWhen estimating a linear regression in R, you can include an interaction effect quite easily:\n\nfit_lm &lt;- lm(ActiveEn ~ EgoSoc + IntMot + EgoSoc*IntMot, \n             data = meece)\nsummary(fit_lm)\n\n\nCall:\nlm(formula = ActiveEn ~ EgoSoc + IntMot + EgoSoc * IntMot, data = meece)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.80566 -0.21744  0.00282  0.20297  0.97698 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.47313    0.33727   1.403  0.16189    \nEgoSoc         0.39341    0.12398   3.173  0.00169 ** \nIntMot         0.50620    0.11418   4.433 1.39e-05 ***\nEgoSoc:IntMot -0.09037    0.04288  -2.107  0.03607 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3081 on 252 degrees of freedom\nMultiple R-squared:  0.2344,    Adjusted R-squared:  0.2253 \nF-statistic: 25.72 on 3 and 252 DF,  p-value: 1.506e-14\n\n\nIn most SEM software programs, you cannot include an interaction effect in this way. The lavaan syntax below will run, but simply assigns EgoSoc as a label to the regression path for IntMot. You’ll see that running the code below results in a linear regression model with two predictors, but no interaction effect.\n\nmod3 &lt;- '\nActiveEn ~ EgoSoc + IntMot + EgoSoc*IntMot\n'\n\nfit3 &lt;- sem(model = mod3, data = meece)\nsummary(fit3)\n\nInstead, we need to use a supporting R package, modsem, which can help you estimate interaction effects between observed (and latent) variables. It does so by introducing a new operator (:), which can be used like * in the lm() function. We have to use the modsem function and specify a method for how to compute the interaction effect (alternative methods can be used when estimating a latent variable interaction effect):\n\nmod3 &lt;- '\nActiveEn ~ EgoSoc + IntMot + EgoSoc:IntMot\n'\n\nfit3 &lt;- modsem(model = mod3, data = meece, method = \"pind\")\nsummary(fit3, std = TRUE)\n\nmodsem (version 1.0.5, approach = pind):\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         4\n\n  Number of observations                           256\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  ActiveEn ~                                                            \n    EgoSoc            0.393    0.123    3.198    0.001    0.393    0.843\n    IntMot            0.506    0.113    4.468    0.000    0.506    0.781\n    EgoSocIntMot     -0.090    0.043   -2.124    0.034   -0.090   -0.600\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .ActiveEn          0.093    0.008   11.314    0.000    0.093    0.766\n\n\nWhen we have two continuous predictors, we can interpret their interaction effect as follows:\n\nThe interaction regression coefficient represents the effect of a one-unit change in Intrinsic Motivation on the association between Ego-Social Goal Orientation and our outcome Active Cognitive Engagement.\n\nIt is often easier to interpret this kind of interaction by plotting the relationship between a predictor and outcome at different levels of the second predictor (or moderator). Typical levels are the mean of the moderator and one standard deviation above/below that mean. We can use functions from the modsem package.\n\n# Set up the values at which we want to probe the impact of \n# Task Mastery Goals:\n# First we compute the value that is one SD below the mean, then \n# the mean, and finally the value that is one SD above the mean\nsimple_slope_values &lt;- c(mean(meece$IntMot) - sd(meece$IntMot),\n                   mean(meece$IntMot),\n                   mean(meece$IntMot) + sd(meece$IntMot))\n\n# Round to 2 decimals for readability\nsimple_slope_values &lt;- round(simple_slope_values, 2)\n\nplot_interaction(\"EgoSoc\", \"IntMot\", \"ActiveEn\", \"EgoSocIntMot\", vals_z = simple_slope_values, \n                 model = fit3)\n\n\n\n\nNote that the modsem plot functions use mean-centering for plotting whatever is shown on the x-axis. Thus, in the plot above, a value of 0 on EgoSoc represents the mean of EgoSoc (which is 2.48).\nThe simple slopes plot above shows that the association between Ego-Social Goal Orientation and Active Engagement decreases for those with higher levels of Intrinsic Motivation (blue line). We can test at what level of Intrinsic Motivation the association between Ego-Social Goals and Active Engagement stops being significant by computing and plotting Johnson-Neyman regions. The max_z argument determines the maximum value shown on the x-axis. Remember that the x-axis is mean-centered, so here, the maximum value is six points above the mean.\n\nplot_jn(x = \"EgoSoc\", z = \"IntMot\", y = \"ActiveEn\", model = fit3, max_z = 6)\n\n\n\n\nThe plot above shows that the association between Ego-Social Goals and Active Engagement stops being significant when Intrinsic Motivation is 3.51 points above the average. The horizontal black line represents the distribution of values for Intrinsic Motivation. The thicker part of the black line covers values within 2 standard deviations from the average Intrinsic Motivation score. Any values beyond this region have a very low probability and are unlikely to be observed in the population. Thus, we can conclude that the effect of Ego-Social Goals on Active Engagement is significant across all typical levels of Intrinsic Motivation (perhaps indicating that the moderation effect is quite small).\nYou can use a similar approach to estimate interaction effects between dichotomous (yes/no) variables or a mix of dichotomous and continuous predictors. Interaction effects can also be combined with indirect effects and larger path models. We will revisit interaction effects in a bonus section of the SEM R Lab, to see how we can use this package to estimate latent variable interaction effects."
  },
  {
    "objectID": "pathanalysis.html#summary",
    "href": "pathanalysis.html#summary",
    "title": "2  Path Analysis",
    "section": "2.10 Summary",
    "text": "2.10 Summary\nIn this R lab, you were introduced to the steps involved in specifying, estimating, and interpreting the results of a path model, an important quantitative method that can help us understand the associations among many variables. As you may have noticed, the model that Meece and colleagues specified included several indirect effects. How you can specify and evaluate the significance of those indirect effects will be the focus of the next R Lab."
  },
  {
    "objectID": "indirecteffects.html",
    "href": "indirecteffects.html",
    "title": "3  Path Analysis",
    "section": "",
    "text": "4 Model Specification\nNext, we will specify the same model as we did in the previous lab, which aligned with the model tested by the authors. This time, we will add the code necessary to compute the indirect and total effects present in the model. To do so, we need to give each path in the model a label that we can use to define the indirect and total effects. We can do that by using the * symbol. For example, in the code below b1*TaskMast labels the path from Task Mastery to Active Engagement as b1. In indirect effects, it is customary to label paths from the predictor to the mediator with a, paths from the mediator to the outcome with b, and paths from the predictor to the outcome with c.\nmod1 &lt;- '\nActiveEn ~ b1*TaskMast + b2*EgoSoc + c1*IntMot\n\nTaskMast ~ a1*SciAtt + a2*IntMot\nEgoSoc ~ a3*SciAtt + a4*IntMot + b3*TaskMast\n\n\nSciAtt ~~ IntMot\n\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind := a2*b1\nim.tm.es.ind := a2*b3*b2\nim.es.ind := a4*b2\nim.total.ind := (a2*b1) + (a2*b3*b2) + (a4*b2) \nim.total := (a2*b1) + (a2*b3*b2) + (a4*b2) + c1\n\n# indirect effects between SciAtt &gt; AciveEn\nsa.tm.ind := a1*b1\nsa.tm.es.ind := a1*b3*b2\nsa.es.ind := a3*b2\nsa.total.ind := (a1*b1) + (a1*b3*b2) + (a3*b2)\n'\nOnce we have labeled all the paths, we can use the labels to specify the indirect and total (indirect) effects. Since these are parameters that we estimate after the direct effects have already been estimated, we need to give each new parameter a name. It helps if these names make sense to you. For example, in the code above, the parameter im.tm.ind refers to the indirect effect (ind) from IntMot (im) via TaskMast (tm).\nTo get the total indirect effect, you can simply add all the specific indirect effects together. If there is a direct effect from the main predictor to the main outcome, then we can also compute the total effect, by adding the direct effect (here c1) to the total indirect effects.\nWhy is there no total effect for the connection between SciAtt &gt; ActiveEn?\nYou can also see that some indirect effects are made up of more than two paths. This is the case with the paths that include the directed effect from Task Mastery to Ego Social goals (e.g., im.tm.es.ind := a2*b3*b2)."
  },
  {
    "objectID": "indirecteffects.html#loading-r-packages",
    "href": "indirecteffects.html#loading-r-packages",
    "title": "3  Indirect Effects",
    "section": "3.1 Loading R Packages",
    "text": "3.1 Loading R Packages\nIf you want to use the functionality of a package, you will need to “load” the package into your environment. To do that, we use the library function:\n\nlibrary(rio)\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(ggplot2)\nlibrary(GGally)"
  },
  {
    "objectID": "indirecteffects.html#loading-data-into-our-environment",
    "href": "indirecteffects.html#loading-data-into-our-environment",
    "title": "3  Indirect Effects",
    "section": "3.2 Loading data into our environment",
    "text": "3.2 Loading data into our environment\nLoad the data into your environment. We will use the same data we’ve used in the previous Lab:\n\nmeece &lt;- import(file = \"data/meece.csv\")"
  },
  {
    "objectID": "indirecteffects.html#data-exploration",
    "href": "indirecteffects.html#data-exploration",
    "title": "3  Indirect Effects",
    "section": "3.3 Data Exploration",
    "text": "3.3 Data Exploration\nBefore analyzing the data, we can look at the distribution of the variables to see if they follow a normal distribution (one of the main assumptions of the ML estimator that lavaan uses by default).\n\nggpairs(meece, progress = FALSE, diag = list(continuous = \"barDiag\"))\n\n\n\n\nThis plot shows several things: on the diagonal, the univariate distribution of the variables (here using a histogram), in the lower triangle, we see scatter plots of pairs of variables, which appear to indicate that the relationships between variables are approximately linear. In the upper triangle, we see the actual Pearson correlation coefficient with significance information.\nDo the histograms look “normal” enough? What can we do if there are issues with normality?\nPackage semTools includes a set of functions to evaluate the skew and kurtosis of observed variables:\n\n# Univariate skew and kurtosis\napply(meece, 2, skew)\n\n              IntMot     SciAtt   TaskMast     EgoSoc   ActiveEn\nskew (g1) -0.1212397 -0.1038950 -0.1987473 0.08361646 -0.2038482\nse         0.1530931  0.1530931  0.1530931 0.15309311  0.1530931\nz         -0.7919347 -0.6786394 -1.2982121 0.54618045 -1.3315306\np          0.4283988  0.4973664  0.1942145 0.58494190  0.1830145\n\napply(meece, 2, kurtosis)\n\n                    IntMot     SciAtt  TaskMast     EgoSoc   ActiveEn\nExcess Kur (g2) -0.2634421 0.04668221 0.1033383 -0.3550750 0.57178812\nse               0.3061862 0.30618622 0.3061862  0.3061862 0.30618622\nz               -0.8603982 0.15246347 0.3375015 -1.1596702 1.86745217\np                0.3895696 0.87882140 0.7357388  0.2461831 0.06183847\n\n# Multivariate skew and kurtosis\nmardiaSkew(meece)\n\n       b1d        chi         df          p \n 0.7426468 31.6862628 35.0000000  0.6288746 \n\nmardiaKurtosis(meece)\n\n       b2d          z          p \n34.1571166 -0.8059507  0.4202713"
  },
  {
    "objectID": "indirecteffects.html#model-estimation",
    "href": "indirecteffects.html#model-estimation",
    "title": "3  Indirect Effects",
    "section": "3.5 Model Estimation",
    "text": "3.5 Model Estimation\nEstimating a path model in R is super simple! However, when we have indirect effects, we typically use bootstrapped standard errors (because multiplying two parameters by each other results in a distribution that is not Normally distributed and would result in making more Type I errors if we test significance). Typically, you would request at least 1000 bootstrap samples, but in the interest of saving time, we will use just 100 in this Lab. To make sure we’re all getting the same results, we will also specify a seed (iseed), which ensures that the bootstrap samples are reproducible.\n\nfit1 &lt;- sem(model = mod1, data = meece,\n            se = \"bootstrap\", bootstrap = 100,\n            iseed = 8789)"
  },
  {
    "objectID": "indirecteffects.html#parameter-interpretation",
    "href": "indirecteffects.html#parameter-interpretation",
    "title": "3  Indirect Effects",
    "section": "3.6 Parameter Interpretation",
    "text": "3.6 Parameter Interpretation\nWe will skip over the evaluation step for today and focus on the interpretation of the results.\nTo examine the parameter estimates when we rely on bootstrapping, we can use the parameterEstimates() function. Bootstrapped confidence intervals can be created in different ways, but the current best standard is to use bias-corrected percentiles (bca.simple). With the arguments below, we tell the function the hide the z statistic (zstat = FALSE) and p-value (pvalue = FALSE), because those are still based on the classic Normality assumption. In addition, we can ask that the output be shown as text, which will put the estimates in the classic lavaan summary format (easier to read):\n\nparameterEstimates(fit1, boot.ci.type = \"bca.simple\", \n                   ci = TRUE, se = TRUE, \n                   zstat = FALSE, pvalue = FALSE,\n                   output = \"text\")\n\n\nRegressions:\n                   Estimate  Std.Err ci.lower ci.upper\n  ActiveEn ~                                          \n    TaskMast  (b1)    0.459    0.036    0.370    0.523\n    EgoSoc    (b2)    0.070    0.023    0.013    0.113\n    IntMot    (c1)    0.072    0.032    0.022    0.157\n  TaskMast ~                                          \n    SciAtt    (a1)    0.255    0.054    0.157    0.384\n    IntMot    (a2)    0.248    0.063    0.157    0.414\n  EgoSoc ~                                            \n    SciAtt    (a3)   -0.179    0.091   -0.374    0.015\n    IntMot    (a4)   -0.371    0.100   -0.569   -0.217\n    TaskMast  (b3)    0.504    0.106    0.295    0.724\n\nCovariances:\n                   Estimate  Std.Err ci.lower ci.upper\n  IntMot ~~                                           \n    SciAtt            0.184    0.025    0.135    0.240\n\nVariances:\n                   Estimate  Std.Err ci.lower ci.upper\n   .ActiveEn          0.059    0.005    0.051    0.068\n   .TaskMast          0.164    0.015    0.140    0.192\n   .EgoSoc            0.495    0.043    0.408    0.581\n    IntMot            0.290    0.024    0.250    0.343\n    SciAtt            0.371    0.033    0.311    0.434\n\nDefined Parameters:\n                   Estimate  Std.Err ci.lower ci.upper\n    im.tm.ind         0.114    0.032    0.070    0.190\n    im.tm.es.ind      0.009    0.005    0.002    0.020\n    im.es.ind        -0.026    0.012   -0.054   -0.006\n    im.total.ind      0.096    0.035    0.044    0.174\n    im.total          0.168    0.045    0.094    0.277\n    sa.tm.ind         0.117    0.025    0.074    0.169\n    sa.tm.es.ind      0.009    0.004    0.003    0.022\n    sa.es.ind        -0.013    0.008   -0.028    0.003\n    sa.total.ind      0.114    0.029    0.067    0.171\n\n\nThe output above gives us the unstandardized estimates, with a lot of other information. When using bootstrapping, we will focus on the estimates (est), and the lower (ci.lower) and upper (ci.upper) bounds of the 95% confidence interval. If this interval does does not include 0 (i.e., both bounds are positive or negative), we can conclude that the effect is significant (\\(\\alpha = .05\\)).\nWhat do the estimates and confidence intervals tell us about the indirect effects?"
  },
  {
    "objectID": "indirecteffects.html#example-write-up-of-above-results",
    "href": "indirecteffects.html#example-write-up-of-above-results",
    "title": "3  Indirect Effects",
    "section": "3.7 Example Write-Up of Above Results",
    "text": "3.7 Example Write-Up of Above Results\nIntrinsic Motivation was significantly related to Active Engagement both directly (B = .072, 95% CI [.022, .157]) and through three indirect paths, indicating partial mediation [assuming I have defensible causal assumptions]. Two indirect effects were positive and consistent with the direct effect, whereas the oe indirect effect (via Ego-Social Goals) was slightly negative and inconsistent. Thus, some of the positive effect via Task Mastery Goals on Ego-Social Goals (and indirectly Active Engagement) are diminished by the negative effect of Science Attitudes on Ego-Social Goals. Overall, Active Engagement is expected to increase by .217 (95% CI [.119, .372]) given a one-unit increase in Intrinsic Motivation through all direct and indirect pathways.\nScience Attitudes were significantly related to Active Engagement through two of three indirect paths. The two significant indirect effects were positive, whereas the non-significant indirect effect (via Ego-Social Goals) was slightly negative (B = -.013, 95% CI [-.028, .003]). Looking at the direct effects that make up the non-significant indirect effect, Science Attitudes was not significantly related to Ego-Social Goals (B = -.179, 95% CI [-.374, .015]). Overall, Active Engagement is expected to increase by .164 (95% CI [.094, .257]) given a one-unit increase in Science Attitudes through all indirect pathways (no direct path was included)."
  },
  {
    "objectID": "indirecteffects.html#summary",
    "href": "indirecteffects.html#summary",
    "title": "3  Indirect Effects",
    "section": "3.8 Summary",
    "text": "3.8 Summary\nIn this R lab, you were introduced to the steps involved in specifying, estimating, and interpreting indirect effects. Below, you’ll find two Bonus sections that demonstrate how to extract standardized estimates with 95% CIs and how to include a moderator into the mediation model (moderated mediation). In the next R Lab, you will learn all about model evaluation (i.e., does the model do a good job representing the associations between the variables?)."
  },
  {
    "objectID": "indirecteffects.html#bonus-1-standardized-indirect-effects-with-correct-95-confidence-interval",
    "href": "indirecteffects.html#bonus-1-standardized-indirect-effects-with-correct-95-confidence-interval",
    "title": "3  Indirect Effects",
    "section": "3.9 Bonus 1: Standardized Indirect Effects (with correct 95% Confidence Interval)",
    "text": "3.9 Bonus 1: Standardized Indirect Effects (with correct 95% Confidence Interval)\nAlthough lavaan can give us the standardized estimates of the indirect effects, the confidence intervals that it provides are not based on the bootstrapped samples. To get the correct 95% confidence intervals, we can use the package semhelpinghands, which includes several functions that help us use lavaan to its fullest extend.\n\nlibrary(semhelpinghands)\n\nTo use the package, we use the function standardizedSolution_boot_ci() to compute the correct 95% confidence interval. We can use the print() function to get a prettier version of the output.\n\nci_boot &lt;- standardizedSolution_boot_ci(fit1)\n\nprint(ci_boot,\n      output = \"text\")\n\n\nStandardized Estimates Only\n\n  Standard errors                            Bootstrap\n  Confidence interval                        Bootstrap\n  Confidence Level                               95.0%\n  Standardization Type                         std.all\n  Number of requested bootstrap draws              100\n  Number of successful bootstrap draws             100\n\nRegressions:\n               Standardized  Std.Err ci.lower ci.upper\n  ActiveEn ~                                          \n    TaskMast  (b1)    0.630    0.041    0.526    0.704\n    EgoSoc    (b2)    0.150    0.050    0.045    0.252\n    IntMot    (c1)    0.110    0.047    0.023    0.210\n  TaskMast ~                                          \n    SciAtt    (a1)    0.324    0.067    0.185    0.454\n    IntMot    (a2)    0.279    0.064    0.168    0.411\n  EgoSoc ~                                            \n    SciAtt    (a3)   -0.145    0.071   -0.304   -0.020\n    IntMot    (a4)   -0.267    0.071   -0.386   -0.090\n    TaskMast  (b3)    0.323    0.066    0.179    0.452\n\nCovariances:\n               Standardized  Std.Err ci.lower ci.upper\n  IntMot ~~                                           \n    SciAtt            0.560    0.045    0.451    0.631\n\nVariances:\n               Standardized  Std.Err ci.lower ci.upper\n   .ActiveEn          0.487    0.043    0.409    0.579\n   .TaskMast          0.716    0.053    0.582    0.809\n   .EgoSoc            0.884    0.035    0.801    0.941\n    IntMot            1.000       NA       NA       NA\n    SciAtt            1.000       NA       NA       NA\n\nDefined Parameters:\n               Standardized  Std.Err ci.lower ci.upper\n    im.tm.ind         0.175    0.043    0.108    0.269\n    im.tm.es.ind      0.013    0.007    0.003    0.029\n    im.es.ind        -0.040    0.018   -0.076   -0.007\n    im.total.ind      0.149    0.049    0.070    0.250\n    im.total          0.259    0.060    0.135    0.398\n    sa.tm.ind         0.204    0.045    0.119    0.290\n    sa.tm.es.ind      0.016    0.007    0.004    0.032\n    sa.es.ind        -0.022    0.014   -0.052   -0.001\n    sa.total.ind      0.198    0.052    0.097    0.299"
  },
  {
    "objectID": "indirecteffects.html#bonus-2-moderated-mediation-example",
    "href": "indirecteffects.html#bonus-2-moderated-mediation-example",
    "title": "3  Indirect Effects",
    "section": "3.10 Bonus 2: Moderated Mediation Example",
    "text": "3.10 Bonus 2: Moderated Mediation Example\nSometimes, we hypothesize that one or more paths that make up an indirect effect are themselves moderated (so-called moderated mediation). In the example below, we take the arbitrary moderation model from the previous Lab and extend it with a new outcome variable so that there is an indirect effect. In this model, Active Engagement acts as a mediator between Ego-Social Goal Orientations and Science Attitudes (Note: this model is not based on any theory, it was solely set up to illustrate this method). Intrinsic Motivation is included as a moderator on the path from Ego-Social Goals to Active Engagement. Thus, in this model, we hypothesize that Intrinsic Motivation affects the indirect effect by moderating this first part of the indirect effect. You can also specify a model where moderation occurs in the second part of the indirect effect (or both, or the direct effect, or combinations of everything).\nWe will again use the modsem package to help us with the interaction effect. As an initial step, we only want to focus on whether or not the moderator significantly affects the indirect effect. We can test this by specifying a so-called index of moderated mediation parameter, which represents the indirect effect of the interaction term and the b-path. We still use bootstrapping for testing the significance of any paths:\n\nlibrary(modsem)\n\nmod2 &lt;- '\nSciAtt ~ b*ActiveEn + c*EgoSoc\n\nActiveEn ~ a1*EgoSoc + a2*IntMot + a3*EgoSoc:IntMot\n\n# index of moderated mediation\nind.mod.im := a3*b\n'\n\nfit2 &lt;- modsem(model = mod2, data = meece, method = \"pind\",\n               se = \"bootstrap\", bootstrap = 100,\n               iseed = 8789)\n\nTo look at the parameter estimates as we’ve done before, we need to extract the lavaan object from the modsem object (otherwise functions such as parameterEstimates won’t work):\n\nfit2_lav &lt;- extract_lavaan(fit2)\n\nparameterEstimates(fit2_lav, boot.ci.type = \"bca.simple\", \n                   ci = TRUE, se = TRUE, \n                   zstat = FALSE, pvalue = FALSE,\n                   output = \"text\")\n\n\nRegressions:\n                   Estimate  Std.Err ci.lower ci.upper\n  SciAtt ~                                            \n    ActiveEn   (b)    0.619    0.100    0.380    0.797\n    EgoSoc     (c)   -0.175    0.051   -0.245   -0.037\n  ActiveEn ~                                          \n    EgoSoc    (a1)    0.393    0.126    0.176    0.660\n    IntMot    (a2)    0.506    0.121    0.245    0.774\n    EgScIntMt (a3)   -0.090    0.042   -0.175   -0.009\n\nVariances:\n                   Estimate  Std.Err ci.lower ci.upper\n   .SciAtt            0.319    0.027    0.269    0.403\n   .ActiveEn          0.093    0.008    0.080    0.111\n\nDefined Parameters:\n                   Estimate  Std.Err ci.lower ci.upper\n    ind.mod.im       -0.056    0.028   -0.127   -0.007\n\n\nIn the output above, we can see that: - Both main effects of Ego-Social Goals and Intrinsic Motivation are positive and significant (the 95% CI does not include 0); - The interaction effect is significant and negative (consistent with what we found in the previous Lab); - The path from the intermediate variable (Active Engagement) to Science Attitudes is significant and positive, whereas the direct effect of Ego-Social Goals on Science Attitudes is significant and negative.\nThus, although the direct association is negative, the indirect association via Active Engagement looks to be positive. But what role does Intrinsic Motivation play in moderating that indirect path?\nThe index of moderated mediation is negative and significant. This suggests that Intrinsic Motivation weakens the indirect effect of Ego-Social Goals on Science Attitudes through Active Engagement: the higher intrinsic motivation, the weaker the indirect effect. We can compute the indirect effect at several levels of the moderator to understand the moderated mediation effect better. To do so, we first compute simple slopes (i.e., the effect of the main predictor on the mediator at different levels of the moderator) and then combine those with the b-path to get several conditional indirect effects. It is typical to look at the impact of the moderator at it’s mean value and 1 SD above and below that mean, so let’s compute those first:\n\nmean(meece$IntMot)\n\n[1] 2.85\n\nmean(meece$IntMot) - sd(meece$IntMot)\n\n[1] 2.31\n\nmean(meece$IntMot) + sd(meece$IntMot)\n\n[1] 3.39\n\n\nNext, we can plug these values into our model specification to compute simple slopes and conditional indirect effects as follows:\n\nmod3 &lt;- '\nSciAtt ~ b*ActiveEn + c*EgoSoc\n\nActiveEn ~ a1*EgoSoc + a2*IntMot + a3*EgoSoc:IntMot\n\n# index of moderated mediation\nind.mod.im := a3*b\n\n# simple slopes\nim.low := a1 + a3*2.31\nim.mean := a1 + a3*2.85\nim.high := a1 + a3*3.39\n\n# conditional indirect effect\na1.b.low := im.low * b\na1.b.mean := im.mean * b\na1.b.high := im.high * b\n'\n\nfit3 &lt;- modsem(model = mod3, data = meece, method = \"pind\",\n               se = \"bootstrap\", bootstrap = 100,\n            iseed = 8789)\n\nIn the output below, we can see that the indirect effect gets smaller as the moderator value goes from low, to mean, to high:\n\nfit3_lav &lt;- extract_lavaan(fit3)\n\nparameterEstimates(fit3_lav, boot.ci.type = \"bca.simple\", \n                   ci = TRUE, se = TRUE, \n                   zstat = FALSE, pvalue = FALSE,\n                   output = \"text\")\n\n\nRegressions:\n                   Estimate  Std.Err ci.lower ci.upper\n  SciAtt ~                                            \n    ActiveEn   (b)    0.619    0.100    0.380    0.797\n    EgoSoc     (c)   -0.175    0.051   -0.245   -0.037\n  ActiveEn ~                                          \n    EgoSoc    (a1)    0.393    0.126    0.176    0.660\n    IntMot    (a2)    0.506    0.121    0.245    0.774\n    EgScIntMt (a3)   -0.090    0.042   -0.175   -0.009\n\nVariances:\n                   Estimate  Std.Err ci.lower ci.upper\n   .SciAtt            0.319    0.027    0.269    0.403\n   .ActiveEn          0.093    0.008    0.080    0.111\n\nDefined Parameters:\n                   Estimate  Std.Err ci.lower ci.upper\n    ind.mod.im       -0.056    0.028   -0.127   -0.007\n    im.low            0.185    0.037    0.084    0.254\n    im.mean           0.136    0.027    0.077    0.183\n    im.high           0.087    0.033    0.025    0.163\n    a1.b.low          0.114    0.029    0.054    0.170\n    a1.b.mean         0.084    0.021    0.047    0.132\n    a1.b.high         0.054    0.022    0.019    0.115"
  },
  {
    "objectID": "indirecteffects.html#model-specification",
    "href": "indirecteffects.html#model-specification",
    "title": "3  Indirect Effects",
    "section": "3.4 Model Specification",
    "text": "3.4 Model Specification\nNext, we will specify the same model as we did in the previous lab, which aligned with the model tested by the authors. This time, we will add the code necessary to compute the indirect and total effects present in the model. To do so, we need to give each path in the model a label that we can use to define the indirect and total effects. We can do that by using the * symbol. For example, in the code below b1*TaskMast labels the path from Task Mastery to Active Engagement as b1. In indirect effects, it is customary to label paths from the predictor to the mediator with a, paths from the mediator to the outcome with b, and paths from the predictor to the outcome with c.\n\nmod1 &lt;- '\nActiveEn ~ b1*TaskMast + b2*EgoSoc + c1*IntMot\n\nTaskMast ~ a1*SciAtt + a2*IntMot\nEgoSoc ~ a3*SciAtt + a4*IntMot + b3*TaskMast\n\n\nSciAtt ~~ IntMot\n\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind := a2*b1\nim.tm.es.ind := a2*b3*b2\nim.es.ind := a4*b2\nim.total.ind := (a2*b1) + (a2*b3*b2) + (a4*b2) \nim.total := (a2*b1) + (a2*b3*b2) + (a4*b2) + c1\n\n# indirect effects between SciAtt &gt; AciveEn\nsa.tm.ind := a1*b1\nsa.tm.es.ind := a1*b3*b2\nsa.es.ind := a3*b2\nsa.total.ind := (a1*b1) + (a1*b3*b2) + (a3*b2)\n'\n\nOnce we have labeled all the paths, we can use the labels to specify the indirect and total (indirect) effects. Since these are parameters that we estimate after the direct effects have already been estimated, we need to give each new parameter a name. It helps if these names make sense to you. For example, in the code above, the parameter im.tm.ind refers to the indirect effect (ind) from IntMot (im) via TaskMast (tm).\nTo get the total indirect effect, you can simply add all the specific indirect effects together. If there is a direct effect from the main predictor to the main outcome, then we can also compute the total effect, by adding the direct effect (here c1) to the total indirect effects.\nWhy is there no total effect for the connection between SciAtt &gt; ActiveEn?\nYou can also see that some indirect effects are made up of more than two paths. This is the case with the paths that include the directed effect from Task Mastery to Ego Social goals (e.g., im.tm.es.ind := a2*b3*b2)."
  },
  {
    "objectID": "modelevaluation.html#loading-r-packages",
    "href": "modelevaluation.html#loading-r-packages",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.1 Loading R Packages",
    "text": "4.1 Loading R Packages\nLoad the required packages for this lab into your R environment:\n\nlibrary(rio)\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(semhelpinghands)"
  },
  {
    "objectID": "modelevaluation.html#loading-data-into-our-environment",
    "href": "modelevaluation.html#loading-data-into-our-environment",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.2 Loading data into our environment",
    "text": "4.2 Loading data into our environment\nLoad the data into your environment. We will use the same data we’ve used in the previous Lab:\n\nmeece &lt;- import(file = \"data/meece.csv\")"
  },
  {
    "objectID": "modelevaluation.html#model-1",
    "href": "modelevaluation.html#model-1",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.3 Model 1",
    "text": "4.3 Model 1\n\nModel Specification\nNext, we will specify a bare bones model that aligns with the central hypotheses of the authors behind these data. We will take a model building approach. The central hypotheses are:\n\nScience Attitudes affect Active Cognitive Engagement through the intermediate variable Ego-Social Goals\nIntrinsic Motivation affects Active Cognitive Engagement through the intermediate variable Task Mastery Goals\n\n\nmod1 &lt;- '\nActiveEn ~ b1*TaskMast + b2*EgoSoc\n\nTaskMast ~ a1*IntMot\nEgoSoc ~ a2*SciAtt\n\n\nSciAtt ~~ IntMot\n\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind := a1*b1\n\n# indirect effects between SciAtt &gt; AciveEn\nsa.es.ind := a2*b2\n'\n\nWhat are some additional theory-informed hypotheses we can list?\n\n\nModel Estimation\nSome of the local fit options are not available when bootstrapping is used during estimation, so for now, we will estimate the model without bootstrapping. Effects that are defined after estimation (such as indirect effects) do not affect the fit of a model to the data, so this decision will not affect our model evaluation choices. Once the model evaluation process is complete, we can re-estimate the final model with bootstrapping.\n\nfit1 &lt;- sem(model = mod1, data = meece)\n\n\n\nModel Evaluation\nHere, we will follow the steps described in the textbook.\n\nGlobal Fit\nFirst, we will test the exact fit of the model to the data using the Chi-square model test. We can find this statistic by including fit.measures = T in the summary() function and finding the section labeled Model Test User Model. Note that I also set estimates = F, so that the parameter estimates are not included in the output (mostly to reduce the length of the output):\n\nsummary(fit1, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           256\n\nModel Test User Model:\n                                                      \n  Test statistic                                56.448\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               398.422\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.868\n  Tucker-Lewis Index (TLI)                       0.735\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -828.169\n  Loglikelihood unrestricted model (H1)       -799.945\n                                                      \n  Akaike (AIC)                                1676.338\n  Bayesian (BIC)                              1711.790\n  Sample-size adjusted Bayesian (SABIC)       1680.087\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.200\n  90 Percent confidence interval - lower         0.155\n  90 Percent confidence interval - upper         0.249\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.094\n\n\nWhat does the Chi-square test tell us about the exact fit of this model?\nOther fit indices that are reported here:\n\nModel Test Baseline Model: This is the Chi-square of the worst model, that is used to compute the CFI/TLI. This Chi-square should always be larger than the Model Test User Model.\nCFI/TLI: Goodness-of-fit indices, values closer to 1 indicate better fit\nLoglikelihood and Information Criteria: This information is used to compute the AIC and BIC (and SABIC), which help you compare non-nested models\nRoot Mean Square Error of Approximation: Badness-of-fit index, values closer to 0 indicate better fit. This section helps you use the 90% confidence interval to compute the p-value for H0: RMSEA is &lt;= .05 (if p &gt; .05, this indicates good fit) and H0 = RMSEA &gt;= .08 (if p &gt; .05, this indicates poor fit).\nSRMR: Badness-of-fit index, values closer to 0 indicate better fit.\n\n\n\nLocal Fit\nTo identify where the friction between the data and the model might be, we can look at local fit using the covariance residuals. It can be helpful to compare results across different methods:\n\nresiduals(fit1, type = \"standardized\")\n\n$type\n[1] \"standardized\"\n\n$cov\n         ActvEn TskMst EgoSoc IntMot SciAtt\nActiveEn  2.905                            \nTaskMast  2.905  0.000                     \nEgoSoc    2.905  2.905  0.000              \nIntMot    1.658  0.000 -2.346  0.000       \nSciAtt    3.026  4.630  0.000  0.000  0.000\n\nresiduals(fit1, type = \"normalized\")\n\n$type\n[1] \"normalized\"\n\n$cov\n         ActvEn TskMst EgoSoc IntMot SciAtt\nActiveEn  0.311                            \nTaskMast  0.263  0.000                     \nEgoSoc    1.779  2.635  0.000              \nIntMot    0.971  0.000 -1.908  0.000       \nSciAtt    2.303  3.208  0.000  0.000  0.000\n\nresiduals(fit1, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n         ActvEn TskMst EgoSoc IntMot SciAtt\nActiveEn  0.000                            \nTaskMast  0.011  0.000                     \nEgoSoc    0.112  0.166  0.000              \nIntMot    0.060  0.000 -0.122  0.000       \nSciAtt    0.148  0.222  0.000  0.000  0.000\n\n\nWhat patterns can you see in the covariance residuals? What path could we add to the model?"
  },
  {
    "objectID": "modelevaluation.html#model-2",
    "href": "modelevaluation.html#model-2",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.4 Model 2",
    "text": "4.4 Model 2\n\nModel Respecification\nLets add the hypothesis that Task Mastery Goals and Ego-Social Goals are correlated/associated\n\nmod2 &lt;- '\nActiveEn ~ b1*TaskMast + b2*EgoSoc\n\nTaskMast ~ a1*IntMot\nEgoSoc ~ a2*SciAtt\n\n\nTaskMast ~~ EgoSoc\n\nSciAtt ~~ IntMot\n\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind := a1*b1\n\n# indirect effects between SciAtt &gt; AciveEn\nsa.es.ind := a2*b2\n'\n\nWe can estimate the model and save it in fit2:\n\nfit2 &lt;- sem(model = mod2, data = meece)\n\n\n\nModel Evaluation\nWe will use the same sources of information to evaluate the fit of this modified model.\n\nGlobal Fit\n\nsummary(fit2, fit.measures = T,  estimates = F)\n\nlavaan 0.6.17 ended normally after 24 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        11\n\n  Number of observations                           256\n\nModel Test User Model:\n                                                      \n  Test statistic                                32.567\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               398.422\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.926\n  Tucker-Lewis Index (TLI)                       0.816\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -816.229\n  Loglikelihood unrestricted model (H1)       -799.945\n                                                      \n  Akaike (AIC)                                1654.457\n  Bayesian (BIC)                              1693.454\n  Sample-size adjusted Bayesian (SABIC)       1658.581\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.167\n  90 Percent confidence interval - lower         0.117\n  90 Percent confidence interval - upper         0.222\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.997\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.080\n\n\nWhat does the Chi-square test tell us about the exact fit of this model?\n\n\nLocal Fit\nWe can examine to what extend the added covariance between Task Mastery and Ego-Social Goals has resolved the local fit issues (only showing one method here):\n\nresiduals(fit2, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n         ActvEn TskMst EgoSoc IntMot SciAtt\nActiveEn  0.000                            \nTaskMast -0.009  0.000                     \nEgoSoc   -0.054 -0.078  0.000              \nIntMot    0.058 -0.017 -0.083  0.000       \nSciAtt    0.153  0.213  0.069  0.000  0.000\n\n\nWhat patterns can you see in the covariance residuals? What path could we add to the model?"
  },
  {
    "objectID": "modelevaluation.html#model-comparison-of-model-1-and-model-2",
    "href": "modelevaluation.html#model-comparison-of-model-1-and-model-2",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.5 Model Comparison of Model 1 and Model 2",
    "text": "4.5 Model Comparison of Model 1 and Model 2\nWe can also use the Chi-square difference test to compare the original and modified model to each other. Here, the original model is more constraint and the modified model is less constraint. The Chi-square difference test, tests the Null hypothesis: Chi-square constrained == Chi-square free.\n\nIf the Chi-square difference test is significant, it means that the contrained model fits the data worse than the free model, which means that adding the additional path helped us improve the global fit.\nIf the Chi-square difference test is not significant, it means that the constrained mode fits the data equally well as the free model, which means that adding the additional path did not improve model fit.\n\nTo ensure that our models are nested, we use the net() function from the semTools package. This function checks if two models are nested and if two models are equivalent:\n\nnet(fit1, fit2)\n\n\n        If cell [R, C] is TRUE, the model in row R is nested within column C.\n\n        If the models also have the same degrees of freedom, they are equivalent.\n\n        NA indicates the model in column C did not converge when fit to the\n        implied means and covariance matrix from the model in row R.\n\n        The hidden diagonal is TRUE because any model is equivalent to itself.\n        The upper triangle is hidden because for models with the same degrees\n        of freedom, cell [C, R] == cell [R, C].  For all models with different\n        degrees of freedom, the upper diagonal is all FALSE because models with\n        fewer degrees of freedom (i.e., more parameters) cannot be nested\n        within models with more degrees of freedom (i.e., fewer parameters).\n        \n              fit2 fit1\nfit2 (df = 4)          \nfit1 (df = 5) TRUE     \n\n\nNext, we can use the compareFit() function from the semTools package to compare the models using the Chi-square difference test:\n\ncomp12 &lt;- compareFit(fit1, fit2)\nsummary(comp12)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n     Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit2  4 1654.5 1693.5 32.568                                          \nfit1  5 1676.3 1711.8 56.448     23.881 0.29896       1  1.025e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n       chisq df pvalue rmsea   cfi   tli  srmr       aic       bic\nfit2 32.567†  4   .000 .167† .926† .816† .080† 1654.457† 1693.454†\nfit1 56.448   5   .000 .200  .868  .735  .094  1676.338  1711.790 \n\n################## Differences in Fit Indices #######################\n            df rmsea    cfi    tli  srmr    aic    bic\nfit1 - fit2  1 0.033 -0.059 -0.081 0.014 21.881 18.336\n\n\nDoes the modified model result in an improvement in global fit?"
  },
  {
    "objectID": "modelevaluation.html#model-3",
    "href": "modelevaluation.html#model-3",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.6 Model 3",
    "text": "4.6 Model 3\n\nModel Respecification\nWe can keep building out model by including a path from Science Attitudes to Task Mastery Goals, which means that we hypothesize that Science Attitudes indirectly affect Active Cognitive Engagement through both Ego-Social and Task Mastery Goals.\n\nmod3 &lt;- '\nActiveEn ~ b1*TaskMast + b2*EgoSoc\n\nTaskMast ~ a1*IntMot + a3*SciAtt\nEgoSoc ~ a2*SciAtt\n\n\nTaskMast ~~ EgoSoc\n\nSciAtt ~~ IntMot\n\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind := a1*b1\n\n# indirect effects between SciAtt &gt; AciveEn\nsa.es.ind := a2*b2\nsa.tm.ind := a3*b1\nsa.total.ind := (a2*b2) + (a3*b1)\n'\n\nWe can estimate the model and save it in fit3:\n\nfit3 &lt;- sem(model = mod3, data = meece)\n\n\n\nModel Evaluation\nWe will use the same sources of information to evaluate the fit of this modified model.\n\nGlobal Fit\n\nsummary(fit3, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Number of observations                           256\n\nModel Test User Model:\n                                                      \n  Test statistic                                11.194\n  Degrees of freedom                                 3\n  P-value (Chi-square)                           0.011\n\nModel Test Baseline Model:\n\n  Test statistic                               398.422\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.979\n  Tucker-Lewis Index (TLI)                       0.930\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -805.542\n  Loglikelihood unrestricted model (H1)       -799.945\n                                                      \n  Akaike (AIC)                                1635.084\n  Bayesian (BIC)                              1677.626\n  Sample-size adjusted Bayesian (SABIC)       1639.583\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.103\n  90 Percent confidence interval - lower         0.044\n  90 Percent confidence interval - upper         0.171\n  P-value H_0: RMSEA &lt;= 0.050                    0.067\n  P-value H_0: RMSEA &gt;= 0.080                    0.775\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.037\n\n\nWhat does the Chi-square test tell us about the exact fit of this model?\n\n\nLocal Fit\n\nresiduals(fit3, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n         ActvEn TskMst EgoSoc IntMot SciAtt\nActiveEn  0.000                            \nTaskMast -0.006  0.000                     \nEgoSoc   -0.025 -0.037  0.000              \nIntMot    0.047 -0.025 -0.122  0.000       \nSciAtt    0.001  0.004  0.000  0.000  0.000\n\n\nWhat patterns can you see in the covariance residuals? What path could we add to the model?"
  },
  {
    "objectID": "modelevaluation.html#model-comparison-of-model-2-and-model-3",
    "href": "modelevaluation.html#model-comparison-of-model-2-and-model-3",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.7 Model Comparison of Model 2 and Model 3",
    "text": "4.7 Model Comparison of Model 2 and Model 3\n\ncomp23 &lt;- compareFit(fit3, fit2)\nsummary(comp23)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n     Df    AIC    BIC  Chisq Chisq diff  RMSEA Df diff Pr(&gt;Chisq)    \nfit3  3 1635.1 1677.6 11.194                                         \nfit2  4 1654.5 1693.5 32.568     21.373 0.2821       1   3.78e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n       chisq df pvalue rmsea   cfi   tli  srmr       aic       bic\nfit3 11.194†  3   .011 .103† .979† .930† .037† 1635.084† 1677.626†\nfit2 32.567   4   .000 .167  .926  .816  .080  1654.457  1693.454 \n\n################## Differences in Fit Indices #######################\n            df rmsea    cfi    tli  srmr    aic    bic\nfit2 - fit3  1 0.064 -0.052 -0.114 0.043 19.373 15.828\n\n\nDoes the modified model result in an improvement in global fit?"
  },
  {
    "objectID": "modelevaluation.html#model-4",
    "href": "modelevaluation.html#model-4",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.8 Model 4",
    "text": "4.8 Model 4\n\nModel Respecification\nLets add the path from Intrinsic Motivation to Ego-Social Goals, which matches the hypothesis that Intrinsic Motivation indirectly affects Cognitive Engagement through both Task Mastery and Ego-Social Goals:\n\nmod4 &lt;- '\nActiveEn ~ b1*TaskMast + b2*EgoSoc\n\nTaskMast ~ a1*IntMot + a3*SciAtt\nEgoSoc ~ a2*SciAtt + a4*IntMot\n\n\nTaskMast ~~ EgoSoc\n\nSciAtt ~~ IntMot\n\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind := a1*b1\nim.es.ind := a4*b1\nim.total.ind := (a1*b1) + (a4*b1)\n\n# indirect effects between SciAtt &gt; AciveEn\nsa.es.ind := a2*b2\nsa.tm.ind := a3*b1\nsa.total.ind := (a2*b2) + (a3*b1)\n'\n\nWe can estimate the model and save it in fit4:\n\nfit4 &lt;- sem(model = mod4, data = meece)\n\n\n\nModel Evaluation\nWe will use the same sources of information to evaluate the fit of this modified model.\n\nGlobal Fit\n\nsummary(fit4, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           256\n\nModel Test User Model:\n                                                      \n  Test statistic                                 5.506\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.064\n\nModel Test Baseline Model:\n\n  Test statistic                               398.422\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.991\n  Tucker-Lewis Index (TLI)                       0.955\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -802.698\n  Loglikelihood unrestricted model (H1)       -799.945\n                                                      \n  Akaike (AIC)                                1631.396\n  Bayesian (BIC)                              1677.483\n  Sample-size adjusted Bayesian (SABIC)       1636.270\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.083\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.169\n  P-value H_0: RMSEA &lt;= 0.050                    0.186\n  P-value H_0: RMSEA &gt;= 0.080                    0.612\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.021\n\n\nWhat does the Chi-square test tell us about the exact fit of this model?\n\n\nLocal Fit\n\nresiduals(fit4, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n         ActvEn TskMst EgoSoc IntMot SciAtt\nActiveEn  0.000                            \nTaskMast  0.000  0.000                     \nEgoSoc    0.000  0.000  0.000              \nIntMot    0.079  0.000  0.000  0.000       \nSciAtt   -0.002  0.000  0.000  0.000  0.000\n\n\nWhat patterns can you see in the covariance residuals? What path could we add to the model?"
  },
  {
    "objectID": "modelevaluation.html#model-comparison-of-model-3-and-model-4",
    "href": "modelevaluation.html#model-comparison-of-model-3-and-model-4",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.9 Model Comparison of Model 3 and Model 4",
    "text": "4.9 Model Comparison of Model 3 and Model 4\n\ncomp34 &lt;- compareFit(fit3, fit4)\nsummary(comp34)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n     Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)  \nfit4  2 1631.4 1677.5  5.5063                                        \nfit3  3 1635.1 1677.6 11.1941     5.6878 0.13532       1    0.01708 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n       chisq df pvalue rmsea   cfi   tli  srmr       aic       bic\nfit4  5.506†  2   .064 .083† .991† .955† .021† 1631.396† 1677.483†\nfit3 11.194   3   .011 .103  .979  .930  .037  1635.084  1677.626 \n\n################## Differences in Fit Indices #######################\n            df rmsea    cfi    tli  srmr   aic   bic\nfit3 - fit4  1 0.021 -0.012 -0.025 0.017 3.688 0.143\n\n\nDoes the modified model result in an improvement in global fit?"
  },
  {
    "objectID": "modelevaluation.html#parameter-estimate-interpretation",
    "href": "modelevaluation.html#parameter-estimate-interpretation",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.10 Parameter Estimate Interpretation",
    "text": "4.10 Parameter Estimate Interpretation\nTypically, you would look at the estimates of newly added paths at each step of the model building process, to ensure that the estimates align with theoretical expectations. Here, we kind of skipped that, but we will take a quick look now. Please refer back to the Indirect Effects R Lab to read more about interpreting indirect effects.\n\nfit4 &lt;- sem(model = mod4, data = meece,\n            se = \"bootstrap\", bootstrap = 1000,\n            iseed = 8789)\n\nFirst, we can look at the (unstandardized) parameter estimates:\n\nparameterEstimates(fit4, boot.ci.type = \"bca.simple\", \n                   ci = TRUE, se = TRUE, \n                   zstat = FALSE, pvalue = FALSE,\n                   output = \"text\")\n\n\nRegressions:\n                   Estimate  Std.Err ci.lower ci.upper\n  ActiveEn ~                                          \n    TaskMast  (b1)    0.499    0.035    0.430    0.572\n    EgoSoc    (b2)    0.056    0.022    0.012    0.099\n  TaskMast ~                                          \n    IntMot    (a1)    0.248    0.064    0.128    0.372\n    SciAtt    (a3)    0.255    0.051    0.153    0.358\n  EgoSoc ~                                            \n    SciAtt    (a2)   -0.050    0.086   -0.214    0.126\n    IntMot    (a4)   -0.246    0.104   -0.454   -0.036\n\nCovariances:\n                   Estimate  Std.Err ci.lower ci.upper\n .TaskMast ~~                                         \n   .EgoSoc            0.083    0.017    0.049    0.120\n  IntMot ~~                                           \n    SciAtt            0.184    0.024    0.138    0.238\n\nVariances:\n                   Estimate  Std.Err ci.lower ci.upper\n   .ActiveEn          0.060    0.005    0.052    0.073\n   .TaskMast          0.164    0.014    0.137    0.192\n   .EgoSoc            0.537    0.046    0.458    0.641\n    IntMot            0.290    0.024    0.249    0.343\n    SciAtt            0.371    0.032    0.312    0.441\n\nDefined Parameters:\n                   Estimate  Std.Err ci.lower ci.upper\n    im.tm.ind         0.124    0.035    0.058    0.195\n    im.es.ind        -0.123    0.052   -0.229   -0.021\n    im.total.ind      0.001    0.068   -0.134    0.133\n    sa.es.ind        -0.003    0.005   -0.016    0.006\n    sa.tm.ind         0.127    0.025    0.078    0.178\n    sa.total.ind      0.124    0.027    0.071    0.178\n\n\nEven though our model fits the data well, we can see that the path from Science Attitudes to Ego-Social Goals (which was part of our theoretical model at the start of all this), is not significant. We might want to explore if model trimming (i.e., removing this path) does not affect the overall model fit. However, since this path was so central to our theory, we would ideally want to collect another sample and test if the trimmed model can be replicated.\nAnother piece of output that we can examine are the R-squared estimates for each endogenous variable in the model. These represent the proportion of variance in the endogenous variables that can be explained by the predictors in the model. Remember, a well-fitting model can have endogenous variables with low R-squareds. This is because the model-implied variances include both the explained (R-squared) and unexplained/error (1 - R-squared) variance. Thus, a model can fit well as long as the model closely predicts the total variance in the endogenous variables, even if a large part of that variance is unexplained/error.\nWe can use lavInspect() to get the R-squared estimates:\n\nlavInspect(fit4, what = \"rsquare\")\n\nActiveEn TaskMast   EgoSoc \n   0.504    0.284    0.041 \n\n\nFor which endogenous variable does the model result in the largest unexplained/error variance?"
  },
  {
    "objectID": "modelevaluation.html#comparing-groups",
    "href": "modelevaluation.html#comparing-groups",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.11 Comparing groups",
    "text": "4.11 Comparing groups\nNext, we will look at a special use of model evaluation and comparison: multiple group path model. We will learn how to compare the same model across different groups. For that purpose, lets pretend that the meece study was repeated for a sample of high school students (the original sample are middle school students). These data are saved in data_meece2.csv.\nYou can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/meece2.csv. Make sure to save it in the folder you are using for this class.\nWe will add a sample variable to each data frame and then combine the two data frames together:\n\nmeece2 &lt;- import(\"data/meece2.csv\")\n\n# Create group variable for each dataset\nmeece$sample &lt;- 1\nmeece2$sample &lt;- 2\n\n# Combine two groups into one dataframe\nmeece_all &lt;- rbind(meece, meece2)\n\nFor this example, we will estimate a simplified version of the model we’ve been working on so far, by only including Intrinsic Motivation as an exogenous variable. Compared to the single-group analysis model, we need to make some adjustments to the multiple-group scenario, specifically in how we label variables.\nWe initially start with a model in which all paths are estimated separately for each group. Now, each path needs a label for each group, and we use c() to list these labels for each path. For example, for the path from Task Mastery to Active Engagement, we use c(b1.g1, b1.g2). We also need to define indirect (and if present total) effects for each group separately.\n\nmod_g1 &lt;- '\nActiveEn ~ c(b1.g1, b1.g2)*TaskMast + c(b2.g1, b2.g2)*EgoSoc\n\nTaskMast ~ c(a1.g1, a1.g2)*IntMot\nEgoSoc ~ c(a2.g1, a2.g2)*IntMot\n\nTaskMast ~~ EgoSoc\n\n# Group = 1\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind.g1 := a1.g1*b1.g1\nim.es.ind.g1 := a2.g1*b2.g1\nim.total.ind.g1 := (a1.g1*b1.g1) + (a2.g1*b2.g1)\n\n# Group = 2\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind.g2 := a1.g2*b1.g2\nim.es.ind.g2 := a2.g2*b2.g2\nim.total.ind.g2 := (a1.g2*b1.g2) + (a2.g2*b2.g2)\n'\n\nWhen we estimate this model, we need to tell lavaan what variable contains the group assignment for each participant by adding group = \"group\". In your data, your group variable might have a different name. Again, we’re going to skip bootstrapping because I am focused on demonstrating how you can compare estimates across groups using the Chi-square difference test:\n\nfit_g1 &lt;- sem(model = mod_g1, data = meece_all, group = \"sample\")\n\nIf you use the summary() function, you will get parameter estimates per group, printed out sequentially. For complex models, this can result in a very long output object:\n\nsummary(fit_g1, fit.measures = T)\n\nlavaan 0.6.17 ended normally after 42 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        22\n\n  Number of observations per group:                   \n    1                                              256\n    2                                              256\n\nModel Test User Model:\n                                                      \n  Test statistic                                15.190\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.001\n  Test statistic for each group:\n    1                                            4.571\n    2                                           10.620\n\nModel Test Baseline Model:\n\n  Test statistic                               493.713\n  Degrees of freedom                                12\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.973\n  Tucker-Lewis Index (TLI)                       0.836\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -851.940\n  Loglikelihood unrestricted model (H1)       -844.345\n                                                      \n  Akaike (AIC)                                1747.881\n  Bayesian (BIC)                              1841.124\n  Sample-size adjusted Bayesian (SABIC)       1771.292\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.161\n  90 Percent confidence interval - lower         0.092\n  90 Percent confidence interval - upper         0.240\n  P-value H_0: RMSEA &lt;= 0.050                    0.006\n  P-value H_0: RMSEA &gt;= 0.080                    0.971\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.029\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [1]:\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ActiveEn ~                                          \n    TaskMst (b1.1)    0.499    0.032   15.420    0.000\n    EgoSoc  (b2.1)    0.056    0.021    2.728    0.006\n  TaskMast ~                                          \n    IntMot  (a1.1)    0.409    0.049    8.289    0.000\n  EgoSoc ~                                            \n    IntMot  (a2.1)   -0.278    0.085   -3.266    0.001\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .TaskMast ~~                                         \n   .EgoSoc            0.080    0.020    3.956    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ActiveEn          0.523    0.111    4.735    0.000\n   .TaskMast          2.035    0.143   14.221    0.000\n   .EgoSoc            3.272    0.247   13.262    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ActiveEn          0.060    0.005   11.314    0.000\n   .TaskMast          0.181    0.016   11.314    0.000\n   .EgoSoc            0.538    0.048   11.314    0.000\n\n\nGroup 2 [2]:\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ActiveEn ~                                          \n    TaskMst (b1.2)    0.269    0.031    8.632    0.000\n    EgoSoc  (b2.2)    0.195    0.020    9.621    0.000\n  TaskMast ~                                          \n    IntMot  (a1.2)    0.373    0.053    7.095    0.000\n  EgoSoc ~                                            \n    IntMot  (a2.2)   -0.268    0.087   -3.090    0.002\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .TaskMast ~~                                         \n   .EgoSoc            0.071    0.021    3.450    0.001\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ActiveEn          0.538    0.107    5.043    0.000\n   .TaskMast          2.137    0.151   14.132    0.000\n   .EgoSoc            3.201    0.250   12.823    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .ActiveEn          0.057    0.005   11.314    0.000\n   .TaskMast          0.196    0.017   11.314    0.000\n   .EgoSoc            0.533    0.047   11.314    0.000\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    im.tm.ind.g1      0.204    0.028    7.301    0.000\n    im.es.ind.g1     -0.016    0.007   -2.094    0.036\n    im.total.nd.g1    0.188    0.030    6.219    0.000\n    im.tm.ind.g2      0.100    0.018    5.481    0.000\n    im.es.ind.g2     -0.052    0.018   -2.942    0.003\n    im.total.nd.g2    0.048    0.028    1.728    0.084\n\n\nYou can also use the group_by_groups() function from the semhelpinghands package to get a quick overview of just the parameter estimates to see if there are any that appear particularly different:\n\ngroup_by_groups(fit_g1)\n\n        lhs op      rhs  est_1  est_2\n1  ActiveEn  ~   EgoSoc  0.056  0.195\n2  ActiveEn  ~ TaskMast  0.499  0.269\n3    EgoSoc  ~   IntMot -0.278 -0.268\n4  TaskMast  ~   IntMot  0.409  0.373\n5  ActiveEn ~~ ActiveEn  0.060  0.057\n6    EgoSoc ~~   EgoSoc  0.538  0.533\n7    IntMot ~~   IntMot  0.290  0.276\n8  TaskMast ~~   EgoSoc  0.080  0.071\n9  TaskMast ~~ TaskMast  0.181  0.196\n10 ActiveEn ~1           0.523  0.538\n11   EgoSoc ~1           3.272  3.201\n12   IntMot ~1           2.850  2.828\n13 TaskMast ~1           2.035  2.137\n\n\nAre there any estimates that look like they might differ across groups?\nNote that multiple group analyses include the variable means/intercepts as well, which are denoted with e.g., ActiveEn ~ 1. This means we can also test if the groups have equivalent average levels of the variables (where for endogenous variables, this is actually the intercept, or the expected value when all predictors equal 0).\n\nSpecifying a More Restrictive Model\nTo restrict certain parameters to be equivalent across groups, we need to assign the same label to the parameter in both groups. For example, the label of the path from Task Mastery to Active Engagement is now c(b1, b1). We might do this if we want to test the Null hypothesis of no group difference in the strength of an association between two variables. In this case, we might want to see if our new sample replicates the findings found in the original sample.\n\nmod_g2 &lt;- '\nActiveEn ~ c(b1, b1)*TaskMast + c(b2, b2)*EgoSoc\n\nTaskMast ~ c(a1, a1)*IntMot\nEgoSoc ~ c(a2, a2)*IntMot\n\n\nTaskMast ~~ EgoSoc\n\n# Group = 1 and 2 because no separate effects\n# indirect and total effect between IntMot &gt; AciveEn\nim.tm.ind.g1 := a1*b1\nim.es.ind.g1 := a2*b2\nim.total.ind.g1 := (a1*b1) + (a2*b2)\n'\n\nWhen estimating this model, you still need to include group = \"sample\":\n\nfit_g2 &lt;- sem(model = mod_g2, data = meece_all, group = \"sample\")\n\nWhen we look at the group_by_groups output, all the regression estimates should be equivalent across groups. They are estimated as though they are one parameter (instead of two, one per group). You can see the difference reflected in the degrees of freedom, which are much higher for this (more constrained) model:\n\ngroup_by_groups(fit_g2)\n\n        lhs op      rhs  est_1  est_2\n1  ActiveEn  ~   EgoSoc  0.128  0.128\n2  ActiveEn  ~ TaskMast  0.379  0.379\n3    EgoSoc  ~   IntMot -0.274 -0.274\n4  TaskMast  ~   IntMot  0.392  0.392\n5  ActiveEn ~~ ActiveEn  0.066  0.062\n6    EgoSoc ~~   EgoSoc  0.538  0.533\n7    IntMot ~~   IntMot  0.290  0.276\n8  TaskMast ~~   EgoSoc  0.080  0.071\n9  TaskMast ~~ TaskMast  0.181  0.196\n10 ActiveEn ~1           0.730  0.351\n11   EgoSoc ~1           3.259  3.216\n12   IntMot ~1           2.850  2.828\n13 TaskMast ~1           2.082  2.083\n\n\nAre there parameters that are still estimated separately for each group?\n\n\nModel Comparison using the Chi-square difference test\nWe can use the Chi-square difference test to compare the two multiple group models. In this case, a significant Chi-square difference test would indicate that the restrictive model (where all regression paths are specified to be equivalent across groups) fits the data worse than the free model, implying that there are likely some differences between the groups in terms of the associations between variables.\n\ncomp_g12 &lt;- compareFit(fit_g1, fit_g2)\nsummary(comp_g12)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n       Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit_g1  2 1747.9 1841.1 15.190                                          \nfit_g2  6 1782.0 1858.3 57.309     42.118 0.19294       4  1.577e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n         chisq df pvalue rmsea   cfi   tli  srmr       aic       bic\nfit_g1 15.190†  2   .001 .161† .973† .836† .029† 1747.881† 1841.124†\nfit_g2 57.309   6   .000 .183  .893  .787  .071  1781.999  1858.289 \n\n################## Differences in Fit Indices #######################\n                df rmsea    cfi    tli  srmr    aic    bic\nfit_g2 - fit_g1  4 0.022 -0.079 -0.049 0.042 34.118 17.165\n\n\nWhat can we conclude based on the chi-square difference test?\n\n\nLooking at local fit per group\nWe can use information about the local fit for each group to identify variable pairs for which the model is fitting differently across groups. Here, we will only look at correlation residuals (in the interest of space):\n\nresiduals(fit_g2, type = \"cor\")\n\n$`1`\n$`1`$type\n[1] \"cor.bollen\"\n\n$`1`$cov\n         ActvEn TskMst EgoSoc IntMot\nActiveEn  0.000                     \nTaskMast  0.123  0.000              \nEgoSoc   -0.149 -0.006  0.000       \nIntMot    0.187  0.015 -0.003  0.000\n\n$`1`$mean\nActiveEn TaskMast   EgoSoc   IntMot \n       0        0        0        0 \n\n\n$`2`\n$`2`$type\n[1] \"cor.bollen\"\n\n$`2`$cov\n         ActvEn TskMst EgoSoc IntMot\nActiveEn  0.000                     \nTaskMast -0.125  0.000              \nEgoSoc    0.157  0.007  0.000       \nIntMot    0.034 -0.017  0.004  0.000\n\n$`2`$mean\nActiveEn TaskMast   EgoSoc   IntMot \n       0        0        0        0 \n\n\nDo you see any inconsistencies in the pattern across groups?"
  },
  {
    "objectID": "modelevaluation.html#summary",
    "href": "modelevaluation.html#summary",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.12 Summary",
    "text": "4.12 Summary\nIn this R lab, you were introduced to the steps involved in model evaluation and comparison, including using model comparison methods to compare multiple groups. Below, you’ll find two Bonus sections that demonstrate how to test whether specific direct or indirect effects are equivalent across groups and how to request and interpret modification indices. In the next R Lab, you will learn all about latent variables and confirmatory factor analysis, which will also require you to apply your knowledge of model evaluation and comparison."
  },
  {
    "objectID": "modelevaluation.html#bonus-1-testing-the-equivalence-of-specific-direct-and-indirect-effects",
    "href": "modelevaluation.html#bonus-1-testing-the-equivalence-of-specific-direct-and-indirect-effects",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.13 Bonus 1: Testing the equivalence of specific direct and indirect effects",
    "text": "4.13 Bonus 1: Testing the equivalence of specific direct and indirect effects\nSometimes, you may want to test the equivalence of specific paths, instead of groups of parameters as we did above. To do so, we can use the Wald test. For this comparison, we start with the unconstrained model (saved in fit_g1), in which all direct effects are estimated separately for each group. With the code below, we test if the direct effect from Task Mastery &gt; Active Engagement is equivalent across the two age groups:\n\nlavTestWald(fit_g1, constraints = \"b1.g1 == b1.g2\")\n\n$stat\n[1] 26.17973\n\n$df\n[1] 1\n\n$p.value\n[1] 3.110712e-07\n\n$se\n[1] \"standard\"\n\n\nThe Wald test evaluates the Null hypothesis assigned to the constraints argument in the function. Here it tests the Null hypothesis that the two direct effects are equivalent across groups. Thus, a significant results (p &lt; .05) indicates that we should reject the null and conclude that there is evidence that the two direct effects are different.\nWhat would happen if we used the second model, in which all paths are constrained across groups, as input for the Wald test?\nNext, I will describe using the Wald test to test if the indirect effect is equivalent across groups. For this comparison, we again start with the unconstrained model (saved in fit_g1), in which all direct effects are estimated separately for each group. With the code below, we test if the indirect effect from Intrinsic Motivation &gt; Task Mastery &gt; Active Engagement is equivalent across the two age groups:\n\nlavTestWald(fit_g1, constraints = \"im.tm.ind.g1 == im.tm.ind.g2\")\n\n$stat\n[1] 9.62194\n\n$df\n[1] 1\n\n$p.value\n[1] 0.001922665\n\n$se\n[1] \"standard\"\n\n\nThe Wald test evaluates the Null hypothesis assigned to the constraints argument in the function. Here it tests the Null hypothesis that the two indirect effects are equivalent. Thus, a significant results (p &lt; .05) indicates that we should reject the null and conclude that there is evidence that the two indirect effects are different.\n\n\n\n\n\n\nNote\n\n\n\nNote that failing to reject the Wald test only tells us that the indirect effect is equivalent across the two groups. It could be possible that there are still differences in each of the (unconstrained) direct paths that make up the indirect effect. As a simple math example, the direct effect paths could be 4 and 5 for group 1 (indirect effect is 4x5 = 20), but 2 and 10 for group 2 (indirect effect is 2x10 = 20). Thus, it may also be important to test the equivalence of the direct effects."
  },
  {
    "objectID": "modelevaluation.html#bonus-2-modification-indices",
    "href": "modelevaluation.html#bonus-2-modification-indices",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.14 Bonus 2: Modification Indices",
    "text": "4.14 Bonus 2: Modification Indices\nAlthough I do not recommend relying purely on modification indices to guide your model building process, I do want you to know how to examine them. For this exercise, we will use our original model specification to see what kind of path the modification indices would have suggested. The modificationindices() function below requests modification indices that are at least 10 (indicating that Chi-square is expected to be lowered by 10 if the suggested parameter is added), by adding minimum.value = 10 (this value is arbitrary, but can help you filter out modifications that only improve the Chi-square by a smidge). By including .sort = TRUE, the results will be sorted from largest modification index (biggest impact on model fit) to smallest.\n\nmodificationIndices(fit1, sort. = TRUE, minimum.value = 10)\n\n        lhs op      rhs     mi    epc sepc.lv sepc.all sepc.nox\n35   SciAtt  ~ TaskMast 23.398  0.358   0.358    0.282    0.282\n19 TaskMast ~~   SciAtt 23.398  0.065   0.065    0.250    0.250\n26 TaskMast  ~   SciAtt 23.398  0.255   0.255    0.324    0.324\n18 TaskMast ~~   IntMot 23.398 -0.103  -0.103   -0.447   -0.447\n31   IntMot  ~ TaskMast 23.398 -0.567  -0.567   -0.504   -0.504\n17 TaskMast ~~   EgoSoc 21.223  0.091   0.091    0.288    0.288\n25 TaskMast  ~   EgoSoc 16.102  0.143   0.143    0.223    0.223\n28   EgoSoc  ~ TaskMast 10.876  0.330   0.330    0.211    0.211\n27   EgoSoc  ~ ActiveEn 10.622  0.647   0.647    0.298    0.298\n\n\nBased on our restrictions, the algorithm identified 10 modifications. The first three columns of output show you what modification is suggested, the fourth column (mi) gives you the modification index and the final columns give you an idea of what the expected parameter change will be if that parameter is included in the model (can be useful if you want to know if it would result in a large effect size). Let’s look at them.\n\nThe largest modification index suggests a path from Task Mastery Goals to Science Attitudes. This path is not in line with the theory that suggests that attitudes develop before goal orientations emerge. In addition, adding this path would turn Science Attitudes from exogenous to endogenous. In this new role, the covariance between Intrinsic Motivation and Science Attitudes would turn into a residual covariance, which violates one of the assumptions of path models.\nThe second to fifth modification indices are of the same magnitude as the first, but suggest very different associations. The second and third suggest that Task Mastery and Science attitudes should be allowed to covary, or that Science Attitudes should predict Task Mastery (this is a path we do end up including in a later modification). The fourth and fifth suggest that Task Mastery and Intrinsic Motivation should be associated through either a (residual) covariance or a directed path to Intrinsic Motivation. Each of these parameters would result in a non-recursive model with feedback loops.\nFinally, the sixth modification index suggests the modification we made (based on theory): Add the covariance between Task Mastery and Ego-Social Goals. Although this modification does not result in the largest expected decline in the Chi-square, it is the first one that makes theoretical sense.\n\nI hope that this example helps illustrate how modification indices are entirely data driven and that many of the modifications will make no sense from a theoretical or statistical point of view."
  },
  {
    "objectID": "indirecteffects.html#loading-data",
    "href": "indirecteffects.html#loading-data",
    "title": "3  Indirect Effects",
    "section": "3.2 Loading Data",
    "text": "3.2 Loading Data\nLoad the data into your environment. We will use the same data we’ve used in the previous Lab:\n\nmeece &lt;- import(file = \"data/meece.csv\")"
  },
  {
    "objectID": "modelevaluation.html#loading-data",
    "href": "modelevaluation.html#loading-data",
    "title": "4  Model Evaluation and Comparison",
    "section": "4.2 Loading Data",
    "text": "4.2 Loading Data\nLoad the data into your environment. We will use the same data we’ve used in the previous Lab:\n\nmeece &lt;- import(file = \"data/meece.csv\")"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#loading-r-packages",
    "href": "confirmatoryfactoranalysis.html#loading-r-packages",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.1 Loading R packages",
    "text": "5.1 Loading R packages\nLoad the required packages for this lab into your R environment:\n\nlibrary(rio)\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(semhelpinghands)"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#loading-data",
    "href": "confirmatoryfactoranalysis.html#loading-data",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.2 Loading Data",
    "text": "5.2 Loading Data\nLoad the data into your environment. For this lab we will use the data that was also used in the book chapter example: a sample of 200 children who completed the KABC (Kaufman Assessment Battery for Children), which includes eight subtests: Hand Movements (hm), Number Recall (nr), Word Order (wo), Gestalt Closure (gc), Triangles (tr), Spatial Memory (sm), Matrix Analogies (ma), and Photo Series (ps).\nYou can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/kabc.csv. Make sure to save it in the folder you are using for this class.\n\nkabc &lt;- import(file = \"data/kabc.csv\")"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#unidimensional-cfa",
    "href": "confirmatoryfactoranalysis.html#unidimensional-cfa",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.3 Unidimensional CFA",
    "text": "5.3 Unidimensional CFA\n\nModel Specification\nNext, we will specify a single factor CFA using lavaan syntax. We will use a new operator, =~, which tells lavaan that we are specifying a reflective latent factor. You can give the factor any name you want and put it on the left side of =~. All the indicators of the latent factor go on the right side of =~ with +s in between:\n\nmod1 &lt;- '\nCogA =~ hm + nr + wo + gc + tr + sm + ma + ps\n'\n\n\n\nModel Estimation\nNext, we will estimate the model using different model identification constraints. We will start with lavaan’s default: the reference variable method (or unit loading identification). To use this method, we do not need to add anything to our model estimation function, cfa.\n\nfit1a &lt;- cfa(model = mod1, data = kabc)\n\nTo estimate the same model using a unit variance identification constraint, we can change the code as follows:\n\nfit1b &lt;- cfa(model = mod1, data = kabc, \n             std.lv = TRUE)\n\nFinally, to estimate the same model using effect coding identification constraints, we can change the code as follows:\n\nfit1c &lt;- cfa(model = mod1, data = kabc, \n             effect.coding = TRUE)\n\nAre all these models equivalent? We can use the net() function to check:\n\nnet(fit1a, fit1b, fit1c)\n\n\n        If cell [R, C] is TRUE, the model in row R is nested within column C.\n\n        If the models also have the same degrees of freedom, they are equivalent.\n\n        NA indicates the model in column C did not converge when fit to the\n        implied means and covariance matrix from the model in row R.\n\n        The hidden diagonal is TRUE because any model is equivalent to itself.\n        The upper triangle is hidden because for models with the same degrees\n        of freedom, cell [C, R] == cell [R, C].  For all models with different\n        degrees of freedom, the upper diagonal is all FALSE because models with\n        fewer degrees of freedom (i.e., more parameters) cannot be nested\n        within models with more degrees of freedom (i.e., fewer parameters).\n        \n                fit1a fit1b fit1c\nfit1a (df = 20)                  \nfit1b (df = 20) TRUE             \nfit1c (df = 20) TRUE  TRUE       \n\n\nTo quickly compare the parameter estimates across model identification options, we can use the group_by_models() function from the semhelpinghands package:\n\ngroup_by_models(list(\"marker\" = fit1a, \n                     \"variance\" = fit1b,\n                     \"effect\" = fit1c))\n\n    lhs op  rhs est_marker est_variance est_effect\n1  CogA =~   gc      0.659        1.265      0.699\n2  CogA =~   hm      1.000        1.921      1.060\n3  CogA =~   ma      0.883        1.696      0.936\n4  CogA =~   nr      0.636        1.221      0.674\n5  CogA =~   ps      1.166        2.240      1.237\n6  CogA =~   sm      1.433        2.752      1.519\n7  CogA =~   tr      0.963        1.850      1.021\n8  CogA =~   wo      0.805        1.547      0.854\n9  CogA ~~ CogA      3.690        1.000      3.282\n10   gc ~~   gc      5.652        5.652      5.652\n11   hm ~~   hm      7.812        7.812      7.812\n12   ma ~~   ma      4.925        4.925      4.925\n13   nr ~~   nr      4.240        4.240      4.240\n14   ps ~~   ps      3.936        3.936      3.936\n15   sm ~~   sm      9.979        9.979      9.979\n16   tr ~~   tr      3.831        3.831      3.831\n17   wo ~~   wo      5.975        5.975      5.975\n\n\nA nice way to confirm that the models are identical is to compare the standardized estimates across the different options:\n\ngroup_by_models(list(\"marker\" = fit1a,\n                     \"variance\" = fit1b,\n                     \"effect\" = fit1c),\n                use_standardizedSolution = TRUE, \n                col_names = \"est.std\")\n\n    lhs op  rhs est.std_marker est.std_variance est.std_effect\n1  CogA =~   gc          0.470            0.470          0.470\n2  CogA =~   hm          0.566            0.566          0.566\n3  CogA =~   ma          0.607            0.607          0.607\n4  CogA =~   nr          0.510            0.510          0.510\n5  CogA =~   ps          0.749            0.749          0.749\n6  CogA =~   sm          0.657            0.657          0.657\n7  CogA =~   tr          0.687            0.687          0.687\n8  CogA =~   wo          0.535            0.535          0.535\n9  CogA ~~ CogA          1.000            1.000          1.000\n10   gc ~~   gc          0.779            0.779          0.779\n11   hm ~~   hm          0.679            0.679          0.679\n12   ma ~~   ma          0.631            0.631          0.631\n13   nr ~~   nr          0.740            0.740          0.740\n14   ps ~~   ps          0.440            0.440          0.440\n15   sm ~~   sm          0.569            0.569          0.569\n16   tr ~~   tr          0.528            0.528          0.528\n17   wo ~~   wo          0.714            0.714          0.714\n\n\n\n\nModel Evaluation\nHere, we will follow the steps described in the textbook.\n\nGlobal Fit\nFirst, we will test the exact fit of the model to the data using the Chi-square model test. We can find this statistic by including fit.measures = T in the summary() function and finding the section labeled Model Test User Model. Note that I also set estimates = F, so that the parameter estimates are not included in the output (mostly to reduce the length of the output):\n\nsummary(fit1a, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 36 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        16\n\n  Number of observations                           200\n\nModel Test User Model:\n                                                      \n  Test statistic                               105.427\n  Degrees of freedom                                20\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               498.336\n  Degrees of freedom                                28\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.818\n  Tucker-Lewis Index (TLI)                       0.746\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3812.592\n  Loglikelihood unrestricted model (H1)      -3759.878\n                                                      \n  Akaike (AIC)                                7657.183\n  Bayesian (BIC)                              7709.956\n  Sample-size adjusted Bayesian (SABIC)       7659.267\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.146\n  90 Percent confidence interval - lower         0.119\n  90 Percent confidence interval - upper         0.174\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.084\n\n\nWhat does the Chi-square test tell us about the exact fit of this model?\n\n\nLocal Fit\nTo identify where the friction between the data and the model might be, we can look at local fit using the covariance residuals. It can be helpful to compare results across different methods, so we will use the normalized residuals and the correlation residuals:\n\nresiduals(fit1a, type = \"normalized\")\n\n$type\n[1] \"normalized\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  1.331  0.000                                          \nwo  0.629  4.667  0.000                                   \ngc -0.777 -1.823 -1.274  0.000                            \ntr -0.930 -1.098 -1.050  0.757  0.000                     \nsm  0.367 -0.613 -0.970 -0.117  0.240  0.000              \nma  0.608  0.138 -0.334  0.334  0.038  0.147  0.000       \nps -0.448 -1.249 -0.402  0.890  0.804  0.230 -0.450  0.000\n\nresiduals(fit1a, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  0.101  0.000                                          \nwo  0.047  0.397  0.000                                   \ngc -0.056 -0.130 -0.091  0.000                            \ntr -0.069 -0.080 -0.077  0.057  0.000                     \nsm  0.028 -0.045 -0.071 -0.009  0.019  0.000              \nma  0.046  0.010 -0.025  0.025  0.003  0.011  0.000       \nps -0.034 -0.092 -0.030  0.068  0.066  0.018 -0.035  0.000\n\n\nWhat patterns can you see in the covariance residuals? Do you think a different CFA would be more appropriate?"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#two-correlated-factors-cfa",
    "href": "confirmatoryfactoranalysis.html#two-correlated-factors-cfa",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.4 Two Correlated Factors CFA",
    "text": "5.4 Two Correlated Factors CFA\nLets examine the hypothesis that there are two correlated factors underlying the KABC subtests.\n\nModel (re)Specification and Estimation\nWhen we specify a two-facor CFA in lavaan we don’t need to include the covariance between the factors in the syntax; it will be included automatically. So, all we need to do is specify the two factors:\n\nmod2 &lt;- '\nSequent =~ hm + nr + wo\nSimult =~ gc + tr + sm + ma + ps\n'\n\nWe can estimate the model and save it in fit2a:\n\nfit2a &lt;- cfa(model = mod2, data = kabc)\n\n\n\nModel Evaluation\nWe will use the same sources of information to evaluate the fit of this modified model.\n\nGlobal Fit\n\nsummary(fit2a, fit.measures = T,  estimates = F)\n\nlavaan 0.6.17 ended normally after 43 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        17\n\n  Number of observations                           200\n\nModel Test User Model:\n                                                      \n  Test statistic                                38.325\n  Degrees of freedom                                19\n  P-value (Chi-square)                           0.005\n\nModel Test Baseline Model:\n\n  Test statistic                               498.336\n  Degrees of freedom                                28\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.959\n  Tucker-Lewis Index (TLI)                       0.939\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3779.041\n  Loglikelihood unrestricted model (H1)      -3759.878\n                                                      \n  Akaike (AIC)                                7592.082\n  Bayesian (BIC)                              7648.153\n  Sample-size adjusted Bayesian (SABIC)       7594.295\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.071\n  90 Percent confidence interval - lower         0.038\n  90 Percent confidence interval - upper         0.104\n  P-value H_0: RMSEA &lt;= 0.050                    0.132\n  P-value H_0: RMSEA &gt;= 0.080                    0.358\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.072\n\n\nWhat does the Chi-square test tell us about the exact fit of this model?\n\n\nLocal Fit\nWe can examine to what extend new factor structure addressed local fit issues:\n\nresiduals(fit2a, type = \"normalized\")\n\n$type\n[1] \"normalized\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr -0.144  0.000                                          \nwo -0.687  0.209  0.000                                   \ngc  0.981 -1.631 -0.927  0.000                            \ntr  1.603 -0.772 -0.502  0.194  0.000                     \nsm  2.869 -0.066 -0.208 -0.405 -0.084  0.000              \nma  2.996  0.751  0.479  0.194 -0.092  0.318  0.000       \nps  2.289 -0.833  0.241  0.350  0.148 -0.036 -0.516  0.000\n\nresiduals(fit2a, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr -0.011  0.000                                          \nwo -0.051  0.018  0.000                                   \ngc  0.071 -0.116 -0.066  0.000                            \ntr  0.119 -0.057 -0.037  0.015  0.000                     \nsm  0.219 -0.005 -0.015 -0.030 -0.007  0.000              \nma  0.227  0.056  0.035  0.014 -0.007  0.024  0.000       \nps  0.174 -0.061  0.018  0.027  0.012 -0.003 -0.040  0.000\n\n\nWhat patterns can you see in the covariance residuals? What path could we add to the model?"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#model-comparison",
    "href": "confirmatoryfactoranalysis.html#model-comparison",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.5 Model Comparison",
    "text": "5.5 Model Comparison\nWe can also use the Chi-square difference test to compare the original and modified CFA to each other. Here, the original one-factor CFA model is more constrained and the modified two-factor CFA model is less constrained. Here, a significant Chi-square difference indicates that the more constrained one-factor model fits significantly worse than the two-factor model. We can use the compareFit() function from the semTools package to compare the models using the Chi-square difference test:\n\ncomp12 &lt;- compareFit(fit1a, fit2a)\nsummary(comp12)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n      Df    AIC    BIC   Chisq Chisq diff  RMSEA Df diff Pr(&gt;Chisq)    \nfit2a 19 7592.1 7648.2  38.325                                         \nfit1a 20 7657.2 7710.0 105.427     67.102 0.5749       1  2.578e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n         chisq df pvalue rmsea   cfi   tli  srmr       aic       bic\nfit2a  38.325† 19   .005 .071† .959† .939† .072† 7592.082† 7648.153†\nfit1a 105.427  20   .000 .146  .818  .746  .084  7657.183  7709.956 \n\n################## Differences in Fit Indices #######################\n              df rmsea    cfi    tli  srmr    aic    bic\nfit1a - fit2a  1 0.075 -0.141 -0.194 0.011 65.102 61.804\n\n\nDoes the less constrained two-factor model result in an improvement in global fit?"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#introducing-cross-loadings-or-residual-covariances",
    "href": "confirmatoryfactoranalysis.html#introducing-cross-loadings-or-residual-covariances",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.6 Introducing Cross-Loadings or Residual Covariances",
    "text": "5.6 Introducing Cross-Loadings or Residual Covariances\nEven though the two-factor CFA fits better than the one-factor CFA, it’s Model Chi-square test is still significant, indicating that it is not an exact fit to the data. We can use the local fit information to help us decide what kind of theory-informed alterations might be reasonable to add. One option is to include a cross-loading of Hand Movements (which has its main loading on the Sequential factor): The task requires exact reproduction of a sequence of hand movements performed by the examiner, but there is also a clear visual-spatial component to the task that could reflect simultaneous processing. A second option is to include a residual covariance between Number Recall and Word Order. It might be that both these tasks require memorization, which may not be a component that they share with Hand Movements.\n\nModel (re)Specification and Estimation\nFor the purpose of this lab, we will add the cross-loading:\n\nmod3 &lt;- '\nSequent =~ hm + nr + wo\nSimult =~ gc + tr + sm + ma + ps + hm \n'\n\nWe can estimate the model and save it in fit3a:\n\nfit3a &lt;- cfa(model = mod3, data = kabc)\n\n\n\nModel Evaluation\nWe will use the same sources of information to evaluate the fit of this modified model.\n\nGlobal Fit\n\nsummary(fit3a, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 49 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           200\n\nModel Test User Model:\n                                                      \n  Test statistic                                18.108\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.449\n\nModel Test Baseline Model:\n\n  Test statistic                               498.336\n  Degrees of freedom                                28\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3768.932\n  Loglikelihood unrestricted model (H1)      -3759.878\n                                                      \n  Akaike (AIC)                                7573.864\n  Bayesian (BIC)                              7633.234\n  Sample-size adjusted Bayesian (SABIC)       7576.208\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.005\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.063\n  P-value H_0: RMSEA &lt;= 0.050                    0.859\n  P-value H_0: RMSEA &gt;= 0.080                    0.008\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.035\n\n\nWhat does the Chi-square test tell us about the exact fit of this model?\n\n\nLocal Fit\n\nresiduals(fit3a, type = \"normalized\")\n\n$type\n[1] \"normalized\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  0.270  0.000                                          \nwo -0.270  0.000  0.000                                   \ngc -0.688 -1.380 -0.678  0.000                            \ntr -0.713 -0.395 -0.130  0.286  0.000                     \nsm  0.706  0.169  0.026 -0.443 -0.099  0.000              \nma  1.044  0.955  0.682  0.154 -0.115  0.155  0.000       \nps -0.181 -0.457  0.606  0.418  0.280 -0.091 -0.577  0.000\n\nresiduals(fit3a, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  0.020  0.000                                          \nwo -0.020  0.000  0.000                                   \ngc -0.050 -0.098 -0.049  0.000                            \ntr -0.053 -0.029 -0.010  0.022  0.000                     \nsm  0.054  0.012  0.002 -0.033 -0.008  0.000              \nma  0.079  0.071  0.050  0.011 -0.009  0.012  0.000       \nps -0.014 -0.034  0.046  0.032  0.023 -0.007 -0.044  0.000\n\n\nWhat patterns can you see in the covariance residuals? Do we need to consider any more adjustments?\n\n\n\nModel Comparison\n\ncomp23 &lt;- compareFit(fit3a, fit2a)\nsummary(comp23)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n      Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit3a 18 7573.9 7633.2 18.108                                          \nfit2a 19 7592.1 7648.2 38.325     20.217 0.30998       1  6.913e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n        chisq df pvalue rmsea    cfi    tli  srmr       aic       bic\nfit3a 18.108† 18   .449 .005† 1.000† 1.000† .035† 7573.864† 7633.234†\nfit2a 38.325  19   .005 .071   .959   .939  .072  7592.082  7648.153 \n\n################## Differences in Fit Indices #######################\n              df rmsea    cfi   tli  srmr    aic    bic\nfit2a - fit3a  1 0.066 -0.041 -0.06 0.037 18.217 14.919\n\n\nDoes the modified (less constrained) model result in an improvement in global fit?"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#approximate-fit-indices",
    "href": "confirmatoryfactoranalysis.html#approximate-fit-indices",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.7 Approximate Fit Indices",
    "text": "5.7 Approximate Fit Indices\nSo far, we have ignored the approximate fit indices that are reported by lavaan. We can get a quick overview of these indices across the three main models we have specified by using the compareFit function:\n\ncomp123 &lt;- compareFit(fit3a, fit2a, fit1a)\nsummary(comp123)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n      Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit3a 18 7573.9 7633.2  18.108                                          \nfit2a 19 7592.1 7648.2  38.325     20.217 0.30998       1  6.913e-06 ***\nfit1a 20 7657.2 7710.0 105.427     67.102 0.57490       1  2.578e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n         chisq df pvalue rmsea    cfi    tli  srmr       aic       bic\nfit3a  18.108† 18   .449 .005† 1.000† 1.000† .035† 7573.864† 7633.234†\nfit2a  38.325  19   .005 .071   .959   .939  .072  7592.082  7648.153 \nfit1a 105.427  20   .000 .146   .818   .746  .084  7657.183  7709.956 \n\n################## Differences in Fit Indices #######################\n              df rmsea    cfi    tli  srmr    aic    bic\nfit2a - fit3a  1 0.066 -0.041 -0.060 0.037 18.217 14.919\nfit1a - fit2a  1 0.075 -0.141 -0.194 0.011 65.102 61.804\n\n\nThe second table in the output includes commonly reported indices of approximate fit (e.g., RMSEA, CFI, SRMR).\nTake a closer look at these indices across the three models and determine for each model if it fit well (a) approximately or (b) exactly."
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#estimate-interpretation",
    "href": "confirmatoryfactoranalysis.html#estimate-interpretation",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.8 Estimate Interpretation",
    "text": "5.8 Estimate Interpretation\nNow that we’ve completed the model respecification cycle, we can interpret the results of our final model. First, we can look at the (unstandardized) parameter estimates:\n\nsummary(fit3a, std = T, rsquare = T)\n\nlavaan 0.6.17 ended normally after 49 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           200\n\nModel Test User Model:\n                                                      \n  Test statistic                                18.108\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.449\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  Sequent =~                                                            \n    hm                1.000                               0.857    0.253\n    nr                2.285    0.777    2.941    0.003    1.958    0.818\n    wo                2.767    0.941    2.939    0.003    2.370    0.819\n  Simult =~                                                             \n    gc                1.000                               1.345    0.500\n    tr                1.436    0.228    6.307    0.000    1.932    0.717\n    sm                2.074    0.340    6.095    0.000    2.790    0.666\n    ma                1.241    0.215    5.762    0.000    1.670    0.598\n    ps                1.727    0.266    6.500    0.000    2.324    0.777\n    hm                0.986    0.248    3.979    0.000    1.326    0.391\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  Sequent ~~                                                            \n    Simult            0.587    0.231    2.546    0.011    0.510    0.510\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .hm                7.851    0.845    9.291    0.000    7.851    0.683\n   .nr                1.899    0.487    3.896    0.000    1.899    0.331\n   .wo                2.750    0.713    3.856    0.000    2.750    0.329\n   .gc                5.444    0.585    9.297    0.000    5.444    0.750\n   .tr                3.521    0.457    7.702    0.000    3.521    0.485\n   .sm                9.767    1.179    8.287    0.000    9.767    0.556\n   .ma                5.013    0.569    8.815    0.000    5.013    0.643\n   .ps                3.554    0.529    6.718    0.000    3.554    0.397\n    Sequent           0.734    0.490    1.499    0.134    1.000    1.000\n    Simult            1.810    0.526    3.444    0.001    1.000    1.000\n\nR-Square:\n                   Estimate\n    hm                0.317\n    nr                0.669\n    wo                0.671\n    gc                0.250\n    tr                0.515\n    sm                0.444\n    ma                0.357\n    ps                0.603\n\n\nThe unstandardized estimates are mostly used to evaluate significance of the different parameter estimates. When using CFA, the focus is typically on interpreting the standardized estimates. Standardized factor loadings’ interpretation depends on whether an indicator loads on one or multiple factors.\n\nOne factor loading: can be interpreted as Pearson correlations between the indicators and their factor.\nMultiple factor (cross)loadings: can be interpreted as standardized regression estimates, indicating the expected change in the indicator in standard deviation units, for a one standard deviation increase in factor A, holding factor B constant.\n\nIn the code above, we also requested R-squared estimates (rsquare = T). Ideally, factors should explain at least half of the variance in continuous indicators (R-square = .50), that would be excellent. Values near .40 are very good, near .30 are good, near .20 are fair, and near .10 are poor. What kind of R-square is acceptable depends on the purpose that the latent factor will be used for. If the factors are used to make high-stakes decisions you’d want the indicators to share a lot of common variance, which means higher R-squareds."
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#reliability-based-on-factor-models",
    "href": "confirmatoryfactoranalysis.html#reliability-based-on-factor-models",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.9 Reliability based on factor models",
    "text": "5.9 Reliability based on factor models\nWe can estimate the reliability/internal consistency with Coefficient omega, which can be interpreted in a similar manner as Cronbach’s alpha, but takes into account that the indicators are caused by a shared common factor with differing degrees of association (i.e., different factor loadings). We can use the compRelSEM() function from the semTools package to compute coefficient Omega:\n\ncompRelSEM(fit3a)\n\nSequent  Simult \n  0.559   0.737 \n\n\nHow would you interpret the reliability of these two factors?"
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#summary",
    "href": "confirmatoryfactoranalysis.html#summary",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.10 Summary",
    "text": "5.10 Summary\nIn this R lab, you were introduced to the steps involved in specifying, estimating, evaluating, comparing and interpreting the results of confirmatory factor analyses. Below, you’ll find a Bonus section that demonstrates how to include a residual covariance in a CFA model. In the next R Lab, you will learn all about structural equation modeling, combining the power of path analyses and CFAs."
  },
  {
    "objectID": "confirmatoryfactoranalysis.html#bonus-adding-a-residual-covariance",
    "href": "confirmatoryfactoranalysis.html#bonus-adding-a-residual-covariance",
    "title": "5  Confirmatory Factor Analysis",
    "section": "5.11 Bonus: Adding a residual covariance",
    "text": "5.11 Bonus: Adding a residual covariance\nTo add a residual covariance between two indicators, we use the ~~ operator:\n\nmod4 &lt;- '\nSequent =~ hm + nr + wo\nSimult =~ gc + tr + sm + ma + ps \n\nnr ~~ wo\n'\n\nWe can estimate the model and save it in fit4a:\n\nfit4a &lt;- cfa(model = mod4, data = kabc)\n\n\nModel Evaluation\n\nGlobal Fit\n\nsummary(fit4a, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 57 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           200\n\nModel Test User Model:\n                                                      \n  Test statistic                                18.108\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.449\n\nModel Test Baseline Model:\n\n  Test statistic                               498.336\n  Degrees of freedom                                28\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -3768.932\n  Loglikelihood unrestricted model (H1)      -3759.878\n                                                      \n  Akaike (AIC)                                7573.864\n  Bayesian (BIC)                              7633.234\n  Sample-size adjusted Bayesian (SABIC)       7576.208\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.005\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.063\n  P-value H_0: RMSEA &lt;= 0.050                    0.859\n  P-value H_0: RMSEA &gt;= 0.080                    0.008\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.035\n\n\n\n\nLocal Fit\n\nresiduals(fit4a, type = \"normalized\")\n\n$type\n[1] \"normalized\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  0.270  0.000                                          \nwo -0.271  0.000  0.000                                   \ngc -0.688 -1.380 -0.678  0.000                            \ntr -0.713 -0.395 -0.130  0.286  0.000                     \nsm  0.706  0.169  0.026 -0.443 -0.099  0.000              \nma  1.044  0.955  0.682  0.154 -0.115  0.155  0.000       \nps -0.181 -0.457  0.606  0.418  0.280 -0.091 -0.577  0.000\n\nresiduals(fit4a, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       hm     nr     wo     gc     tr     sm     ma     ps\nhm  0.000                                                 \nnr  0.020  0.000                                          \nwo -0.020  0.000  0.000                                   \ngc -0.050 -0.098 -0.049  0.000                            \ntr -0.053 -0.029 -0.010  0.022  0.000                     \nsm  0.054  0.012  0.002 -0.033 -0.008  0.000              \nma  0.079  0.071  0.050  0.011 -0.009  0.012  0.000       \nps -0.014 -0.034  0.046  0.032  0.023 -0.007 -0.044  0.000\n\n\n\n\n\nModel Comparison\n\ncomp24 &lt;- compareFit(fit4a, fit2a)\nsummary(comp24)\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n      Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit4a 18 7573.9 7633.2 18.108                                          \nfit2a 19 7592.1 7648.2 38.325     20.217 0.30998       1  6.913e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n        chisq df pvalue rmsea    cfi    tli  srmr       aic       bic\nfit4a 18.108† 18   .449 .005† 1.000† 1.000† .035† 7573.864† 7633.234†\nfit2a 38.325  19   .005 .071   .959   .939  .072  7592.082  7648.153 \n\n################## Differences in Fit Indices #######################\n              df rmsea    cfi   tli  srmr    aic    bic\nfit2a - fit4a  1 0.066 -0.041 -0.06 0.037 18.217 14.919\n\n\n\n\nEstimate Interpretation\nTake a look at the estimates and note the differences in standardized estimates and R-squared across the two models (with cross-loading or with residual covariance).\n\nsummary(fit4a, std = T, rsquare = T)\n\nlavaan 0.6.17 ended normally after 57 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           200\n\nModel Test User Model:\n                                                      \n  Test statistic                                18.108\n  Degrees of freedom                                18\n  P-value (Chi-square)                           0.449\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  Sequent =~                                                            \n    hm                1.000                               2.303    0.679\n    nr                0.566    0.107    5.284    0.000    1.303    0.544\n    wo                0.685    0.129    5.292    0.000    1.578    0.545\n  Simult =~                                                             \n    gc                1.000                               1.345    0.500\n    tr                1.436    0.228    6.307    0.000    1.932    0.717\n    sm                2.074    0.340    6.095    0.000    2.790    0.666\n    ma                1.241    0.215    5.762    0.000    1.670    0.598\n    ps                1.727    0.266    6.500    0.000    2.324    0.777\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .nr ~~                                                                 \n   .wo                2.584    0.516    5.007    0.000    2.584    0.531\n  Sequent ~~                                                            \n    Simult            2.372    0.504    4.703    0.000    0.766    0.766\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .hm                6.200    1.070    5.792    0.000    6.200    0.539\n   .nr                4.033    0.509    7.922    0.000    4.033    0.704\n   .wo                5.879    0.743    7.912    0.000    5.879    0.703\n   .gc                5.444    0.585    9.297    0.000    5.444    0.750\n   .tr                3.521    0.457    7.702    0.000    3.521    0.485\n   .sm                9.767    1.179    8.287    0.000    9.767    0.556\n   .ma                5.013    0.569    8.815    0.000    5.013    0.643\n   .ps                3.554    0.529    6.718    0.000    3.554    0.397\n    Sequent           5.302    1.304    4.066    0.000    1.000    1.000\n    Simult            1.810    0.526    3.444    0.001    1.000    1.000\n\nR-Square:\n                   Estimate\n    hm                0.461\n    nr                0.296\n    wo                0.297\n    gc                0.250\n    tr                0.515\n    sm                0.444\n    ma                0.357\n    ps                0.603\n\n\n\n\nReliability based on factor models\n\ncompRelSEM(fit4a)\n\nSequent  Simult \n  0.559   0.790"
  },
  {
    "objectID": "sem.html#loading-r-packages",
    "href": "sem.html#loading-r-packages",
    "title": "6  Structural Equation Modeling",
    "section": "6.1 Loading R packages",
    "text": "6.1 Loading R packages\nLoad the required packages for this lab into your R environment.\n\nlibrary(rio)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(modsem)"
  },
  {
    "objectID": "sem.html#loading-data",
    "href": "sem.html#loading-data",
    "title": "6  Structural Equation Modeling",
    "section": "6.2 Loading Data",
    "text": "6.2 Loading Data\nLoad the data into your environment. For this lab we will use a dataset based on N = 441 children whose caregivers completed a survey about family environment and child behavior. You can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/projectkids.csv. Make sure to save it in the folder you are using for this class.\nThe full dataset and more information about this project can be found here: https://www.ldbase.org/datasets/72ab9852-8ebc-4ba0-bb1f-5f1c347e2572.\n\nkids &lt;- read.csv(\"data/projectkids.csv\")\n\nThe dataset includes item responses to 5 Reading Problem items from the Colorado Learning Disability Questionnaire (CLDQ; rated on five-point scale from never to always), 9 Attention items from the The Strengths and Weaknesses of ADHD Symptoms and Normal Behavior Scale (SWAN; rated on a seven-point scale from far below to far above average), and a composite, mean score of the Homework Problems Checklist (based on 19 items, rated on a four-point scale from never to very often).\nHere are some example items from each scale:\nCLDQ Reading Problems (item stem: Decide how well each statement describes your child):\n\nQ1: Does/did your child have difficulty with spelling?\nQ5: Does/did your child read below grade or expectancy level?\nQ6: Does/did your child require extra help in school because of problems in reading and spelling?\n\nSWAN Attention Items (item stem: How does your child compare to other children of the same age?):\n\nQ1: Gives close attention to detail and avoids careless mistakes\nQ2: Sustains attention on tasks or play activities\nQ3: Listens when spoken to directly\nQ5: Organizes tasks and activities\n\nHPC Items (item stem: Circle the best answer that best describes your child’s homework habits):\n\nQ1: Fails to bring home assignments and materials\nQ4: Refuses to do homework assignment\nQ6: Must be reminded to sit down and start homework\nQ12: Easily frustrated by homework assignments\n\nThe hypothesis we want to test is whether there is an indirect effect of Attention, via Homework problems (or lack thereof), on Reading Problems. In other words, do kids with higher levels of attention experience fewer homework problems, which in turn is associated with fewer reading problems?"
  },
  {
    "objectID": "sem.html#data-exploration",
    "href": "sem.html#data-exploration",
    "title": "6  Structural Equation Modeling",
    "section": "6.3 Data Exploration",
    "text": "6.3 Data Exploration\nBefore analyzing the data, we can look at the distribution of the variables to see if they follow a normal distribution (one of the main assumptions of the ML estimator that lavaan uses by default) or if we can see skew in the distributions.\n\nkids %&gt;%\n  pivot_longer(everything()) %&gt;%\n  ggplot(aes(x=value)) +\n  geom_histogram() + \n  facet_wrap(vars(name), scales = \"free\")\n\n\n\n\nDo the histograms look “normal” enough? What can we do if there are issues with normality?\nPackage semTools includes a set of functions to evaluate the skew and kurtosis of observed variables:\n\n# Univariate skew and kurtosis\napply(kids, 2, skew)\n\n             cldq_1     cldq_2     cldq_4     cldq_5     cldq_6     swan_1\nskew (g1) 0.9726340  2.7834505  1.6533033  1.6591248  1.6700060 -0.0384075\nse        0.1167748  0.1166424  0.1166424  0.1167748  0.1166424  0.1235604\nz         8.3291402 23.8631175 14.1741228 14.2078958 14.3173193 -0.3108398\np         0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.7559224\n               swan_2     swan_3      swan_4      swan_5      swan_6     swan_7\nskew (g1) -0.28474452 -0.1664108 -0.08387429 -0.09631494 -0.25689087 -0.1524466\nse         0.12403473  0.1235604  0.12371791  0.12324720  0.12356041  0.1237179\nz         -2.29568375 -1.3467971 -0.67794785 -0.78147772 -2.07907099 -1.2322114\np          0.02169397  0.1780456  0.49780476  0.43452158  0.03761083  0.2178701\n               swan_8      swan_9   hpc_mean\nskew (g1) -0.02334995 -0.07898916  1.4079328\nse         0.12356041  0.12340351  0.1166424\nz         -0.18897595 -0.64008847 12.0705092\np          0.85011167  0.52211509  0.0000000\n\napply(kids, 2, kurtosis)\n\n                   cldq_1     cldq_2       cldq_4       cldq_5       cldq_6\nExcess Kur (g2) 0.2298165  7.5171117 1.660876e+00 1.464507e+00 1.488210e+00\nse              0.2335497  0.2332847 2.332847e-01 2.335497e-01 2.332847e-01\nz               0.9840156 32.2229039 7.119522e+00 6.270642e+00 6.379370e+00\np               0.3251078  0.0000000 1.082912e-12 3.595619e-10 1.778178e-10\n                     swan_1     swan_2      swan_3       swan_4      swan_5\nExcess Kur (g2) -0.51524242 -0.2199770 -0.45229948 -0.678691670 -0.62596197\nse               0.24712083  0.2480695  0.24712083  0.247435830  0.24649441\nz               -2.08498181 -0.8867558 -1.83027667 -2.742899730 -2.53945709\np                0.03707095  0.3752104  0.06720858  0.006089928  0.01110247\n                    swan_6      swan_7     swan_8     swan_9  hpc_mean\nExcess Kur (g2) -0.3902963 -0.61695200 -0.3109368 -0.3559437 1.9502122\nse               0.2471208  0.24743583  0.2471208  0.2468070 0.2332847\nz               -1.5793745 -2.49338182 -1.2582379 -1.4421946 8.3597932\np                0.1142502  0.01265327  0.2083057  0.1492475 0.0000000\n\n\nWhich variables are significantly skewed? And which have significant issues with kurtosis?"
  },
  {
    "objectID": "sem.html#measurement-model",
    "href": "sem.html#measurement-model",
    "title": "6  Structural Equation Modeling",
    "section": "6.4 Measurement Model",
    "text": "6.4 Measurement Model\nIn the first step of model estimation, we will specify a CFA with all measured constructs and covariances between all factors. For the HPC mean score, we can specify a single-indicator factor. To do so, we need some estimate of reliability. This checklist is a highly reliable scale with a previously found Cronbach’s alpha of .96 (to be honest, this may mean that many of the items have so much overlap that the measured construct is quite narrow in its operational definition). Next, we need to know the variance in the HPC mean score in our sample, and then use the appropriate formula to compute the residual variance estimate:\n\nvar(kids$hpc_mean)\n\n[1] 0.3928782\n\n# residual = (1 - .96) * 0.393\n(1 - .96) * 0.393\n\n[1] 0.01572\n\n\nNext, we can specify and estimate the full measurement model. As some of the observed variables are skewed, we will use the mlr estimator. In addition, our data contain some missing values. For this lab, we will assume that these data are missing at random (MAR) and us full information maximum likelihood (fiml) to still use all available data.\n\n\n\n\n\n\nNote\n\n\n\nWhen using mlr, we get additional versions of approximate fit indices. Use the robust version if available, otherwise use the scaled version.\n\n\n\nbig_cfa &lt;- '\nreadprob =~ cldq_1 + cldq_2 + cldq_4 + cldq_5 + cldq_6\nattention =~ swan_1 + swan_2 + swan_3 + swan_4 + swan_5 + swan_6 + \n             swan_7 + swan_8 + swan_9\n             \nhwp =~ 1*hpc_mean\nhpc_mean ~~ 0.01572*hpc_mean\n'\n\nfit_cfa &lt;- cfa(big_cfa, kids, \n               estimator = \"mlr\", \n               missing = \"fiml\")\n\nsummary(fit_cfa, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 65 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        47\n\n  Number of observations                           441\n  Number of missing patterns                        13\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               294.259     214.704\n  Degrees of freedom                                88          88\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.371\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              5812.658    3750.370\n  Degrees of freedom                               105         105\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.550\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.964       0.965\n  Tucker-Lewis Index (TLI)                       0.957       0.959\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.968\n  Robust Tucker-Lewis Index (TLI)                            0.962\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -7407.271   -7407.271\n  Scaling correction factor                                  1.639\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -7260.142   -7260.142\n  Scaling correction factor                                  1.464\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               14908.542   14908.542\n  Bayesian (BIC)                             15100.727   15100.727\n  Sample-size adjusted Bayesian (SABIC)      14951.571   14951.571\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.073       0.057\n  90 Percent confidence interval - lower         0.064       0.049\n  90 Percent confidence interval - upper         0.082       0.065\n  P-value H_0: RMSEA &lt;= 0.050                    0.000       0.076\n  P-value H_0: RMSEA &gt;= 0.080                    0.106       0.000\n                                                                  \n  Robust RMSEA                                               0.070\n  90 Percent confidence interval - lower                     0.059\n  90 Percent confidence interval - upper                     0.082\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.003\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.089\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.034       0.034\n\n\nWhat does the chi-square test of model fit tell us?\nWe will also use local fit information to give us more insight into the fit of our measurement model.\n\nresiduals(fit_cfa, type = \"cor.bollen\")$cov\n\n         cldq_1 cldq_2 cldq_4 cldq_5 cldq_6 swan_1 swan_2 swan_3 swan_4 swan_5\ncldq_1    0.000                                                               \ncldq_2    0.078  0.000                                                        \ncldq_4    0.034  0.028  0.000                                                 \ncldq_5   -0.056 -0.024 -0.002  0.000                                          \ncldq_6   -0.020 -0.021 -0.010  0.023  0.000                                   \nswan_1   -0.095  0.021 -0.009 -0.056 -0.051  0.000                            \nswan_2   -0.031  0.051  0.028 -0.009 -0.002  0.064  0.000                     \nswan_3    0.031  0.100  0.059  0.011  0.005  0.013  0.065  0.000              \nswan_4   -0.017  0.078  0.061  0.001 -0.008 -0.026  0.001  0.050  0.000       \nswan_5   -0.054  0.061  0.065  0.005  0.004 -0.008 -0.035 -0.063  0.023  0.000\nswan_6   -0.069  0.010 -0.018 -0.094 -0.067  0.008  0.008 -0.029 -0.014  0.012\nswan_7    0.000  0.084  0.071 -0.004 -0.016 -0.029 -0.034 -0.031 -0.006  0.045\nswan_8   -0.057  0.028  0.036 -0.029 -0.023 -0.017  0.011 -0.004 -0.035  0.002\nswan_9   -0.039  0.015  0.047 -0.034 -0.037  0.001 -0.020  0.018  0.014 -0.022\nhpc_mean  0.065 -0.021 -0.040 -0.003  0.025 -0.028  0.013  0.042 -0.002  0.001\n         swan_6 swan_7 swan_8 swan_9 hpc_mn\ncldq_1                                     \ncldq_2                                     \ncldq_4                                     \ncldq_5                                     \ncldq_6                                     \nswan_1                                     \nswan_2                                     \nswan_3                                     \nswan_4                                     \nswan_5                                     \nswan_6    0.000                            \nswan_7    0.004  0.000                     \nswan_8    0.036  0.004  0.000              \nswan_9   -0.010  0.021 -0.002  0.000       \nhpc_mean  0.036 -0.009 -0.042  0.000  0.000\n\n\nNone of the correlation residuals are &gt; |.10|, indicating that remaining misfit might be trivial. Note that many people (including you), may stop at this point and continue to specify the structural model. However, this is a lab, so I want to show you some strategies for mindful model adjustment.\nThe approximate fit indices (especially RMSEA) indicate that global fit is not (approximately) amazing. I will use the modification indices to see if there are any parameters that, when added to the model, would meaningfully improve model fit. To ensure that we don’t get distracted by trivial options, we can add a somewhat large minimum.value with which the model Chi-square needs to improve for a parameter to be included in the output.\n\nmodindices(fit_cfa, sort. = TRUE, minimum.value = 15)\n\n       lhs op    rhs     mi    epc sepc.lv sepc.all sepc.nox\n145 swan_1 ~~ swan_2 29.330  0.169   0.169    0.311    0.311\n176 swan_5 ~~ swan_7 25.010  0.167   0.167    0.303    0.303\n163 swan_3 ~~ swan_5 22.381 -0.179  -0.179   -0.267   -0.267\n124 cldq_5 ~~ cldq_6 21.551  0.121   0.121    0.428    0.428\n87  cldq_1 ~~ cldq_5 17.822 -0.110  -0.110   -0.248   -0.248\n162 swan_3 ~~ swan_4 17.421  0.135   0.135    0.242    0.242\n154 swan_2 ~~ swan_3 17.308  0.144   0.144    0.231    0.231\n\n\nThe largest modification index is associated with the residual covariance between the first two items of the SWAN (measuring attention). Both of these items contain the word ‘attention’ (see above), whereas none of the other items on this subscale contain that word. Thus, it may be reasonable that parents respond very similarly to these items because they share more in common than they do with the other items on the subscale."
  },
  {
    "objectID": "sem.html#improving-the-measurement-model",
    "href": "sem.html#improving-the-measurement-model",
    "title": "6  Structural Equation Modeling",
    "section": "6.5 Improving the Measurement Model",
    "text": "6.5 Improving the Measurement Model\nAfter adding this residual covariance to the model, we estimate and evaluate the model again.\n\nbig_cfa2 &lt;- '\nreadprob =~ cldq_1 + cldq_2 + cldq_4 + cldq_5 + cldq_6\nattention =~ swan_1 + swan_2 + swan_3 + swan_4 + swan_5 + swan_6 + \n             swan_7 + swan_8 + swan_9\n             \nhwp =~ 1* hpc_mean\nhpc_mean ~~ 0.01572*hpc_mean\n\nswan_1 ~~ swan_2\n'\n\nfit_cfa2 &lt;- cfa(big_cfa2, kids, \n                estimator = \"mlr\", \n                missing = \"fiml\")\n\nsummary(fit_cfa2, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 73 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        48\n\n  Number of observations                           441\n  Number of missing patterns                        13\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               265.499     195.622\n  Degrees of freedom                                87          87\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.357\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              5812.658    3750.370\n  Degrees of freedom                               105         105\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.550\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.969       0.970\n  Tucker-Lewis Index (TLI)                       0.962       0.964\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.973\n  Robust Tucker-Lewis Index (TLI)                            0.968\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -7392.891   -7392.891\n  Scaling correction factor                                  1.658\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -7260.142   -7260.142\n  Scaling correction factor                                  1.464\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               14881.782   14881.782\n  Bayesian (BIC)                             15078.057   15078.057\n  Sample-size adjusted Bayesian (SABIC)      14925.727   14925.727\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.068       0.053\n  90 Percent confidence interval - lower         0.059       0.045\n  90 Percent confidence interval - upper         0.078       0.062\n  P-value H_0: RMSEA &lt;= 0.050                    0.001       0.259\n  P-value H_0: RMSEA &gt;= 0.080                    0.019       0.000\n                                                                  \n  Robust RMSEA                                               0.065\n  90 Percent confidence interval - lower                     0.053\n  90 Percent confidence interval - upper                     0.077\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.023\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.019\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.034       0.034\n\n\nWe can test if this model is a better fit to our data than the previous model (note that I used @nested here to extract only the Chi-squared difference table).\n\ncomp_12 &lt;- compareFit(fit_cfa, fit_cfa2)\ncomp_12@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n         Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit_cfa2 87 14882 15078 265.50                                  \nfit_cfa  88 14908 15101 294.26     11.369       1  0.0007469 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat does the Chi-square difference test tell us?\nLet’s see if there are any other large modification indices that are meaningfully larger than other modification indices:\n\nmodindices(fit_cfa2, sort. = TRUE, minimum.value = 15)\n\n       lhs op    rhs     mi    epc sepc.lv sepc.all sepc.nox\n163 swan_3 ~~ swan_5 23.062 -0.182  -0.182   -0.273   -0.273\n125 cldq_5 ~~ cldq_6 21.523  0.121   0.121    0.428    0.428\n176 swan_5 ~~ swan_7 20.546  0.150   0.150    0.281    0.281\n154 swan_2 ~~ swan_3 18.952  0.146   0.146    0.225    0.225\n162 swan_3 ~~ swan_4 18.763  0.141   0.141    0.254    0.254\n88  cldq_1 ~~ cldq_5 17.806 -0.110  -0.110   -0.248   -0.248\n\n\nThere are still some modification indices &gt; 15, but the first one does not necessarily make theoretical sense. The suggested modification is to add a residual covariance between SWAN item 3 and 5 (see above for content), but if we look at the epc column (which stands for expected parameter change), it expects that that covariance is going to be negative. A negative residual covariance indicates that there may be an omitted common cause that affects each item in the opposite way. In other words, item 3 and 5 may have less in common than the measurement model predicted. While the content of item 3 and 5 is not extremely similar, they are still both hypothesized to measure attention on this well-validated scale. Thus, adding this residual covariance does not seem theoretically justified. It may just be a peculiarity of our sample.\nThe next set of modification indices have very similar values, thus, at least in statistical terms, there is no real reason to pick one over the other. CLDQ item 5 and 6 (see above) are both about reading problems that have emerged in the school setting (while other questions on this subscale are about reading problems more generally), so there may be theoretical justification to add this residual covariance. In addition, the epc for this modification indicates that the standardized residual correlation (in sepc.all column) between these two items is .43, which can be considered a large correlation. Compared to the next largest modification index, there is more evidence that adding this residual covariance is theoretically justified."
  },
  {
    "objectID": "sem.html#improving-the-measurement-model-round-2",
    "href": "sem.html#improving-the-measurement-model-round-2",
    "title": "6  Structural Equation Modeling",
    "section": "6.6 Improving the Measurement Model (Round 2)",
    "text": "6.6 Improving the Measurement Model (Round 2)\nAfter adding this residual covariance to the model, we estimate and evaluate the model again.\n\nbig_cfa3 &lt;- '\nreadprob =~ cldq_1 + cldq_2 + cldq_4 + cldq_5 + cldq_6\nattention =~ swan_1 + swan_2 + swan_3 + swan_4 + swan_5 + swan_6 + \n             swan_7 + swan_8 + swan_9\n             \nhwp =~ 1* hpc_mean\nhpc_mean ~~ 0.01572*hpc_mean\n\nswan_1 ~~ swan_2\ncldq_5 ~~ cldq_6\n'\n\nfit_cfa3 &lt;- cfa(big_cfa3, kids, \n                estimator = \"mlr\", \n                missing = \"fiml\")\n\nsummary(fit_cfa3, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 66 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        49\n\n  Number of observations                           441\n  Number of missing patterns                        13\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               246.103     184.173\n  Degrees of freedom                                86          86\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.336\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              5812.658    3750.370\n  Degrees of freedom                               105         105\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.550\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.972       0.973\n  Tucker-Lewis Index (TLI)                       0.966       0.967\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.976\n  Robust Tucker-Lewis Index (TLI)                            0.971\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -7383.193   -7383.193\n  Scaling correction factor                                  1.688\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -7260.142   -7260.142\n  Scaling correction factor                                  1.464\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               14864.386   14864.386\n  Bayesian (BIC)                             15064.749   15064.749\n  Sample-size adjusted Bayesian (SABIC)      14909.246   14909.246\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.065       0.051\n  90 Percent confidence interval - lower         0.056       0.042\n  90 Percent confidence interval - upper         0.075       0.060\n  P-value H_0: RMSEA &lt;= 0.050                    0.005       0.422\n  P-value H_0: RMSEA &gt;= 0.080                    0.005       0.000\n                                                                  \n  Robust RMSEA                                               0.062\n  90 Percent confidence interval - lower                     0.049\n  90 Percent confidence interval - upper                     0.074\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.060\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.006\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.036       0.036\n\n\nWe can test if this model is a better fit to our data than the previous model.\n\ncomp_23 &lt;- compareFit(fit_cfa3, fit_cfa2)\ncomp_23@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n         Df   AIC   BIC Chisq Chisq diff Df diff Pr(&gt;Chisq)  \nfit_cfa3 86 14864 15065 246.1                                \nfit_cfa2 87 14882 15078 265.5     6.1408       1    0.01321 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat does the Chi-square difference test tell us?\nLet’s see if there are any other large modification indices that are meaningfully larger than other modification indices:\n\nmodindices(fit_cfa3, sort. = TRUE, minimum.value = 15)\n\n       lhs op    rhs     mi    epc sepc.lv sepc.all sepc.nox\n163 swan_3 ~~ swan_5 23.119 -0.182  -0.182   -0.274   -0.274\n176 swan_5 ~~ swan_7 20.511  0.150   0.150    0.280    0.280\n154 swan_2 ~~ swan_3 18.939  0.146   0.146    0.225    0.225\n162 swan_3 ~~ swan_4 18.746  0.141   0.141    0.253    0.253\n\n\nWe might consider adding the residual covariance between SWAN item 5 and 7. Both items mention ‘activities’, but there are many other items on this subscale that contain the word ‘activities’, so there is nothing special about this pair of items. Any further modifications may be purely data-driven (i.e., exploratory).\nIn addition to model fit, we can also consider how well the factor explain variance among the observed items.\n\nlavInspect(fit_cfa3, what = \"rsquare\")\n\nhpc_mean   cldq_1   cldq_2   cldq_4   cldq_5   cldq_6   swan_1   swan_2 \n   0.960    0.524    0.567    0.829    0.706    0.775    0.715    0.717 \n  swan_3   swan_4   swan_5   swan_6   swan_7   swan_8   swan_9 \n   0.584    0.823    0.790    0.720    0.792    0.674    0.759 \n\n\nAre the R-squared values sufficiently high to support that our measurement model is accounting for enough common variance among the items?\nFinally, we can examine the reliability of our factors using coefficient Omega (note that the output does not include the hwp factor, since that’s a single-indicator factor, and you need multiple indicators to compute coefficient Omega):\n\ncompRelSEM(fit_cfa)\n\n readprob attention \n    0.920     0.962 \n\n\nOverall, I’m satisfied with the measurement model component of the SEM. The two residual covariances will need to be replicated in new samples to confirm that there is some shared cause among them that is separate from their main latent factors.\nNote that R-squared and reliability are not affected by residual covariances, but they would be affected by added cross-loadings."
  },
  {
    "objectID": "sem.html#structural-model",
    "href": "sem.html#structural-model",
    "title": "6  Structural Equation Modeling",
    "section": "6.7 Structural Model",
    "text": "6.7 Structural Model\nNow that we have finalized the measurement model, we can move on to the structural model. Let’s specify and estimate the hypothesized structural model:\n\nbig_sem &lt;- '\n# Measurement Model\nreadprob =~ cldq_1 + cldq_2 + cldq_4 + cldq_5 + cldq_6\nattention =~ swan_1 + swan_2 + swan_3 + swan_4 + swan_5 + swan_6 + \n             swan_7 + swan_8 + swan_9\n             \nhwp =~ 1* hpc_mean\nhpc_mean ~~ 0.01572*hpc_mean\n\nswan_1 ~~ swan_2\ncldq_5 ~~   cldq_6\n\n# Structural Model\nreadprob ~ b*hwp\nhwp ~ a*attention\n\n\n# Indirect Effects\nind.att.hwp := a*b\n'\n\nfit_sem &lt;- sem(big_sem, kids, \n               estimator = \"mlr\", \n               missing = \"fiml\")\n\nsummary(fit_sem, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 60 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        48\n\n  Number of observations                           441\n  Number of missing patterns                        13\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               249.799     187.394\n  Degrees of freedom                                87          87\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.333\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              5812.658    3750.370\n  Degrees of freedom                               105         105\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.550\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.971       0.972\n  Tucker-Lewis Index (TLI)                       0.966       0.967\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.976\n  Robust Tucker-Lewis Index (TLI)                            0.971\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -7385.041   -7385.041\n  Scaling correction factor                                  1.702\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -7260.142   -7260.142\n  Scaling correction factor                                  1.464\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               14866.082   14866.082\n  Bayesian (BIC)                             15062.356   15062.356\n  Sample-size adjusted Bayesian (SABIC)      14910.027   14910.027\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.065       0.051\n  90 Percent confidence interval - lower         0.056       0.042\n  90 Percent confidence interval - upper         0.075       0.060\n  P-value H_0: RMSEA &lt;= 0.050                    0.004       0.401\n  P-value H_0: RMSEA &gt;= 0.080                    0.005       0.000\n                                                                  \n  Robust RMSEA                                               0.062\n  90 Percent confidence interval - lower                     0.050\n  90 Percent confidence interval - upper                     0.074\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.055\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.006\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.046       0.046\n\n\nWe can compare this model to a just identified structural model that includes the direct effect from Attention to Reading Problems:\n\nbig_sem2 &lt;- '\n# Measurement Model\nreadprob =~ cldq_1 + cldq_2 + cldq_4 + cldq_5 + cldq_6\nattention =~ swan_1 + swan_2 + swan_3 + swan_4 + swan_5 + swan_6 + \n             swan_7 + swan_8 + swan_9\n\nhwp =~ 1* hpc_mean\nhpc_mean ~~ 0.01572*hpc_mean\n\nswan_1 ~~ swan_2\ncldq_5 ~~   cldq_6\n\n# Structural Model\nreadprob ~ b*hwp + c*attention\nhwp ~ a*attention\n\n\n# Indirect Effects\nind.att.hwp := a*b\ntot.att := c + a*b\n'\n\nfit_sem2 &lt;- sem(big_sem2, kids, \n                estimator = \"mlr\", \n                missing = \"fiml\")\n\ncomp_34 &lt;- compareFit(fit_sem, fit_sem2)\ncomp_34@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n         Df   AIC   BIC Chisq Chisq diff Df diff Pr(&gt;Chisq)  \nfit_sem2 86 14864 15065 246.1                                \nfit_sem  87 14866 15062 249.8     3.5066       1    0.06112 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat does the Chi-square difference test tell us?"
  },
  {
    "objectID": "sem.html#parameter-estimate-interpretation",
    "href": "sem.html#parameter-estimate-interpretation",
    "title": "6  Structural Equation Modeling",
    "section": "6.8 Parameter Estimate Interpretation",
    "text": "6.8 Parameter Estimate Interpretation\nNow that we’ve finalized our structural model, we can interpret the parameter estimates. We will re-estimate the final model, using bootstrapping to get confidence intervals for the indirect effect. Note that we cannot combine mlr with bootstrapping, because the bootstrap method itself is a way of addressing non-normality. So we change the estimator back to ml.\n\nfit_semb &lt;- sem(big_sem, kids, \n                estimator = \"ml\", \n                missing = \"fiml\",\n                se = \"bootstrap\", \n                bootstrap = 1000,\n                iseed = 8789)\n\nparameterEstimates(fit_semb, boot.ci.type = \"bca.simple\", \n                   ci = TRUE, se = TRUE, \n                   zstat = FALSE, pvalue = FALSE,\n                   output = \"text\")\n\n\nLatent Variables:\n                   Estimate  Std.Err ci.lower ci.upper\n  readprob =~                                         \n    cldq_1            1.000             1.000    1.000\n    cldq_2            0.765    0.064    0.622    0.877\n    cldq_4            1.272    0.076    1.134    1.438\n    cldq_5            1.257    0.083    1.113    1.444\n    cldq_6            1.326    0.083    1.186    1.509\n  attention =~                                        \n    swan_1            1.000             1.000    1.000\n    swan_2            0.940    0.035    0.865    1.001\n    swan_3            0.831    0.049    0.735    0.929\n    swan_4            1.092    0.043    1.015    1.183\n    swan_5            1.175    0.049    1.085    1.271\n    swan_6            1.032    0.048    0.940    1.123\n    swan_7            1.104    0.051    1.013    1.204\n    swan_8            1.020    0.051    0.937    1.139\n    swan_9            1.030    0.040    0.956    1.109\n  hwp =~                                              \n    hpc_mean          1.000             1.000    1.000\n\nRegressions:\n                   Estimate  Std.Err ci.lower ci.upper\n  readprob ~                                          \n    hwp        (b)    0.687    0.074    0.545    0.833\n  hwp ~                                               \n    attention  (a)   -0.360    0.022   -0.403   -0.318\n\nCovariances:\n                   Estimate  Std.Err ci.lower ci.upper\n .swan_1 ~~                                           \n   .swan_2            0.171    0.050    0.075    0.282\n .cldq_5 ~~                                           \n   .cldq_6            0.118    0.044    0.030    0.214\n\nIntercepts:\n                   Estimate  Std.Err ci.lower ci.upper\n   .cldq_1            1.988    0.053    1.877    2.086\n   .cldq_2            1.327    0.038    1.249    1.401\n   .cldq_4            1.646    0.054    1.535    1.746\n   .cldq_5            1.663    0.059    1.545    1.784\n   .cldq_6            1.662    0.058    1.553    1.782\n   .swan_1            4.541    0.073    4.410    4.703\n   .swan_2            4.720    0.069    4.597    4.876\n   .swan_3            4.838    0.067    4.710    4.974\n   .swan_4            4.624    0.075    4.476    4.774\n   .swan_5            4.427    0.083    4.272    4.593\n   .swan_6            4.646    0.078    4.501    4.813\n   .swan_7            4.529    0.080    4.379    4.701\n   .swan_8            4.055    0.079    3.908    4.220\n   .swan_9            4.541    0.073    4.397    4.693\n   .hpc_mean          1.676    0.031    1.619    1.738\n   .readprob          0.000             0.000    0.000\n    attention         0.000             0.000    0.000\n   .hwp               0.000             0.000    0.000\n\nVariances:\n                   Estimate  Std.Err ci.lower ci.upper\n   .hpc_mean          0.016             0.016    0.016\n   .cldq_1            0.570    0.058    0.460    0.690\n   .cldq_2            0.279    0.039    0.213    0.369\n   .cldq_4            0.207    0.047    0.127    0.321\n   .cldq_5            0.418    0.071    0.290    0.570\n   .cldq_6            0.324    0.044    0.247    0.434\n   .swan_1            0.623    0.072    0.497    0.790\n   .swan_2            0.546    0.062    0.439    0.687\n   .swan_3            0.769    0.080    0.628    0.944\n   .swan_4            0.400    0.041    0.327    0.482\n   .swan_5            0.573    0.070    0.460    0.751\n   .swan_6            0.648    0.102    0.490    0.916\n   .swan_7            0.499    0.093    0.357    0.732\n   .swan_8            0.784    0.082    0.645    0.986\n   .swan_9            0.525    0.058    0.424    0.649\n   .readprob          0.449    0.065    0.329    0.582\n    attention         1.561    0.141    1.294    1.857\n   .hwp               0.174    0.021    0.139    0.218\n\nDefined Parameters:\n                   Estimate  Std.Err ci.lower ci.upper\n    ind.att.hwp      -0.247    0.031   -0.310   -0.187\n\nlavInspect(fit_semb, what = \"rsquare\")\n\nhpc_mean   cldq_1   cldq_2   cldq_4   cldq_5   cldq_6   swan_1   swan_2 \n   0.960    0.524    0.568    0.831    0.704    0.773    0.715    0.717 \n  swan_3   swan_4   swan_5   swan_6   swan_7   swan_8   swan_9 readprob \n   0.584    0.823    0.790    0.719    0.792    0.674    0.759    0.283 \n     hwp \n   0.537 \n\n\nThe direct effect of attention on homework problems is negative (b = -.358, 95% CI = [-.402,-.317]),indicating that kids with higher attention levels experience fewer homework problems. The direct effect of homework problems on reading problems is positive (b = .690, 95% CI = [.547, .833]), indicating that kids with more homework problems experience more reading problems. This means that the indirect effect of attention on reading problems through homework problems is negative (b = -.247, 95% CI = [-.309,-.191]), which indicates that the decrease in homework problems that is associated with a one-unit increase in attention is associated with a decrease in reading problems. Overall, the model explains 28% of the variability in homework problems and 54% of the variability in reading problems.\nIn a paper, you could report all parameter values (including those from the measurement model) as unstandardized + 95% CI and standardized + SE in a table and/or figure."
  },
  {
    "objectID": "sem.html#interaction-effects-with-latent-variables",
    "href": "sem.html#interaction-effects-with-latent-variables",
    "title": "6  Structural Equation Modeling",
    "section": "6.9 Interaction Effects with Latent Variables",
    "text": "6.9 Interaction Effects with Latent Variables\nNext, I will use these data to illustrate the process of estimating interaction effects between latent factors. Here, we will test the hypothesis that Attentiveness moderates the association between Reading Problems and Homework Problems (which acts as the outcome variable here!).\nWe can use the modsem package to help estimate these interaction effects. To include the interaction effect in the model specification, you do the following (note structural model section):\n\nbig_sem3 &lt;- '\n# Measurement Model\nreadprob =~ cldq_1 + cldq_2 + cldq_4 + cldq_5 + cldq_6\nattention =~ swan_1 + swan_2 + swan_3 + swan_4 + swan_5 + swan_6 + \n             swan_7 + swan_8 + swan_9\n\nhwp =~ 1* hpc_mean\nhpc_mean ~~ 0.01572*hpc_mean\n\nswan_1 ~~ swan_2\ncldq_5 ~~   cldq_6\n\n# Structural Model\nhwp ~ readprob + attention + readprob:attention\n'\n\nThere are different methods for estimating an interaction effect between latent variables. Three main options are: the product indicator approach (using double centering), latent model structural equations (LMS), and quasi maximum likelihood estimation (QML). Of these, LMS and QML take more time to estimate and require complete data (but may be more accurate than the product indicator approach and have options for comparing model fit with and without the interaction effect). Here, I will demonstrate the product indicator approach (but example code is also included for the other two methods).\n\nfit_sem_mod_pi &lt;- modsem(model = big_sem3, \n                      data = kids, \n                      missing = \"fiml\",\n                      method = \"dblcent\")\n\n# verbose = TRUE print model estimation progress in the console\n# fit_sem_mod_lms &lt;- modsem(model = big_sem3, \n#                      data = kids, \n#                      method = \"lms\", verbose = TRUE)\n# fit_sem_mod_qml &lt;- modsem(model = big_sem3, \n#                      data = kids, \n#                      method = \"qml\", verbose = TRUE)\n\n\nParameter Estimate Interpretation\nWith the product indicator approach, the modsem package helps compute all the product terms and write all of the lavaan model syntax. The output of this model is very extensive (lots of loadings, lots of residual variances, indicator intercepts, and a bunch of residual covariances which need to be fixed to 0). We will check that all factor loadings are significant and then focus on the regression estimates:\n\nsummary(fit_sem_mod_pi, std = T)\n\nmodsem (version 1.0.5, approach = dblcent):\nlavaan 0.6.17 ended normally after 593 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                       457\n\n  Number of observations                           441\n  Number of missing patterns                        13\n\nModel Test User Model:\n                                                      \n  Test statistic                              4555.221\n  Degrees of freedom                              1433\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                       Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  readprob =~                                                               \n    cldq_1                1.000                               0.780    0.713\n    cldq_2                0.774    0.051   15.278    0.000    0.603    0.750\n    cldq_4                1.280    0.070   18.225    0.000    0.998    0.903\n    cldq_5                1.295    0.078   16.622    0.000    1.009    0.850\n    cldq_6                1.367    0.078   17.506    0.000    1.066    0.893\n  attention =~                                                              \n    swan_1                1.000                               1.251    0.846\n    swan_2                0.939    0.036   26.302    0.000    1.175    0.847\n    swan_3                0.830    0.044   18.766    0.000    1.039    0.764\n    swan_4                1.091    0.044   25.033    0.000    1.365    0.907\n    swan_5                1.173    0.049   24.116    0.000    1.468    0.889\n    swan_6                1.030    0.046   22.217    0.000    1.289    0.848\n    swan_7                1.103    0.046   24.104    0.000    1.379    0.890\n    swan_8                1.018    0.049   20.969    0.000    1.273    0.821\n    swan_9                1.028    0.044   23.315    0.000    1.287    0.871\n  hwp =~                                                                    \n    hpc_mean              1.000                               0.613    0.980\n  readprobattention =~                                                      \n    cldq_1swan_1          1.000                               0.897    0.534\n    cldq_2swan_1          0.961    0.085   11.357    0.000    0.862    0.656\n    cldq_4swan_1          1.537    0.121   12.738    0.000    1.378    0.791\n    cldq_5swan_1          1.776    0.144   12.355    0.000    1.592    0.791\n    cldq_6swan_1          1.883    0.147   12.819    0.000    1.688    0.830\n    cldq_1swan_2          0.999    0.068   14.589    0.000    0.895    0.542\n    cldq_2swan_2          0.919    0.093    9.887    0.000    0.824    0.659\n    cldq_4swan_2          1.428    0.132   10.787    0.000    1.281    0.764\n    cldq_5swan_2          1.717    0.158   10.880    0.000    1.539    0.797\n    cldq_6swan_2          1.806    0.163   11.105    0.000    1.619    0.828\n    cldq_1swan_3          0.836    0.075   11.132    0.000    0.750    0.470\n    cldq_2swan_3          0.678    0.085    7.976    0.000    0.608    0.484\n    cldq_4swan_3          1.186    0.125    9.504    0.000    1.063    0.621\n    cldq_5swan_3          1.357    0.142    9.531    0.000    1.217    0.633\n    cldq_6swan_3          1.432    0.146    9.831    0.000    1.284    0.666\n    cldq_1swan_4          1.115    0.074   15.061    0.000    0.999    0.582\n    cldq_2swan_4          0.976    0.100    9.721    0.000    0.875    0.644\n    cldq_4swan_4          1.557    0.142   10.952    0.000    1.396    0.797\n    cldq_5swan_4          1.786    0.165   10.853    0.000    1.601    0.806\n    cldq_6swan_4          1.874    0.169   11.094    0.000    1.680    0.836\n    cldq_1swan_5          1.200    0.081   14.857    0.000    1.076    0.552\n    cldq_2swan_5          1.146    0.118    9.692    0.000    1.028    0.653\n    cldq_4swan_5          1.734    0.159   10.908    0.000    1.554    0.794\n    cldq_5swan_5          2.032    0.190   10.723    0.000    1.822    0.788\n    cldq_6swan_5          2.146    0.193   11.094    0.000    1.924    0.841\n    cldq_1swan_6          1.163    0.082   14.100    0.000    1.042    0.560\n    cldq_2swan_6          1.182    0.117   10.097    0.000    1.059    0.694\n    cldq_4swan_6          1.708    0.157   10.909    0.000    1.531    0.797\n    cldq_5swan_6          1.968    0.183   10.751    0.000    1.765    0.796\n    cldq_6swan_6          2.076    0.187   11.095    0.000    1.862    0.842\n    cldq_1swan_7          1.092    0.078   13.929    0.000    0.979    0.531\n    cldq_2swan_7          1.089    0.115    9.472    0.000    0.976    0.631\n    cldq_4swan_7          1.605    0.148   10.825    0.000    1.439    0.784\n    cldq_5swan_7          1.876    0.174   10.778    0.000    1.682    0.803\n    cldq_6swan_7          2.009    0.183   10.960    0.000    1.801    0.830\n    cldq_1swan_8          1.106    0.086   12.928    0.000    0.992    0.519\n    cldq_2swan_8          1.117    0.119    9.412    0.000    1.001    0.617\n    cldq_4swan_8          1.634    0.156   10.505    0.000    1.465    0.734\n    cldq_5swan_8          1.898    0.178   10.649    0.000    1.702    0.773\n    cldq_6swan_8          2.027    0.186   10.877    0.000    1.817    0.805\n    cldq_1swan_9          1.072    0.079   13.593    0.000    0.961    0.529\n    cldq_2swan_9          1.023    0.104    9.842    0.000    0.917    0.660\n    cldq_4swan_9          1.569    0.147   10.708    0.000    1.407    0.767\n    cldq_5swan_9          1.799    0.170   10.604    0.000    1.613    0.774\n    cldq_6swan_9          1.882    0.172   10.955    0.000    1.687    0.822\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  hwp ~                                                                 \n    readprob          0.108    0.037    2.913    0.004    0.137    0.137\n    attention        -0.309    0.021  -14.716    0.000   -0.630   -0.630\n    readprobattntn   -0.139    0.031   -4.430    0.000   -0.203   -0.203\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .swan_1 ~~                                                             \n   .swan_2            0.169    0.035    4.829    0.000    0.169    0.290\n .cldq_5 ~~                                                             \n   .cldq_6            0.087    0.028    3.118    0.002    0.087    0.260\n .cldq_1swan_1 ~~                                                       \n   .cldq_2swan_2      0.000                               0.000    0.000\n   .cldq_2swan_3      0.000                               0.000    0.000\n   .cldq_2swan_4      0.000                               0.000    0.000\n   .cldq_2swan_5      0.000                               0.000    0.000\n   .cldq_2swan_6      0.000                               0.000    0.000\n   .cldq_2swan_7      0.000                               0.000    0.000\n   .cldq_2swan_8      0.000                               0.000    0.000\n   .cldq_2swan_9      0.000                               0.000    0.000\n   .cldq_4swan_2      0.000                               0.000    0.000\n   .cldq_4swan_3      0.000                               0.000    0.000\n   .cldq_4swan_4      0.000                               0.000    0.000\n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n   .cldq_5swan_2      0.000                               0.000    0.000\n   .cldq_5swan_3      0.000                               0.000    0.000\n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n   .cldq_6swan_2      0.000                               0.000    0.000\n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_2      0.000                               0.000    0.000\n .cldq_1swan_2 ~~                                                       \n   .cldq_2swan_3      0.000                               0.000    0.000\n   .cldq_2swan_4      0.000                               0.000    0.000\n   .cldq_2swan_5      0.000                               0.000    0.000\n   .cldq_2swan_6      0.000                               0.000    0.000\n   .cldq_2swan_7      0.000                               0.000    0.000\n   .cldq_2swan_8      0.000                               0.000    0.000\n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_2      0.000                               0.000    0.000\n .cldq_1swan_2 ~~                                                       \n   .cldq_4swan_3      0.000                               0.000    0.000\n   .cldq_4swan_4      0.000                               0.000    0.000\n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_2      0.000                               0.000    0.000\n .cldq_1swan_2 ~~                                                       \n   .cldq_5swan_3      0.000                               0.000    0.000\n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_2      0.000                               0.000    0.000\n .cldq_1swan_2 ~~                                                       \n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_1swan_3 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n   .cldq_2swan_5      0.000                               0.000    0.000\n   .cldq_2swan_6      0.000                               0.000    0.000\n   .cldq_2swan_7      0.000                               0.000    0.000\n   .cldq_2swan_8      0.000                               0.000    0.000\n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_1swan_3 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_1swan_3 ~~                                                       \n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_1swan_3      0.000                               0.000    0.000\n .cldq_1swan_3 ~~                                                       \n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_1swan_4 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n   .cldq_2swan_6      0.000                               0.000    0.000\n   .cldq_2swan_7      0.000                               0.000    0.000\n   .cldq_2swan_8      0.000                               0.000    0.000\n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_1swan_4 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_1swan_4 ~~                                                       \n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_1swan_4      0.000                               0.000    0.000\n .cldq_1swan_4 ~~                                                       \n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_1swan_5 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n   .cldq_2swan_7      0.000                               0.000    0.000\n   .cldq_2swan_8      0.000                               0.000    0.000\n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_1swan_5 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_1swan_5 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_1swan_5      0.000                               0.000    0.000\n .cldq_1swan_5 ~~                                                       \n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_2swan_5 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_1swan_6 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n   .cldq_2swan_8      0.000                               0.000    0.000\n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_1swan_6 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_1swan_6 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_1swan_6      0.000                               0.000    0.000\n .cldq_1swan_6 ~~                                                       \n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_2swan_5 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_2swan_6 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_1swan_7 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_1swan_7 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_1swan_7 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_1swan_7      0.000                               0.000    0.000\n .cldq_1swan_7 ~~                                                       \n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_2swan_5 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_2swan_6 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_2swan_7 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_1swan_8 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_4swan_7 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_1swan_8 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_5swan_7 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_1swan_8 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_1swan_8      0.000                               0.000    0.000\n .cldq_1swan_8 ~~                                                       \n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_5 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_6 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_7 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_8 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_7 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_4swan_8 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_7 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_5swan_8 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_6swan_8 ~~                                                       \n   .cldq_1swan_9      0.000                               0.000    0.000\n .cldq_2swan_1 ~~                                                       \n   .cldq_4swan_2      0.000                               0.000    0.000\n   .cldq_4swan_3      0.000                               0.000    0.000\n   .cldq_4swan_4      0.000                               0.000    0.000\n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n   .cldq_5swan_2      0.000                               0.000    0.000\n   .cldq_5swan_3      0.000                               0.000    0.000\n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n   .cldq_6swan_2      0.000                               0.000    0.000\n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_2      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_4swan_3      0.000                               0.000    0.000\n   .cldq_4swan_4      0.000                               0.000    0.000\n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_2      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_5swan_3      0.000                               0.000    0.000\n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_2      0.000                               0.000    0.000\n .cldq_2swan_2 ~~                                                       \n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_3      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_2swan_3      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_3      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_2swan_3      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_3      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_2swan_3      0.000                               0.000    0.000\n .cldq_2swan_3 ~~                                                       \n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_2swan_4      0.000                               0.000    0.000\n .cldq_2swan_4 ~~                                                       \n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_2swan_5 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_2swan_5 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_2swan_5      0.000                               0.000    0.000\n .cldq_2swan_5 ~~                                                       \n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_2swan_6 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_2swan_6 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_2swan_6      0.000                               0.000    0.000\n .cldq_2swan_6 ~~                                                       \n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_2swan_7 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_2swan_7 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_2swan_7      0.000                               0.000    0.000\n .cldq_2swan_7 ~~                                                       \n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_4swan_7 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_2swan_8 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_5swan_7 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_2swan_8 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_2swan_8      0.000                               0.000    0.000\n .cldq_2swan_8 ~~                                                       \n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_7 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_8 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_7 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_5swan_8 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_6swan_8 ~~                                                       \n   .cldq_2swan_9      0.000                               0.000    0.000\n .cldq_4swan_1 ~~                                                       \n   .cldq_5swan_2      0.000                               0.000    0.000\n   .cldq_5swan_3      0.000                               0.000    0.000\n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n   .cldq_6swan_2      0.000                               0.000    0.000\n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_2      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_5swan_3      0.000                               0.000    0.000\n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_2      0.000                               0.000    0.000\n .cldq_4swan_2 ~~                                                       \n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_3      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_4swan_3      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_5swan_4      0.000                               0.000    0.000\n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_3      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_4swan_3      0.000                               0.000    0.000\n .cldq_4swan_3 ~~                                                       \n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_5swan_5      0.000                               0.000    0.000\n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_4swan_4      0.000                               0.000    0.000\n .cldq_4swan_4 ~~                                                       \n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_4swan_5      0.000                               0.000    0.000\n .cldq_4swan_5 ~~                                                       \n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_4swan_6      0.000                               0.000    0.000\n .cldq_4swan_6 ~~                                                       \n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_4swan_7 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_4swan_7      0.000                               0.000    0.000\n .cldq_4swan_7 ~~                                                       \n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_5swan_7 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_4swan_8 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_4swan_8      0.000                               0.000    0.000\n .cldq_4swan_8 ~~                                                       \n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_7 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_8 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_6swan_8 ~~                                                       \n   .cldq_4swan_9      0.000                               0.000    0.000\n .cldq_5swan_1 ~~                                                       \n   .cldq_6swan_2      0.000                               0.000    0.000\n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_2      0.000                               0.000    0.000\n .cldq_5swan_2 ~~                                                       \n   .cldq_6swan_3      0.000                               0.000    0.000\n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_3      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_5swan_3      0.000                               0.000    0.000\n .cldq_5swan_3 ~~                                                       \n   .cldq_6swan_4      0.000                               0.000    0.000\n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_4      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_5swan_4      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_5swan_4      0.000                               0.000    0.000\n .cldq_5swan_4 ~~                                                       \n   .cldq_6swan_5      0.000                               0.000    0.000\n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_5      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_5swan_5      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_5swan_5      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_5swan_5      0.000                               0.000    0.000\n .cldq_5swan_5 ~~                                                       \n   .cldq_6swan_6      0.000                               0.000    0.000\n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_5swan_6      0.000                               0.000    0.000\n .cldq_5swan_6 ~~                                                       \n   .cldq_6swan_7      0.000                               0.000    0.000\n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_5swan_7      0.000                               0.000    0.000\n .cldq_5swan_7 ~~                                                       \n   .cldq_6swan_8      0.000                               0.000    0.000\n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_5swan_8      0.000                               0.000    0.000\n .cldq_5swan_8 ~~                                                       \n   .cldq_6swan_9      0.000                               0.000    0.000\n .cldq_6swan_1 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_2 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_3 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_4 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_5 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_6 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_7 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_6swan_8 ~~                                                       \n   .cldq_5swan_9      0.000                               0.000    0.000\n .cldq_1swan_1 ~~                                                       \n   .cldq_1swan_2      1.270    0.105   12.063    0.000    1.270    0.644\n   .cldq_1swan_3      1.031    0.090   11.522    0.000    1.031    0.516\n   .cldq_1swan_4      1.288    0.110   11.758    0.000    1.288    0.650\n   .cldq_1swan_5      1.538    0.129   11.914    0.000    1.538    0.667\n   .cldq_1swan_6      1.354    0.115   11.791    0.000    1.354    0.619\n   .cldq_1swan_7      1.418    0.121   11.769    0.000    1.418    0.639\n   .cldq_1swan_8      1.361    0.120   11.379    0.000    1.361    0.587\n   .cldq_1swan_9      1.353    0.116   11.678    0.000    1.353    0.617\n   .cldq_2swan_1      0.371    0.041    9.126    0.000    0.371    0.264\n   .cldq_4swan_1      0.506    0.053    9.592    0.000    0.506    0.334\n   .cldq_5swan_1      0.531    0.057    9.337    0.000    0.531    0.304\n   .cldq_6swan_1      0.577    0.058    9.862    0.000    0.577    0.358\n .cldq_1swan_2 ~~                                                       \n   .cldq_1swan_3      1.045    0.090   11.648    0.000    1.045    0.535\n   .cldq_1swan_4      1.277    0.108   11.840    0.000    1.277    0.659\n   .cldq_1swan_5      1.447    0.124   11.666    0.000    1.447    0.641\n   .cldq_1swan_6      1.362    0.114   11.953    0.000    1.362    0.636\n   .cldq_1swan_7      1.321    0.115   11.440    0.000    1.321    0.608\n   .cldq_1swan_8      1.382    0.118   11.665    0.000    1.382    0.608\n   .cldq_1swan_9      1.382    0.115   12.006    0.000    1.382    0.644\n   .cldq_2swan_2      0.296    0.034    8.721    0.000    0.296    0.227\n   .cldq_4swan_2      0.532    0.052   10.178    0.000    0.532    0.355\n   .cldq_5swan_2      0.545    0.057    9.581    0.000    0.545    0.336\n   .cldq_6swan_2      0.596    0.060    9.980    0.000    0.596    0.391\n .cldq_1swan_3 ~~                                                       \n   .cldq_1swan_4      1.131    0.095   11.918    0.000    1.131    0.576\n   .cldq_1swan_5      1.094    0.104   10.542    0.000    1.094    0.478\n   .cldq_1swan_6      1.073    0.096   11.186    0.000    1.073    0.494\n   .cldq_1swan_7      1.065    0.099   10.792    0.000    1.065    0.484\n   .cldq_1swan_8      1.046    0.099   10.577    0.000    1.046    0.455\n   .cldq_1swan_9      1.077    0.097   11.122    0.000    1.077    0.495\n   .cldq_2swan_3      0.688    0.063   10.997    0.000    0.688    0.445\n   .cldq_4swan_3      1.057    0.088   11.947    0.000    1.057    0.559\n   .cldq_5swan_3      1.038    0.092   11.286    0.000    1.038    0.495\n   .cldq_6swan_3      1.090    0.096   11.372    0.000    1.090    0.538\n .cldq_1swan_4 ~~                                                       \n   .cldq_1swan_5      1.668    0.137   12.153    0.000    1.668    0.736\n   .cldq_1swan_6      1.479    0.122   12.124    0.000    1.479    0.688\n   .cldq_1swan_7      1.500    0.127   11.820    0.000    1.500    0.688\n   .cldq_1swan_8      1.412    0.125   11.337    0.000    1.412    0.619\n   .cldq_1swan_9      1.445    0.123   11.784    0.000    1.445    0.671\n   .cldq_2swan_4      0.228    0.026    8.628    0.000    0.228    0.157\n   .cldq_4swan_4      0.361    0.039    9.198    0.000    0.361    0.244\n   .cldq_5swan_4      0.372    0.040    9.235    0.000    0.372    0.227\n   .cldq_6swan_4      0.312    0.039    7.967    0.000    0.312    0.203\n .cldq_1swan_5 ~~                                                       \n   .cldq_1swan_6      1.671    0.141   11.889    0.000    1.671    0.667\n   .cldq_1swan_7      1.975    0.156   12.662    0.000    1.975    0.777\n   .cldq_1swan_8      1.722    0.149   11.581    0.000    1.722    0.648\n   .cldq_1swan_9      1.690    0.142   11.876    0.000    1.690    0.673\n   .cldq_2swan_5      0.198    0.032    6.127    0.000    0.198    0.102\n   .cldq_4swan_5      0.489    0.050    9.809    0.000    0.489    0.253\n   .cldq_5swan_5      0.480    0.053    9.015    0.000    0.480    0.208\n   .cldq_6swan_5      0.484    0.052    9.336    0.000    0.484    0.241\n .cldq_1swan_6 ~~                                                       \n   .cldq_1swan_7      1.587    0.134   11.883    0.000    1.587    0.658\n   .cldq_1swan_8      1.566    0.133   11.758    0.000    1.566    0.622\n   .cldq_1swan_9      1.546    0.129   12.002    0.000    1.546    0.649\n   .cldq_2swan_6      0.305    0.036    8.417    0.000    0.305    0.180\n   .cldq_4swan_6      0.623    0.059   10.537    0.000    0.623    0.349\n   .cldq_5swan_6      0.588    0.062    9.541    0.000    0.588    0.284\n   .cldq_6swan_6      0.612    0.061    9.983    0.000    0.612    0.333\n .cldq_1swan_7 ~~                                                       \n   .cldq_1swan_8      1.665    0.142   11.700    0.000    1.665    0.651\n   .cldq_1swan_9      1.671    0.137   12.195    0.000    1.671    0.692\n   .cldq_2swan_7      0.415    0.042    9.829    0.000    0.415    0.221\n   .cldq_4swan_7      0.466    0.047    9.960    0.000    0.466    0.262\n   .cldq_5swan_7      0.448    0.047    9.486    0.000    0.448    0.229\n   .cldq_6swan_7      0.478    0.050    9.655    0.000    0.478    0.252\n .cldq_1swan_8 ~~                                                       \n   .cldq_1swan_9      1.662    0.137   12.117    0.000    1.662    0.658\n   .cldq_2swan_8      0.592    0.059   10.040    0.000    0.592    0.284\n   .cldq_4swan_8      0.794    0.075   10.628    0.000    0.794    0.358\n   .cldq_5swan_8      0.734    0.075    9.750    0.000    0.734    0.321\n   .cldq_6swan_8      0.796    0.077   10.361    0.000    0.796    0.364\n .cldq_1swan_9 ~~                                                       \n   .cldq_2swan_9      0.381    0.038   10.127    0.000    0.381    0.237\n   .cldq_4swan_9      0.616    0.058   10.548    0.000    0.616    0.339\n   .cldq_5swan_9      0.611    0.061    9.989    0.000    0.611    0.299\n   .cldq_6swan_9      0.563    0.058    9.694    0.000    0.563    0.311\n .cldq_2swan_1 ~~                                                       \n   .cldq_2swan_2      0.537    0.049   10.883    0.000    0.537    0.577\n   .cldq_2swan_3      0.445    0.046    9.655    0.000    0.445    0.409\n   .cldq_2swan_4      0.640    0.057   11.301    0.000    0.640    0.622\n   .cldq_2swan_5      0.680    0.066   10.268    0.000    0.680    0.576\n   .cldq_2swan_6      0.638    0.060   10.558    0.000    0.638    0.586\n   .cldq_2swan_7      0.593    0.061    9.665    0.000    0.593    0.499\n   .cldq_2swan_8      0.626    0.061   10.178    0.000    0.626    0.495\n   .cldq_2swan_9      0.595    0.054   10.942    0.000    0.595    0.576\n   .cldq_4swan_1      0.368    0.041    9.047    0.000    0.368    0.349\n   .cldq_5swan_1      0.368    0.044    8.365    0.000    0.368    0.302\n   .cldq_6swan_1      0.426    0.045    9.379    0.000    0.426    0.379\n .cldq_2swan_2 ~~                                                       \n   .cldq_2swan_3      0.532    0.047   11.199    0.000    0.532    0.514\n   .cldq_2swan_4      0.635    0.055   11.490    0.000    0.635    0.650\n   .cldq_2swan_5      0.627    0.063   10.008    0.000    0.627    0.559\n   .cldq_2swan_6      0.668    0.060   11.129    0.000    0.668    0.645\n   .cldq_2swan_7      0.520    0.058    9.032    0.000    0.520    0.460\n   .cldq_2swan_8      0.586    0.059   10.015    0.000    0.586    0.487\n   .cldq_2swan_9      0.557    0.052   10.697    0.000    0.557    0.567\n   .cldq_4swan_2      0.365    0.036   10.091    0.000    0.365    0.359\n   .cldq_5swan_2      0.366    0.039    9.290    0.000    0.366    0.333\n   .cldq_6swan_2      0.400    0.041    9.707    0.000    0.400    0.388\n .cldq_2swan_3 ~~                                                       \n   .cldq_2swan_4      0.516    0.051   10.016    0.000    0.516    0.452\n   .cldq_2swan_5      0.397    0.058    6.867    0.000    0.397    0.304\n   .cldq_2swan_6      0.467    0.054    8.650    0.000    0.467    0.387\n   .cldq_2swan_7      0.376    0.055    6.842    0.000    0.376    0.285\n   .cldq_2swan_8      0.465    0.055    8.421    0.000    0.465    0.331\n   .cldq_2swan_9      0.471    0.049    9.538    0.000    0.471    0.412\n   .cldq_4swan_3      0.803    0.072   11.126    0.000    0.803    0.544\n   .cldq_5swan_3      0.814    0.075   10.823    0.000    0.814    0.498\n   .cldq_6swan_3      0.895    0.080   11.140    0.000    0.895    0.566\n .cldq_2swan_4 ~~                                                       \n   .cldq_2swan_5      0.901    0.078   11.614    0.000    0.901    0.728\n   .cldq_2swan_6      0.819    0.070   11.669    0.000    0.819    0.718\n   .cldq_2swan_7      0.749    0.071   10.555    0.000    0.749    0.601\n   .cldq_2swan_8      0.799    0.071   11.214    0.000    0.799    0.603\n   .cldq_2swan_9      0.754    0.063   11.906    0.000    0.754    0.697\n   .cldq_4swan_4      0.309    0.030   10.291    0.000    0.309    0.281\n   .cldq_5swan_4      0.315    0.031   10.184    0.000    0.315    0.258\n   .cldq_6swan_4      0.302    0.031    9.712    0.000    0.302    0.264\n .cldq_2swan_5 ~~                                                       \n   .cldq_2swan_6      0.976    0.085   11.466    0.000    0.976    0.745\n   .cldq_2swan_7      0.998    0.091   11.027    0.000    0.998    0.697\n   .cldq_2swan_8      0.987    0.088   11.203    0.000    0.987    0.649\n   .cldq_2swan_9      0.843    0.075   11.276    0.000    0.843    0.678\n   .cldq_4swan_5      0.288    0.036    8.049    0.000    0.288    0.203\n   .cldq_5swan_5      0.265    0.038    6.945    0.000    0.265    0.156\n   .cldq_6swan_5      0.312    0.039    7.979    0.000    0.312    0.211\n .cldq_2swan_6 ~~                                                       \n   .cldq_2swan_7      0.839    0.079   10.646    0.000    0.839    0.635\n   .cldq_2swan_8      0.869    0.078   11.092    0.000    0.869    0.619\n   .cldq_2swan_9      0.776    0.068   11.336    0.000    0.776    0.677\n   .cldq_4swan_6      0.309    0.037    8.470    0.000    0.309    0.243\n   .cldq_5swan_6      0.260    0.038    6.930    0.000    0.260    0.176\n   .cldq_6swan_6      0.365    0.039    9.376    0.000    0.365    0.278\n .cldq_2swan_7 ~~                                                       \n   .cldq_2swan_8      0.951    0.086   11.116    0.000    0.951    0.620\n   .cldq_2swan_9      0.779    0.071   10.943    0.000    0.779    0.623\n   .cldq_4swan_7      0.359    0.041    8.708    0.000    0.359    0.263\n   .cldq_5swan_7      0.342    0.041    8.293    0.000    0.342    0.228\n   .cldq_6swan_7      0.360    0.044    8.201    0.000    0.360    0.247\n .cldq_2swan_8 ~~                                                       \n   .cldq_2swan_9      0.797    0.070   11.320    0.000    0.797    0.599\n   .cldq_4swan_8      0.752    0.065   11.584    0.000    0.752    0.435\n   .cldq_5swan_8      0.717    0.066   10.852    0.000    0.717    0.402\n   .cldq_6swan_8      0.722    0.066   10.973    0.000    0.722    0.422\n .cldq_2swan_9 ~~                                                       \n   .cldq_4swan_9      0.430    0.041   10.568    0.000    0.430    0.350\n   .cldq_5swan_9      0.420    0.042    9.924    0.000    0.420    0.305\n   .cldq_6swan_9      0.441    0.042   10.516    0.000    0.441    0.361\n .cldq_4swan_1 ~~                                                       \n   .cldq_4swan_2      0.413    0.043    9.635    0.000    0.413    0.358\n   .cldq_4swan_3      0.354    0.041    8.539    0.000    0.354    0.247\n   .cldq_4swan_4      0.436    0.051    8.492    0.000    0.436    0.387\n   .cldq_4swan_5      0.491    0.058    8.531    0.000    0.491    0.387\n   .cldq_4swan_6      0.417    0.052    8.062    0.000    0.417    0.338\n   .cldq_4swan_7      0.422    0.054    7.873    0.000    0.422    0.348\n   .cldq_4swan_8      0.459    0.055    8.366    0.000    0.459    0.318\n   .cldq_4swan_9      0.410    0.049    8.420    0.000    0.410    0.327\n   .cldq_5swan_1      0.750    0.064   11.630    0.000    0.750    0.571\n   .cldq_6swan_1      0.718    0.064   11.271    0.000    0.718    0.593\n .cldq_4swan_2 ~~                                                       \n   .cldq_4swan_3      0.392    0.040    9.754    0.000    0.392    0.270\n   .cldq_4swan_4      0.461    0.049    9.484    0.000    0.461    0.403\n   .cldq_4swan_5      0.430    0.051    8.426    0.000    0.430    0.335\n   .cldq_4swan_6      0.439    0.049    9.038    0.000    0.439    0.350\n   .cldq_4swan_7      0.407    0.049    8.314    0.000    0.407    0.331\n   .cldq_4swan_8      0.431    0.050    8.579    0.000    0.431    0.294\n   .cldq_4swan_9      0.414    0.046    9.062    0.000    0.414    0.325\n   .cldq_5swan_2      0.756    0.066   11.424    0.000    0.756    0.599\n   .cldq_6swan_2      0.778    0.067   11.603    0.000    0.778    0.656\n .cldq_4swan_3 ~~                                                       \n   .cldq_4swan_4      0.388    0.047    8.273    0.000    0.388    0.273\n   .cldq_4swan_5      0.344    0.049    7.004    0.000    0.344    0.215\n   .cldq_4swan_6      0.360    0.047    7.728    0.000    0.360    0.231\n   .cldq_4swan_7      0.316    0.047    6.737    0.000    0.316    0.206\n   .cldq_4swan_8      0.350    0.048    7.276    0.000    0.350    0.192\n   .cldq_4swan_9      0.328    0.044    7.514    0.000    0.328    0.207\n   .cldq_5swan_3      1.477    0.116   12.736    0.000    1.477    0.738\n   .cldq_6swan_3      1.424    0.116   12.273    0.000    1.424    0.736\n .cldq_4swan_4 ~~                                                       \n   .cldq_4swan_5      0.591    0.068    8.682    0.000    0.591    0.470\n   .cldq_4swan_6      0.542    0.062    8.780    0.000    0.542    0.442\n   .cldq_4swan_7      0.562    0.065    8.685    0.000    0.562    0.466\n   .cldq_4swan_8      0.577    0.065    8.861    0.000    0.577    0.403\n   .cldq_4swan_9      0.542    0.059    9.161    0.000    0.542    0.435\n   .cldq_5swan_4      0.509    0.047   10.840    0.000    0.509    0.409\n   .cldq_6swan_4      0.504    0.047   10.708    0.000    0.504    0.433\n .cldq_4swan_5 ~~                                                       \n   .cldq_4swan_6      0.588    0.068    8.594    0.000    0.588    0.426\n   .cldq_4swan_7      0.641    0.075    8.543    0.000    0.641    0.473\n   .cldq_4swan_8      0.731    0.077    9.496    0.000    0.731    0.453\n   .cldq_4swan_9      0.517    0.063    8.163    0.000    0.517    0.369\n   .cldq_5swan_5      0.671    0.063   10.732    0.000    0.671    0.397\n   .cldq_6swan_5      0.666    0.061   10.946    0.000    0.666    0.452\n .cldq_4swan_6 ~~                                                       \n   .cldq_4swan_7      0.610    0.068    8.999    0.000    0.610    0.462\n   .cldq_4swan_8      0.636    0.068    9.313    0.000    0.636    0.405\n   .cldq_4swan_9      0.520    0.060    8.741    0.000    0.520    0.381\n   .cldq_5swan_6      0.731    0.066   11.126    0.000    0.731    0.469\n   .cldq_6swan_6      0.672    0.063   10.741    0.000    0.672    0.486\n .cldq_4swan_7 ~~                                                       \n   .cldq_4swan_8      0.714    0.074    9.586    0.000    0.714    0.463\n   .cldq_4swan_9      0.530    0.062    8.481    0.000    0.530    0.395\n   .cldq_5swan_7      0.564    0.053   10.701    0.000    0.564    0.397\n   .cldq_6swan_7      0.590    0.055   10.786    0.000    0.590    0.428\n .cldq_4swan_8 ~~                                                       \n   .cldq_4swan_9      0.532    0.062    8.523    0.000    0.532    0.333\n   .cldq_5swan_8      1.025    0.086   11.904    0.000    1.025    0.541\n   .cldq_6swan_8      1.025    0.086   11.880    0.000    1.025    0.565\n .cldq_4swan_9 ~~                                                       \n   .cldq_5swan_9      0.857    0.072   11.947    0.000    0.857    0.551\n   .cldq_6swan_9      0.810    0.069   11.819    0.000    0.810    0.587\n .cldq_5swan_1 ~~                                                       \n   .cldq_5swan_2      0.459    0.051    8.988    0.000    0.459    0.319\n   .cldq_5swan_3      0.536    0.054    9.876    0.000    0.536    0.292\n   .cldq_5swan_4      0.661    0.067    9.841    0.000    0.661    0.456\n   .cldq_5swan_5      0.759    0.080    9.513    0.000    0.759    0.434\n   .cldq_5swan_6      0.700    0.072    9.778    0.000    0.700    0.423\n   .cldq_5swan_7      0.683    0.071    9.615    0.000    0.683    0.444\n   .cldq_5swan_8      0.619    0.066    9.423    0.000    0.619    0.360\n   .cldq_5swan_9      0.616    0.063    9.799    0.000    0.616    0.379\n   .cldq_6swan_1      0.808    0.071   11.417    0.000    0.808    0.578\n .cldq_5swan_2 ~~                                                       \n   .cldq_5swan_3      0.424    0.047    8.992    0.000    0.424    0.244\n   .cldq_5swan_4      0.445    0.055    8.068    0.000    0.445    0.324\n   .cldq_5swan_5      0.372    0.062    6.023    0.000    0.372    0.224\n   .cldq_5swan_6      0.429    0.058    7.448    0.000    0.429    0.273\n   .cldq_5swan_7      0.414    0.057    7.259    0.000    0.414    0.284\n   .cldq_5swan_8      0.512    0.057    8.957    0.000    0.512    0.314\n   .cldq_5swan_9      0.510    0.054    9.405    0.000    0.510    0.331\n   .cldq_6swan_2      0.856    0.076   11.267    0.000    0.856    0.669\n .cldq_5swan_3 ~~                                                       \n   .cldq_5swan_4      0.574    0.060    9.616    0.000    0.574    0.328\n   .cldq_5swan_5      0.604    0.068    8.843    0.000    0.604    0.285\n   .cldq_5swan_6      0.548    0.062    8.797    0.000    0.548    0.274\n   .cldq_5swan_7      0.524    0.061    8.601    0.000    0.524    0.282\n   .cldq_5swan_8      0.456    0.057    8.056    0.000    0.456    0.219\n   .cldq_5swan_9      0.570    0.057   10.023    0.000    0.570    0.290\n   .cldq_6swan_3      1.632    0.129   12.695    0.000    1.632    0.761\n .cldq_5swan_4 ~~                                                       \n   .cldq_5swan_5      0.927    0.094    9.880    0.000    0.927    0.554\n   .cldq_5swan_6      0.767    0.081    9.450    0.000    0.767    0.486\n   .cldq_5swan_7      0.741    0.082    9.056    0.000    0.741    0.504\n   .cldq_5swan_8      0.633    0.074    8.528    0.000    0.633    0.385\n   .cldq_5swan_9      0.697    0.072    9.653    0.000    0.697    0.449\n   .cldq_6swan_4      0.557    0.050   11.038    0.000    0.557    0.430\n .cldq_5swan_5 ~~                                                       \n   .cldq_5swan_6      0.890    0.097    9.180    0.000    0.890    0.466\n   .cldq_5swan_7      0.963    0.102    9.463    0.000    0.963    0.542\n   .cldq_5swan_8      0.708    0.090    7.855    0.000    0.708    0.356\n   .cldq_5swan_9      0.739    0.084    8.806    0.000    0.739    0.393\n   .cldq_6swan_5      0.745    0.068   10.997    0.000    0.745    0.423\n .cldq_5swan_6 ~~                                                       \n   .cldq_5swan_7      0.888    0.091    9.781    0.000    0.888    0.529\n   .cldq_5swan_8      0.696    0.081    8.637    0.000    0.696    0.371\n   .cldq_5swan_9      0.728    0.078    9.352    0.000    0.728    0.410\n   .cldq_6swan_6      0.759    0.069   10.992    0.000    0.759    0.473\n .cldq_5swan_7 ~~                                                       \n   .cldq_5swan_8      0.762    0.085    8.943    0.000    0.762    0.436\n   .cldq_5swan_9      0.750    0.079    9.537    0.000    0.750    0.454\n   .cldq_6swan_7      0.619    0.057   10.790    0.000    0.619    0.409\n .cldq_5swan_8 ~~                                                       \n   .cldq_5swan_9      0.692    0.073    9.493    0.000    0.692    0.375\n   .cldq_6swan_8      1.122    0.092   12.213    0.000    1.122    0.600\n .cldq_5swan_9 ~~                                                       \n   .cldq_6swan_9      0.916    0.075   12.182    0.000    0.916    0.592\n .cldq_6swan_1 ~~                                                       \n   .cldq_6swan_2      0.318    0.046    6.884    0.000    0.318    0.255\n   .cldq_6swan_3      0.304    0.048    6.275    0.000    0.304    0.186\n   .cldq_6swan_4      0.472    0.062    7.600    0.000    0.472    0.377\n   .cldq_6swan_5      0.502    0.069    7.272    0.000    0.502    0.357\n   .cldq_6swan_6      0.437    0.062    7.013    0.000    0.437    0.322\n   .cldq_6swan_7      0.417    0.066    6.312    0.000    0.417    0.303\n   .cldq_6swan_8      0.375    0.062    6.086    0.000    0.375    0.247\n   .cldq_6swan_9      0.377    0.056    6.735    0.000    0.377    0.283\n .cldq_6swan_2 ~~                                                       \n   .cldq_6swan_3      0.257    0.042    6.104    0.000    0.257    0.163\n   .cldq_6swan_4      0.367    0.052    7.084    0.000    0.367    0.304\n   .cldq_6swan_5      0.346    0.055    6.287    0.000    0.346    0.255\n   .cldq_6swan_6      0.333    0.052    6.414    0.000    0.333    0.254\n   .cldq_6swan_7      0.289    0.053    5.411    0.000    0.289    0.218\n   .cldq_6swan_8      0.280    0.051    5.477    0.000    0.280    0.191\n   .cldq_6swan_9      0.261    0.046    5.650    0.000    0.261    0.203\n .cldq_6swan_3 ~~                                                       \n   .cldq_6swan_4      0.344    0.054    6.385    0.000    0.344    0.217\n   .cldq_6swan_5      0.270    0.057    4.774    0.000    0.270    0.152\n   .cldq_6swan_6      0.328    0.055    6.008    0.000    0.328    0.191\n   .cldq_6swan_7      0.268    0.056    4.789    0.000    0.268    0.154\n   .cldq_6swan_8      0.271    0.053    5.117    0.000    0.271    0.141\n   .cldq_6swan_9      0.236    0.048    4.888    0.000    0.236    0.140\n .cldq_6swan_4 ~~                                                       \n   .cldq_6swan_5      0.628    0.082    7.652    0.000    0.628    0.461\n   .cldq_6swan_6      0.543    0.072    7.500    0.000    0.543    0.413\n   .cldq_6swan_7      0.610    0.080    7.645    0.000    0.610    0.457\n   .cldq_6swan_8      0.538    0.074    7.309    0.000    0.538    0.364\n   .cldq_6swan_9      0.484    0.066    7.311    0.000    0.484    0.375\n .cldq_6swan_5 ~~                                                       \n   .cldq_6swan_6      0.603    0.081    7.447    0.000    0.603    0.409\n   .cldq_6swan_7      0.724    0.095    7.648    0.000    0.724    0.483\n   .cldq_6swan_8      0.666    0.087    7.691    0.000    0.666    0.402\n   .cldq_6swan_9      0.543    0.074    7.306    0.000    0.543    0.375\n .cldq_6swan_6 ~~                                                       \n   .cldq_6swan_7      0.589    0.081    7.225    0.000    0.589    0.407\n   .cldq_6swan_8      0.516    0.075    6.918    0.000    0.516    0.323\n   .cldq_6swan_9      0.520    0.069    7.566    0.000    0.520    0.372\n .cldq_6swan_7 ~~                                                       \n   .cldq_6swan_8      0.687    0.087    7.893    0.000    0.687    0.423\n   .cldq_6swan_9      0.542    0.075    7.274    0.000    0.542    0.382\n .cldq_6swan_8 ~~                                                       \n   .cldq_6swan_9      0.449    0.068    6.614    0.000    0.449    0.286\n  readprob ~~                                                           \n    attention        -0.442    0.060   -7.371    0.000   -0.454   -0.454\n    readprobattntn   -0.378    0.054   -6.975    0.000   -0.541   -0.541\n  attention ~~                                                          \n    readprobattntn    0.214    0.062    3.431    0.001    0.191    0.191\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .cldq_1            1.988    0.052   38.131    0.000    1.988    1.817\n   .cldq_2            1.327    0.038   34.654    0.000    1.327    1.650\n   .cldq_4            1.646    0.053   31.277    0.000    1.646    1.489\n   .cldq_5            1.662    0.057   29.407    0.000    1.662    1.401\n   .cldq_6            1.662    0.057   29.235    0.000    1.662    1.392\n   .swan_1            4.543    0.073   62.258    0.000    4.543    3.074\n   .swan_2            4.722    0.069   68.838    0.000    4.722    3.403\n   .swan_3            4.840    0.067   71.835    0.000    4.840    3.561\n   .swan_4            4.626    0.074   62.469    0.000    4.626    3.075\n   .swan_5            4.430    0.081   54.472    0.000    4.430    2.682\n   .swan_6            4.648    0.075   61.949    0.000    4.648    3.059\n   .swan_7            4.531    0.076   59.326    0.000    4.531    2.924\n   .swan_8            4.057    0.077   52.896    0.000    4.057    2.615\n   .swan_9            4.543    0.073   62.421    0.000    4.543    3.077\n   .hpc_mean          1.676    0.030   56.204    0.000    1.676    2.676\n   .cldq_1swan_1      0.015    0.084    0.180    0.857    0.015    0.009\n   .cldq_2swan_1      0.013    0.066    0.191    0.849    0.013    0.010\n   .cldq_4swan_1      0.023    0.087    0.267    0.790    0.023    0.013\n   .cldq_5swan_1      0.024    0.100    0.242    0.809    0.024    0.012\n   .cldq_6swan_1      0.029    0.101    0.285    0.775    0.029    0.014\n   .cldq_1swan_2      0.022    0.083    0.269    0.788    0.022    0.013\n   .cldq_2swan_2      0.013    0.063    0.213    0.831    0.013    0.011\n   .cldq_4swan_2      0.025    0.084    0.299    0.765    0.025    0.015\n   .cldq_5swan_2      0.029    0.096    0.304    0.761    0.029    0.015\n   .cldq_6swan_2      0.034    0.098    0.348    0.728    0.034    0.017\n   .cldq_1swan_3      0.016    0.080    0.195    0.846    0.016    0.010\n   .cldq_2swan_3      0.011    0.063    0.171    0.864    0.011    0.009\n   .cldq_4swan_3      0.020    0.086    0.233    0.815    0.020    0.012\n   .cldq_5swan_3      0.023    0.096    0.237    0.813    0.023    0.012\n   .cldq_6swan_3      0.024    0.097    0.247    0.805    0.024    0.012\n   .cldq_1swan_4      0.026    0.086    0.301    0.763    0.026    0.015\n   .cldq_2swan_4      0.018    0.068    0.270    0.787    0.018    0.014\n   .cldq_4swan_4      0.031    0.087    0.352    0.725    0.031    0.018\n   .cldq_5swan_4      0.037    0.099    0.374    0.708    0.037    0.019\n   .cldq_6swan_4      0.037    0.100    0.368    0.713    0.037    0.018\n   .cldq_1swan_5      0.017    0.098    0.176    0.860    0.017    0.009\n   .cldq_2swan_5      0.017    0.079    0.215    0.830    0.017    0.011\n   .cldq_4swan_5      0.026    0.098    0.262    0.793    0.026    0.013\n   .cldq_5swan_5      0.031    0.115    0.273    0.785    0.031    0.014\n   .cldq_6swan_5      0.032    0.114    0.278    0.781    0.032    0.014\n   .cldq_1swan_6      0.008    0.093    0.082    0.935    0.008    0.004\n   .cldq_2swan_6      0.002    0.076    0.025    0.980    0.002    0.001\n   .cldq_4swan_6      0.011    0.096    0.119    0.906    0.011    0.006\n   .cldq_5swan_6      0.019    0.111    0.168    0.867    0.019    0.008\n   .cldq_6swan_6      0.018    0.110    0.166    0.868    0.018    0.008\n   .cldq_1swan_7      0.023    0.093    0.247    0.805    0.023    0.012\n   .cldq_2swan_7      0.017    0.078    0.216    0.829    0.017    0.011\n   .cldq_4swan_7      0.025    0.092    0.268    0.789    0.025    0.013\n   .cldq_5swan_7      0.030    0.105    0.283    0.777    0.030    0.014\n   .cldq_6swan_7      0.030    0.108    0.282    0.778    0.030    0.014\n   .cldq_1swan_8      0.025    0.096    0.258    0.796    0.025    0.013\n   .cldq_2swan_8      0.017    0.081    0.215    0.830    0.017    0.011\n   .cldq_4swan_8      0.025    0.100    0.248    0.804    0.025    0.012\n   .cldq_5swan_8      0.027    0.110    0.248    0.804    0.027    0.012\n   .cldq_6swan_8      0.030    0.113    0.263    0.793    0.030    0.013\n   .cldq_1swan_9      0.017    0.091    0.182    0.856    0.017    0.009\n   .cldq_2swan_9      0.016    0.069    0.234    0.815    0.016    0.012\n   .cldq_4swan_9      0.023    0.092    0.249    0.804    0.023    0.012\n   .cldq_5swan_9      0.033    0.104    0.317    0.752    0.033    0.016\n   .cldq_6swan_9      0.029    0.102    0.285    0.775    0.029    0.014\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .hpc_mean          0.016                               0.016    0.040\n   .cldq_1            0.589    0.044   13.436    0.000    0.589    0.492\n   .cldq_2            0.282    0.021   13.175    0.000    0.282    0.437\n   .cldq_4            0.226    0.025    8.870    0.000    0.226    0.185\n   .cldq_5            0.390    0.037   10.557    0.000    0.390    0.277\n   .cldq_6            0.290    0.033    8.906    0.000    0.290    0.203\n   .swan_1            0.619    0.049   12.555    0.000    0.619    0.284\n   .swan_2            0.546    0.044   12.495    0.000    0.546    0.283\n   .swan_3            0.768    0.058   13.210    0.000    0.768    0.416\n   .swan_4            0.400    0.035   11.432    0.000    0.400    0.177\n   .swan_5            0.574    0.048   11.956    0.000    0.574    0.211\n   .swan_6            0.648    0.051   12.620    0.000    0.648    0.281\n   .swan_7            0.500    0.042   11.881    0.000    0.500    0.208\n   .swan_8            0.785    0.061   12.880    0.000    0.785    0.326\n   .swan_9            0.525    0.043   12.316    0.000    0.525    0.241\n   .cldq_1swan_1      2.014    0.132   15.263    0.000    2.014    0.715\n   .cldq_2swan_1      0.980    0.068   14.426    0.000    0.980    0.569\n   .cldq_4swan_1      1.136    0.077   14.763    0.000    1.136    0.374\n   .cldq_5swan_1      1.517    0.098   15.416    0.000    1.517    0.374\n   .cldq_6swan_1      1.289    0.095   13.629    0.000    1.289    0.311\n   .cldq_1swan_2      1.930    0.124   15.559    0.000    1.930    0.707\n   .cldq_2swan_2      0.886    0.059   14.932    0.000    0.886    0.566\n   .cldq_4swan_2      1.168    0.076   15.445    0.000    1.168    0.416\n   .cldq_5swan_2      1.362    0.093   14.680    0.000    1.362    0.365\n   .cldq_6swan_2      1.202    0.090   13.317    0.000    1.202    0.314\n   .cldq_1swan_3      1.981    0.119   16.670    0.000    1.981    0.779\n   .cldq_2swan_3      1.207    0.076   15.790    0.000    1.207    0.765\n   .cldq_4swan_3      1.806    0.118   15.265    0.000    1.806    0.615\n   .cldq_5swan_3      2.217    0.142   15.663    0.000    2.217    0.600\n   .cldq_6swan_3      2.073    0.145   14.335    0.000    2.073    0.557\n   .cldq_1swan_4      1.947    0.131   14.915    0.000    1.947    0.661\n   .cldq_2swan_4      1.077    0.073   14.762    0.000    1.077    0.585\n   .cldq_4swan_4      1.119    0.078   14.278    0.000    1.119    0.365\n   .cldq_5swan_4      1.383    0.096   14.378    0.000    1.383    0.350\n   .cldq_6swan_4      1.215    0.093   12.999    0.000    1.215    0.301\n   .cldq_1swan_5      2.642    0.177   14.904    0.000    2.642    0.695\n   .cldq_2swan_5      1.420    0.103   13.803    0.000    1.420    0.574\n   .cldq_4swan_5      1.416    0.103   13.814    0.000    1.416    0.370\n   .cldq_5swan_5      2.022    0.141   14.296    0.000    2.022    0.379\n   .cldq_6swan_5      1.530    0.119   12.872    0.000    1.530    0.292\n   .cldq_1swan_6      2.376    0.152   15.624    0.000    2.376    0.686\n   .cldq_2swan_6      1.209    0.086   14.107    0.000    1.209    0.519\n   .cldq_4swan_6      1.345    0.093   14.478    0.000    1.345    0.364\n   .cldq_5swan_6      1.805    0.122   14.813    0.000    1.805    0.367\n   .cldq_6swan_6      1.424    0.109   13.066    0.000    1.424    0.291\n   .cldq_1swan_7      2.445    0.161   15.198    0.000    2.445    0.718\n   .cldq_2swan_7      1.443    0.098   14.697    0.000    1.443    0.602\n   .cldq_4swan_7      1.297    0.094   13.817    0.000    1.297    0.385\n   .cldq_5swan_7      1.562    0.112   13.955    0.000    1.562    0.356\n   .cldq_6swan_7      1.467    0.114   12.928    0.000    1.467    0.311\n   .cldq_1swan_8      2.673    0.172   15.501    0.000    2.673    0.731\n   .cldq_2swan_8      1.631    0.103   15.828    0.000    1.631    0.619\n   .cldq_4swan_8      1.836    0.118   15.528    0.000    1.836    0.461\n   .cldq_5swan_8      1.953    0.128   15.226    0.000    1.953    0.403\n   .cldq_6swan_8      1.792    0.125   14.304    0.000    1.792    0.352\n   .cldq_1swan_9      2.385    0.153   15.618    0.000    2.385    0.721\n   .cldq_2swan_9      1.086    0.071   15.228    0.000    1.086    0.564\n   .cldq_4swan_9      1.388    0.092   15.053    0.000    1.388    0.412\n   .cldq_5swan_9      1.747    0.110   15.892    0.000    1.747    0.402\n   .cldq_6swan_9      1.372    0.099   13.845    0.000    1.372    0.325\n    readprob          0.608    0.073    8.372    0.000    1.000    1.000\n    attention         1.565    0.147   10.618    0.000    1.000    1.000\n   .hwp               0.145    0.012   12.428    0.000    0.386    0.386\n    readprobattntn    0.804    0.144    5.569    0.000    1.000    1.000\n\n\nThe regression estimates show that Reading Problems are positively associated with Homework Problems whereas Attentiveness is negatively associated with Homework problems. In addition, the interaction effect is significant and negative. Thus, a one-unit increase in Attentiveness reduces the association between Reading Problems and Homework Problems by about \\(-0.14\\). We can understand the interaction effect better by visualizing it (remember that the x-axis is mean-centered) by plotting the Johnson-Neyman regions (again, the x-axis is mean centered):\n\nplot_jn(x = \"readprob\", z = \"attention\",  y = \"hwp\", model = fit_sem_mod_pi, max_z = 4)\n\n\n\n\nThis figure shows that the association between Reading Problems and Homework Problems is:\n\nsignificant and positive (i.e., reporting more reading problems is associated with more homework problems) for attention levels &lt; 0.2;\nnot significant for attention levels between 0.2 and 2.04;\nsignificant and negative (i.e., reporting more reading problems is associated with fewer homework problems) for attention levels &gt; 2.04.\n\nThese findings (which are highly exploratory and not based on any theory!) may suggest that attentiveness buffers against/compensates for the negative consequences of reading problems on homework problems."
  },
  {
    "objectID": "sem.html#summary",
    "href": "sem.html#summary",
    "title": "6  Structural Equation Modeling",
    "section": "6.10 Summary",
    "text": "6.10 Summary\nIn this R lab, you were introduced to the steps involved in specifying, estimating, evaluating, comparing and interpreting the results of a full structural equation model. In the next R Lab, you will learn all about measurement invariance testing, a method that combines CFA and multiple-group comparisons."
  },
  {
    "objectID": "measurementinvariance_cont.html#loading-r-packages",
    "href": "measurementinvariance_cont.html#loading-r-packages",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.1 Loading R packages",
    "text": "7.1 Loading R packages\n\nlibrary(rio)\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(semhelpinghands)\nlibrary(tidyverse)"
  },
  {
    "objectID": "measurementinvariance_cont.html#loading-data",
    "href": "measurementinvariance_cont.html#loading-data",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.2 Loading Data",
    "text": "7.2 Loading Data\nLoad the data into your environment. For this lab we will use a dataset of N = 1000 individuals who completed the Depression-Anxiety-Stress Scales (DASS-21). For this lab, we will focus on the Anxiety and Stress subscales.\nYou can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/DASS21.csv. Make sure to save it in the folder you are using for this class.\n\nDASS21 &lt;- import(file = \"data/DASS21.csv\")\n\nDASS21$engnat &lt;- factor(DASS21$engnat, \n                        levels = c(\"EnglishNative\", \"ELL\"))\n\nWe will see if there is measurement invariance across participants whose native language is English (1) versus participants who have a different native language/are ELL (2). The table below shows the sample size in each group:\n\ntable(DASS21$engnat)\n\n\nEnglishNative           ELL \n          500           500 \n\n\nHere is an overview of the questions on the Anxiety subscale:\n\nq2: I was aware of dryness in my mouth\nq4: I experienced breathing difficulty (eg, excessively rapid breathing, breathlessness in the absence of physical exertion)\nq7: I experienced trembling (e.g., in the hands)\nq9: I was worried about situations in which I might panic and make a fool of myself.\nq15: I felt I was close to panic.\nq19: I was aware of the action of my heart in the absence of physical exertion (eg, sense of heart rate increase, heart missing a beat).\nq20: I felt scared without any good reason.\n\nAnd the questions on the Stress subscale:\n\nq1: I found it hard to wind down.\nq6: I tended to over-react to situations.\nq8: I felt that I was using a lot of nervous energy.\nq11: I found myself getting agitated.\nq12: I found it difficult to relax.\nq14: I was intolerant of anything that kept me from getting on with what I was doing.\nq18: I felt that I was rather touchy."
  },
  {
    "objectID": "measurementinvariance_cont.html#statistical-decision-criteria",
    "href": "measurementinvariance_cont.html#statistical-decision-criteria",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.3 Statistical Decision Criteria",
    "text": "7.3 Statistical Decision Criteria\nFor this lab, I will use the following statistical decision criteria for the model comparison tests between levels of invariance. These are based on the knowledge that our samples are relatively large (N = 500 per group), and are informed by the textbook and Chen (2007):\n\nLook at Chi-square Difference test.\n\nIf not significant: retain next level of invariance\nIf significant, look at other fit information\n\nAre there any patterns of problematic correlation residuals &gt; |.10|? Reject next level of invariance, test partial invariance\nDoes CFI decrease ≤ 0.010 or does RMSEA increase by ≥ 0.015? Reject next level of invariance, test partial invariance"
  },
  {
    "objectID": "measurementinvariance_cont.html#configural-invariance",
    "href": "measurementinvariance_cont.html#configural-invariance",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.4 Configural Invariance",
    "text": "7.4 Configural Invariance\nWe will specify a two-factor CFA using lavaan syntax. Based on previous research, this two-factor model already includes residual covariances between two pairs of items. What these items have in common is that they focus on physical symptoms of anxiety, which causes them to share more commmon variance with each other (especially with q4) than with the other anxiety items.\n\ncfa_config &lt;- '\nanxiety =~ q2 + q4 + q7 + q9 + q15 + q19 + q20\nstress =~ q1 + q6 + q8 + q11 + q12 + q14 + q18\n\nq4 ~~ q19\nq4 ~~ q7\n'\n\nWe are going to use a function from the semTools package that will help us set the scale for our latent factors and apply the equality constraint labels in later steps of the measurement invariance testing procedure. This saves us A LOT of typing, especially when moving towards partial invariance. As all indicators are responded to on the same response scale, will use the effect-coding method for scaling the latent factors. This will result in latent factors that have the same mean and variance as the average indicator.\n\nfit.config &lt;- measEq.syntax(configural.model = cfa_config, \n                            data = DASS21, \n                            group = \"engnat\", \n                            ID.fac = \"effects\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"mlr\")\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\ncat(as.character(fit.config@call$model))\n\n## LOADINGS:\n\nanxiety =~ c(NA, NA)*q2 + c(lambda.1_1.g1, lambda.1_1.g2)*q2\nanxiety =~ c(NA, NA)*q4 + c(lambda.2_1.g1, lambda.2_1.g2)*q4\nanxiety =~ c(NA, NA)*q7 + c(lambda.3_1.g1, lambda.3_1.g2)*q7\nanxiety =~ c(NA, NA)*q9 + c(lambda.4_1.g1, lambda.4_1.g2)*q9\nanxiety =~ c(NA, NA)*q15 + c(lambda.5_1.g1, lambda.5_1.g2)*q15\nanxiety =~ c(NA, NA)*q19 + c(lambda.6_1.g1, lambda.6_1.g2)*q19\nanxiety =~ c(NA, NA)*q20 + c(lambda.7_1.g1, lambda.7_1.g2)*q20\nstress =~ c(NA, NA)*q1 + c(lambda.8_2.g1, lambda.8_2.g2)*q1\nstress =~ c(NA, NA)*q6 + c(lambda.9_2.g1, lambda.9_2.g2)*q6\nstress =~ c(NA, NA)*q8 + c(lambda.10_2.g1, lambda.10_2.g2)*q8\nstress =~ c(NA, NA)*q11 + c(lambda.11_2.g1, lambda.11_2.g2)*q11\nstress =~ c(NA, NA)*q12 + c(lambda.12_2.g1, lambda.12_2.g2)*q12\nstress =~ c(NA, NA)*q14 + c(lambda.13_2.g1, lambda.13_2.g2)*q14\nstress =~ c(NA, NA)*q18 + c(lambda.14_2.g1, lambda.14_2.g2)*q18\n\n## INTERCEPTS:\n\nq2 ~ c(NA, NA)*1 + c(nu.1.g1, nu.1.g2)*1\nq4 ~ c(NA, NA)*1 + c(nu.2.g1, nu.2.g2)*1\nq7 ~ c(NA, NA)*1 + c(nu.3.g1, nu.3.g2)*1\nq9 ~ c(NA, NA)*1 + c(nu.4.g1, nu.4.g2)*1\nq15 ~ c(NA, NA)*1 + c(nu.5.g1, nu.5.g2)*1\nq19 ~ c(NA, NA)*1 + c(nu.6.g1, nu.6.g2)*1\nq20 ~ c(NA, NA)*1 + c(nu.7.g1, nu.7.g2)*1\nq1 ~ c(NA, NA)*1 + c(nu.8.g1, nu.8.g2)*1\nq6 ~ c(NA, NA)*1 + c(nu.9.g1, nu.9.g2)*1\nq8 ~ c(NA, NA)*1 + c(nu.10.g1, nu.10.g2)*1\nq11 ~ c(NA, NA)*1 + c(nu.11.g1, nu.11.g2)*1\nq12 ~ c(NA, NA)*1 + c(nu.12.g1, nu.12.g2)*1\nq14 ~ c(NA, NA)*1 + c(nu.13.g1, nu.13.g2)*1\nq18 ~ c(NA, NA)*1 + c(nu.14.g1, nu.14.g2)*1\n\n## UNIQUE-FACTOR VARIANCES:\n\nq2 ~~ c(NA, NA)*q2 + c(theta.1_1.g1, theta.1_1.g2)*q2\nq4 ~~ c(NA, NA)*q4 + c(theta.2_2.g1, theta.2_2.g2)*q4\nq7 ~~ c(NA, NA)*q7 + c(theta.3_3.g1, theta.3_3.g2)*q7\nq9 ~~ c(NA, NA)*q9 + c(theta.4_4.g1, theta.4_4.g2)*q9\nq15 ~~ c(NA, NA)*q15 + c(theta.5_5.g1, theta.5_5.g2)*q15\nq19 ~~ c(NA, NA)*q19 + c(theta.6_6.g1, theta.6_6.g2)*q19\nq20 ~~ c(NA, NA)*q20 + c(theta.7_7.g1, theta.7_7.g2)*q20\nq1 ~~ c(NA, NA)*q1 + c(theta.8_8.g1, theta.8_8.g2)*q1\nq6 ~~ c(NA, NA)*q6 + c(theta.9_9.g1, theta.9_9.g2)*q6\nq8 ~~ c(NA, NA)*q8 + c(theta.10_10.g1, theta.10_10.g2)*q8\nq11 ~~ c(NA, NA)*q11 + c(theta.11_11.g1, theta.11_11.g2)*q11\nq12 ~~ c(NA, NA)*q12 + c(theta.12_12.g1, theta.12_12.g2)*q12\nq14 ~~ c(NA, NA)*q14 + c(theta.13_13.g1, theta.13_13.g2)*q14\nq18 ~~ c(NA, NA)*q18 + c(theta.14_14.g1, theta.14_14.g2)*q18\n\n## UNIQUE-FACTOR COVARIANCES:\n\nq4 ~~ c(NA, NA)*q7 + c(theta.3_2.g1, theta.3_2.g2)*q7\nq4 ~~ c(NA, NA)*q19 + c(theta.6_2.g1, theta.6_2.g2)*q19\n\n## LATENT MEANS/INTERCEPTS:\n\nanxiety ~ c(NA, NA)*1 + c(alpha.1.g1, alpha.1.g2)*1\nstress ~ c(NA, NA)*1 + c(alpha.2.g1, alpha.2.g2)*1\n\n## COMMON-FACTOR VARIANCES:\n\nanxiety ~~ c(NA, NA)*anxiety + c(psi.1_1.g1, psi.1_1.g2)*anxiety\nstress ~~ c(NA, NA)*stress + c(psi.2_2.g1, psi.2_2.g2)*stress\n\n## COMMON-FACTOR COVARIANCES:\n\nanxiety ~~ c(NA, NA)*stress + c(psi.2_1.g1, psi.2_1.g2)*stress\n\n## MODEL CONSTRAINTS:\n\nlambda.1_1.g1 == 7 - lambda.2_1.g1 - lambda.3_1.g1 - lambda.4_1.g1 - lambda.5_1.g1 - lambda.6_1.g1 - lambda.7_1.g1\nlambda.1_1.g2 == 7 - lambda.2_1.g2 - lambda.3_1.g2 - lambda.4_1.g2 - lambda.5_1.g2 - lambda.6_1.g2 - lambda.7_1.g2\nnu.1.g1 == 7 - nu.2.g1 - nu.3.g1 - nu.4.g1 - nu.5.g1 - nu.6.g1 - nu.7.g1\nnu.1.g2 == 7 - nu.2.g2 - nu.3.g2 - nu.4.g2 - nu.5.g2 - nu.6.g2 - nu.7.g2\nlambda.8_2.g1 == 7 - lambda.9_2.g1 - lambda.10_2.g1 - lambda.11_2.g1 - lambda.12_2.g1 - lambda.13_2.g1 - lambda.14_2.g1\nlambda.8_2.g2 == 7 - lambda.9_2.g2 - lambda.10_2.g2 - lambda.11_2.g2 - lambda.12_2.g2 - lambda.13_2.g2 - lambda.14_2.g2\nnu.8.g1 == 7 - nu.9.g1 - nu.10.g1 - nu.11.g1 - nu.12.g1 - nu.13.g1 - nu.14.g1\nnu.8.g2 == 7 - nu.9.g2 - nu.10.g2 - nu.11.g2 - nu.12.g2 - nu.13.g2 - nu.14.g2\n\n\nTo see if the configural model is tenable, we will first inspect indices of global (exact and approximate) fit:\n\nsummary(fit.config, fit.measures = T, estimates = F)\n\nlavaan 0.6.17 ended normally after 55 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        98\n  Number of equality constraints                     8\n\n  Number of observations per group:                   \n    EnglishNative                                  500\n    ELL                                            500\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               373.938     315.353\n  Degrees of freedom                               148         148\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.186\n    Yuan-Bentler correction (Mplus variant)                       \n  Test statistic for each group:\n    EnglishNative                              224.144     189.027\n    ELL                                        149.794     126.326\n\nModel Test Baseline Model:\n\n  Test statistic                              6539.400    5341.435\n  Degrees of freedom                               182         182\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.224\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.964       0.968\n  Tucker-Lewis Index (TLI)                       0.956       0.960\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.969\n  Robust Tucker-Lewis Index (TLI)                            0.961\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -17763.167  -17763.167\n  Scaling correction factor                                  0.893\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)     -17576.198  -17576.198\n  Scaling correction factor                                  1.105\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               35706.333   35706.333\n  Bayesian (BIC)                             36148.031   36148.031\n  Sample-size adjusted Bayesian (SABIC)      35862.186   35862.186\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.055       0.048\n  90 Percent confidence interval - lower         0.048       0.041\n  90 Percent confidence interval - upper         0.062       0.054\n  P-value H_0: RMSEA &lt;= 0.050                    0.104       0.719\n  P-value H_0: RMSEA &gt;= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.052\n  90 Percent confidence interval - lower                     0.044\n  90 Percent confidence interval - upper                     0.060\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.345\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.032       0.032\n\n\nThe Chi-square test is significant, but the approximate fit indices look OK. Our sample is relatively large, so we will look at the local fit indices to see if any remaining misfit is trivial, or if there are major issues:\n\nresiduals(fit.config, type = \"cor.bollen\")\n\n$EnglishNative\n$EnglishNative$type\n[1] \"cor.bollen\"\n\n$EnglishNative$cov\n        q2     q4     q7     q9    q15    q19    q20     q1     q6     q8\nq2   0.000                                                               \nq4   0.081  0.000                                                        \nq7   0.059  0.020  0.000                                                 \nq9  -0.023 -0.056  0.015  0.000                                          \nq15 -0.053  0.019 -0.011 -0.004  0.000                                   \nq19  0.057  0.003  0.076 -0.037 -0.026  0.000                            \nq20 -0.051  0.023 -0.031  0.039  0.008 -0.023  0.000                     \nq1  -0.010 -0.050 -0.036 -0.018  0.003  0.019 -0.014  0.000              \nq6   0.001 -0.044 -0.035  0.040  0.011 -0.008 -0.023 -0.033  0.000       \nq8   0.032  0.019  0.103  0.060  0.092  0.045  0.076 -0.028 -0.024  0.000\nq11  0.018 -0.051 -0.073  0.009 -0.024 -0.023 -0.005 -0.012  0.056 -0.034\nq12 -0.023 -0.012 -0.050 -0.035  0.022 -0.024 -0.043  0.092 -0.013 -0.006\nq14  0.065 -0.030 -0.001 -0.013 -0.031  0.033 -0.017  0.031  0.001 -0.089\nq18  0.051  0.021  0.002  0.019 -0.048  0.016 -0.003 -0.037  0.054 -0.021\n       q11    q12    q14    q18\nq2                             \nq4                             \nq7                             \nq9                             \nq15                            \nq19                            \nq20                            \nq1                             \nq6                             \nq8                             \nq11  0.000                     \nq12 -0.017  0.000              \nq14  0.096 -0.027  0.000       \nq18  0.006 -0.011  0.036  0.000\n\n$EnglishNative$mean\n q2  q4  q7  q9 q15 q19 q20  q1  q6  q8 q11 q12 q14 q18 \n  0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n\n\n$ELL\n$ELL$type\n[1] \"cor.bollen\"\n\n$ELL$cov\n        q2     q4     q7     q9    q15    q19    q20     q1     q6     q8\nq2   0.000                                                               \nq4   0.076  0.000                                                        \nq7   0.035  0.009  0.000                                                 \nq9  -0.015 -0.032 -0.027  0.000                                          \nq15 -0.040  0.017  0.011  0.035  0.000                                   \nq19  0.030  0.007  0.041 -0.073  0.008  0.000                            \nq20  0.002 -0.048 -0.017  0.017  0.009 -0.040  0.000                     \nq1  -0.020 -0.011 -0.029 -0.055 -0.045  0.007 -0.023  0.000              \nq6   0.003  0.001 -0.021 -0.005 -0.019 -0.013  0.004  0.038  0.000       \nq8   0.037  0.038  0.078  0.077  0.066  0.069  0.037 -0.055 -0.047  0.000\nq11  0.030 -0.021 -0.058 -0.008 -0.016  0.018  0.028  0.032 -0.024 -0.014\nq12 -0.034 -0.001 -0.028 -0.023 -0.022  0.037  0.001  0.066 -0.012 -0.008\nq14 -0.020 -0.002 -0.005  0.002 -0.053 -0.020 -0.009  0.027  0.032 -0.006\nq18  0.015  0.006  0.019  0.023 -0.047  0.044  0.020 -0.036  0.086 -0.036\n       q11    q12    q14    q18\nq2                             \nq4                             \nq7                             \nq9                             \nq15                            \nq19                            \nq20                            \nq1                             \nq6                             \nq8                             \nq11  0.000                     \nq12 -0.001  0.000              \nq14 -0.002 -0.001  0.000       \nq18  0.025 -0.034  0.004  0.000\n\n$ELL$mean\n q2  q4  q7  q9 q15 q19 q20  q1  q6  q8 q11 q12 q14 q18 \n  0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n\n\nOverall, the correlation residuals look good. Only the correlation residual of q7 and q8 was &gt; .1 (it was .103) in the English native speaker group. There is no a priori justification why these two items, which load onto different factors, share an omitted cause (that could be accommodated via a residual covariance). In addition, the correlation residual was relatively close to .1, indicating that adding the residual covariance would likely only have a small impact on global model fit. Based on these results, we will retain the configural invariance model, and examine weak (metric) invariance.\n\nParameter Estimate Interpretation\nUsing the function below, we can compare the estimates across groups and see that all the measurement-related parameters are still varying across groups (as we have not included any equality constraints yet).\n\ngroup_by_groups(fit.config)\n\n       lhs op     rhs est_EnglishNative est_ELL\n1  anxiety =~     q15             1.183   1.207\n2  anxiety =~     q19             0.902   0.964\n3  anxiety =~      q2             0.781   0.817\n4  anxiety =~     q20             1.102   1.162\n5  anxiety =~      q4             1.015   0.904\n6  anxiety =~      q7             0.935   0.906\n7  anxiety =~      q9             1.082   1.041\n8   stress =~      q1             1.063   0.996\n9   stress =~     q11             0.997   1.011\n10  stress =~     q12             1.097   1.090\n11  stress =~     q14             0.834   0.927\n12  stress =~     q18             0.893   0.819\n13  stress =~      q6             1.037   1.052\n14  stress =~      q8             1.081   1.105\n15 anxiety ~~ anxiety             0.560   0.494\n16 anxiety ~~  stress             0.508   0.454\n17      q1 ~~      q1             0.503   0.434\n18     q11 ~~     q11             0.541   0.501\n19     q12 ~~     q12             0.483   0.499\n20     q14 ~~     q14             0.695   0.568\n21     q15 ~~     q15             0.400   0.403\n22     q18 ~~     q18             0.804   0.749\n23     q19 ~~     q19             0.817   0.755\n24      q2 ~~      q2             1.036   0.886\n25     q20 ~~     q20             0.616   0.486\n26      q4 ~~     q19             0.210   0.182\n27      q4 ~~      q4             0.636   0.672\n28      q4 ~~      q7             0.028   0.136\n29      q6 ~~      q6             0.538   0.562\n30      q7 ~~      q7             0.649   0.684\n31      q8 ~~      q8             0.571   0.476\n32      q9 ~~      q9             0.660   0.604\n33  stress ~~  stress             0.569   0.505\n34 anxiety ~1                     1.308   1.180\n35      q1 ~1                     0.880   0.886\n36     q11 ~1                     1.135   0.922\n37     q12 ~1                     0.937   0.905\n38     q14 ~1                     1.043   1.029\n39     q15 ~1                     0.879   0.662\n40     q18 ~1                     1.094   1.439\n41     q19 ~1                     1.117   1.047\n42      q2 ~1                     1.121   1.312\n43     q20 ~1                     0.925   0.900\n44      q4 ~1                     0.764   0.836\n45      q6 ~1                     1.038   1.005\n46      q7 ~1                     0.869   0.851\n47      q8 ~1                     0.874   0.814\n48      q9 ~1                     1.324   1.392\n49  stress ~1                     1.549   1.351"
  },
  {
    "objectID": "measurementinvariance_cont.html#weak-metric-invariance",
    "href": "measurementinvariance_cont.html#weak-metric-invariance",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.5 Weak (Metric) Invariance",
    "text": "7.5 Weak (Metric) Invariance\nThis is where the semTools function really comes in handy. All we need to do to estimate the Weak Invariance model is change the arguments of the function a little bit:\n\nfit.weak &lt;- measEq.syntax(configural.model = cfa_config, \n                          data = DASS21, \n                          group = \"engnat\", \n                          ID.fac = \"effects\", \n                          meanstructure = TRUE, \n                          return.fit = TRUE,\n                          estimator = \"mlr\",\n                          group.equal = \"loadings\")\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.weak@call$model))\n\nIn the model syntax above (if you remove the # and run the line of code), you can see that each factor loading now has the same label across the two groups, ensuring that they are constraint to be equal.\n\nModel Comparison\nTo test if we can retain the Weak Invariance model, we compare its fit to that of the Configural Invariance model:\n\ncomp_12 &lt;- compareFit(fit.config, fit.weak)\nsummary(comp_12)\n\n################### Nested Model Comparison #########################\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n            Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)\nfit.config 148 35706 36148 373.94                              \nfit.weak   160 35691 36074 382.85     11.021      12     0.5271\n\n####################### Model Fit Indices ###########################\n           chisq.scaled df.scaled pvalue.scaled rmsea.robust cfi.robust\nfit.config     315.353†       148          .000        .052       .969 \nfit.weak       330.756        160          .000        .050†      .969†\n           tli.robust  srmr        aic        bic\nfit.config      .961  .032† 35706.333  36148.031 \nfit.weak        .964† .036  35691.248† 36074.053†\n\n################## Differences in Fit Indices #######################\n                      df.scaled rmsea.robust cfi.robust tli.robust  srmr\nfit.weak - fit.config        12       -0.002          0      0.003 0.004\n                          aic     bic\nfit.weak - fit.config -15.086 -73.979\n\n\nWhat does the Chi-square difference test result tell us?\n\n\nParameter Estimate Interpretation\nUsing the function below, we can compare the estimates across groups and see that all the loadings are now exactly the same (because we constrained them to be). Other parameters are still varying across groups.\n\ngroup_by_groups(fit.weak)\n\n       lhs op     rhs est_EnglishNative est_ELL\n1  anxiety =~     q15             1.192   1.192\n2  anxiety =~     q19             0.930   0.930\n3  anxiety =~      q2             0.798   0.798\n4  anxiety =~     q20             1.130   1.130\n5  anxiety =~      q4             0.964   0.964\n6  anxiety =~      q7             0.925   0.925\n7  anxiety =~      q9             1.061   1.061\n8   stress =~      q1             1.028   1.028\n9   stress =~     q11             1.004   1.004\n10  stress =~     q12             1.093   1.093\n11  stress =~     q14             0.882   0.882\n12  stress =~     q18             0.857   0.857\n13  stress =~      q6             1.044   1.044\n14  stress =~      q8             1.093   1.093\n15 anxiety ~~ anxiety             0.559   0.499\n16 anxiety ~~  stress             0.508   0.456\n17      q1 ~~      q1             0.508   0.430\n18     q11 ~~     q11             0.539   0.502\n19     q12 ~~     q12             0.486   0.498\n20     q14 ~~     q14             0.692   0.574\n21     q15 ~~     q15             0.400   0.403\n22     q18 ~~     q18             0.808   0.747\n23     q19 ~~     q19             0.814   0.758\n24      q2 ~~      q2             1.036   0.886\n25     q20 ~~     q20             0.613   0.491\n26      q4 ~~     q19             0.211   0.179\n27      q4 ~~      q4             0.645   0.666\n28      q4 ~~      q7             0.033   0.132\n29      q6 ~~      q6             0.537   0.562\n30      q7 ~~      q7             0.651   0.681\n31      q8 ~~      q8             0.570   0.479\n32      q9 ~~      q9             0.663   0.601\n33  stress ~~  stress             0.569   0.505\n34 anxiety ~1                     1.308   1.180\n35      q1 ~1                     0.934   0.842\n36     q11 ~1                     1.123   0.931\n37     q12 ~1                     0.944   0.901\n38     q14 ~1                     0.968   1.090\n39     q15 ~1                     0.867   0.679\n40     q18 ~1                     1.149   1.388\n41     q19 ~1                     1.080   1.087\n42      q2 ~1                     1.099   1.335\n43     q20 ~1                     0.888   0.937\n44      q4 ~1                     0.831   0.765\n45      q6 ~1                     1.027   1.015\n46      q7 ~1                     0.882   0.828\n47      q8 ~1                     0.856   0.831\n48      q9 ~1                     1.353   1.369\n49  stress ~1                     1.549   1.351\n\n\nWhen we retain the Weak Invariance model, we can conclude that the measured concepts (Anxiety and Stress) have the same meaning across groups, because the item-factor associations can be considered equivalent (the same amount of common variance is extracted across groups)."
  },
  {
    "objectID": "measurementinvariance_cont.html#strong-invariance",
    "href": "measurementinvariance_cont.html#strong-invariance",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.6 Strong Invariance",
    "text": "7.6 Strong Invariance\nAgain, all we need to do to estimate the Weak Invariance model is change the arguments of the function a little bit:\n\nfit.strong &lt;- measEq.syntax(configural.model = cfa_config, \n                            data = DASS21, \n                            group = \"engnat\", \n                            ID.fac = \"effects\", \n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"mlr\",\n                            group.equal = c(\"loadings\", \"intercepts\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.strong@call$model))\n\n\nModel Comparison\nTo test if we can retain the Strong Invariance model, we compare its fit to that of the Weak Invariance model:\n\ncomp_23 &lt;- compareFit(fit.weak, fit.strong)\nsummary(comp_23)\n\n################### Nested Model Comparison #########################\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n            Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit.weak   160 35691 36074 382.85                                  \nfit.strong 172 35748 36072 463.60     81.276      12  2.356e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n           chisq.scaled df.scaled pvalue.scaled rmsea.robust cfi.robust\nfit.weak       330.756†       160          .000        .050†      .969†\nfit.strong     404.514        172          .000        .056       .958 \n           tli.robust  srmr        aic        bic\nfit.weak        .964† .036† 35691.248† 36074.053 \nfit.strong      .955  .042  35747.993  36071.905†\n\n################## Differences in Fit Indices #######################\n                      df.scaled rmsea.robust cfi.robust tli.robust  srmr    aic\nfit.strong - fit.weak        12        0.006     -0.011     -0.009 0.006 56.745\n                         bic\nfit.strong - fit.weak -2.148\n\n\nWhat does the Chi-square difference test result tell us?\n\n\nLocal Fit Comparison\nSince the fit worsened significantly when testing Strong Invariance, we will focus on problematic residuals in the mean vectors, since constraining the intercepts will affect model fit by changing the model implied means.\n\nresiduals(fit.strong, type = \"cor.bollen\")$EnglishNative$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n-0.119  0.014  0.009 -0.023  0.067 -0.017 -0.042  0.032 -0.006 -0.002  0.080 \n   q12    q14    q18 \n 0.006 -0.074 -0.118 \n\nresiduals(fit.strong, type = \"cor.bollen\")$ELL$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n 0.108 -0.018 -0.012  0.022 -0.069  0.017  0.035 -0.030  0.007  0.002 -0.078 \n   q12    q14    q18 \n-0.007  0.064  0.116 \n\n\nYou will notice that mean residuals for a specific indicator are negative for one group and positive for the other. When we constrain intercepts to be equal across groups, the estimate tends to find a compromise between the two group intercepts. Thus, one group will always have an observed mean that is above that estimate while the other has an observed mean that is below that estimate.\nWhich intercepts appear to be different across groups?"
  },
  {
    "objectID": "measurementinvariance_cont.html#partial-strong-invariance-round-1",
    "href": "measurementinvariance_cont.html#partial-strong-invariance-round-1",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.7 Partial Strong Invariance (Round 1)",
    "text": "7.7 Partial Strong Invariance (Round 1)\nSince the model fit indicated some issues with retaining the Strong Invariance model, we will now examine Partial Strong Invariance. Remember what we already saw in the local fit evaluation of the mean residuals. Next, we will use the Backwards MI approach, using modification indices to evaluate which equality constraint would improve fit most if removed from the model. When working with equality constraints, we cannot use the modificationindices() function. Instead, we need to use the lavTestScore() function. The output provides the same information, but in a less accessible format. In the code below, I am excluding the first four rows of output (by asking for 5:32) to hide the effect-coding equality constraints, which take up a lot of space. You can omit the [5:32,] part.\n\nlavTestScore(fit.strong)$uni[5:32,]\n\n\nunivariate score tests:\n\n     lhs op   rhs     X2 df p.value\n5   .p1. == .p50. 17.694  1   0.000\n6   .p2. == .p51.  1.809  1   0.179\n7   .p3. == .p52.  0.150  1   0.698\n8   .p4. == .p53.  0.708  1   0.400\n9   .p5. == .p54. 16.959  1   0.000\n10  .p6. == .p55.  1.459  1   0.227\n11  .p7. == .p56.  4.825  1   0.028\n12  .p8. == .p57.  3.574  1   0.059\n13  .p9. == .p58.  0.147  1   0.701\n14 .p10. == .p59.  0.035  1   0.852\n15 .p11. == .p60. 13.575  1   0.000\n16 .p12. == .p61.  0.131  1   0.717\n17 .p13. == .p62. 10.311  1   0.001\n18 .p14. == .p63. 18.197  1   0.000\n19 .p15. == .p64. 18.309  1   0.000\n20 .p16. == .p65.  0.738  1   0.390\n21 .p17. == .p66.  0.116  1   0.734\n22 .p18. == .p67.  1.210  1   0.271\n23 .p19. == .p68. 19.397  1   0.000\n24 .p20. == .p69.  0.813  1   0.367\n25 .p21. == .p70.  4.146  1   0.042\n26 .p22. == .p71.  2.654  1   0.103\n27 .p23. == .p72.  0.109  1   0.741\n28 .p24. == .p73.  0.007  1   0.932\n29 .p25. == .p74. 15.167  1   0.000\n30 .p26. == .p75.  0.126  1   0.723\n31 .p27. == .p76.  8.698  1   0.003\n32 .p28. == .p77. 22.118  1   0.000\n\n\nReleasing the equality constraint of .p28 and .p77 is associated with the largest expected change in the model Chi-square test. But what are these parameters? We can add some arguments to the lavTestScore() function to get a table with the expected parameter changes for released constraints, which has more information about the specific parameters. I will filter out only the intercepts so the output is not too long:\n\nlavTestScore(fit.strong, epc = TRUE, standardized = FALSE)$epc %&gt;% \n  filter(str_detect(label, \"nu.\"))\n\nWarning in lavTestScore(fit.strong, epc = TRUE, standardized = FALSE): lavaan\nWARNING: se is not `standard'; not implemented yet; falling back to ordinary\nscore test\n\n\n\nexpected parameter changes (epc) and expected parameter values (epv):\n\n   lhs op rhs block group free label plabel    est    epc    epv\n1   q2 ~1         1     1   15  nu.1  .p15.  0.474 -0.136  0.339\n2   q4 ~1         1     1   16  nu.2  .p16. -0.180 -0.083 -0.263\n3   q7 ~1         1     1   17  nu.3  .p17. -0.082  0.005 -0.077\n4   q9 ~1         1     1   18  nu.4  .p18.  0.301 -0.074  0.226\n5  q15 ~1         1     1   19  nu.5  .p19. -0.457  0.147 -0.310\n6  q19 ~1         1     1   20  nu.6  .p20.  0.152  0.054  0.205\n7  q20 ~1         1     1   21  nu.7  .p21. -0.207  0.021 -0.186\n8   q1 ~1         1     1   22  nu.8  .p22. -0.171 -0.025 -0.196\n9   q6 ~1         1     1   23  nu.9  .p23. -0.027  0.018 -0.009\n10  q8 ~1         1     1   24 nu.10  .p24. -0.260  0.039 -0.221\n11 q11 ~1         1     1   25 nu.11  .p25. -0.031  0.162  0.131\n12 q12 ~1         1     1   26 nu.12  .p26. -0.187  0.018 -0.169\n13 q14 ~1         1     1   27 nu.13  .p27.  0.189  0.017  0.205\n14 q18 ~1         1     1   28 nu.14  .p28.  0.488 -0.292  0.196\n15  q2 ~1         2     2   64  nu.1  .p64.  0.474  0.024  0.498\n16  q4 ~1         2     2   65  nu.2  .p65. -0.180  0.116 -0.064\n17  q7 ~1         2     2   66  nu.3  .p66. -0.082  0.031 -0.050\n18  q9 ~1         2     2   67  nu.4  .p67.  0.301  0.055  0.356\n19 q15 ~1         2     2   68  nu.5  .p68. -0.457 -0.081 -0.538\n20 q19 ~1         2     2   69  nu.6  .p69.  0.152 -0.066  0.085\n21 q20 ~1         2     2   70  nu.7  .p70. -0.207 -0.048 -0.255\n22  q1 ~1         2     2   71  nu.8  .p71. -0.171  0.065 -0.107\n23  q6 ~1         2     2   72  nu.9  .p72. -0.027 -0.019 -0.046\n24  q8 ~1         2     2   73 nu.10  .p73. -0.260 -0.029 -0.289\n25 q11 ~1         2     2   74 nu.11  .p74. -0.031 -0.053 -0.084\n26 q12 ~1         2     2   75 nu.12  .p75. -0.187  0.000 -0.187\n27 q14 ~1         2     2   76 nu.13  .p76.  0.189 -0.085  0.104\n28 q18 ~1         2     2   77 nu.14  .p77.  0.488  0.139  0.627\n\n\nFrom this table, we can see that .p28 and .p77 are the parameter labels for the intercept of q18, which also had a larger correlation residual. This question is worded as follows: ‘I felt that I was rather touchy’. The output above tells us something about what the intercept for this item would be if it were freely estimated across groups (in the epv [expected parameter value] column).\nFrom this information, we can see that the intercept for English Native speakers would decrease from .488 to .196. This indicates that, for English Native speakers with a true value of 0 on Stress, their expected response to this item is close to 0 (or the average intercept across all indicators of Stress).\nIn contrast, for the ELL group, we can see that the intercept would increase from .488 to .627. This indicates that, for ELL speakers with a true value of 0 on Stress, their expected response to this item is further away from 0 (so higher that the average intercept of all indicators of Stress).\nIn other words, when English Native Speakers and ELL Speakers experience the same underlying levels of stress, ELL Speakers respond with a higher response option to ‘I felt that I was rather touchy’.\nTo test if releasing this constraint improves the fit of the Partial Strong Model sufficiently, we need to estimate the partial model. To do so, we can use the group.partial argument in the measEq.syntax() function:\n\nfit.partial1 &lt;- measEq.syntax(configural.model = cfa_config, \n                              data = DASS21, \n                              group = \"engnat\", \n                              ID.fac = \"effects\", \n                              meanstructure = TRUE, \n                              return.fit = TRUE,\n                              estimator = \"mlr\",\n                              group.equal = c(\"loadings\", \"intercepts\"),\n                              group.partial = \"q18 ~ 1\")\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial1@call$model))\n\n\nModel Comparison\nLet’s compare the fit of this model to the Weak Invariance model\n\ncomp_23b &lt;- compareFit(fit.weak, fit.partial1)\nsummary(comp_23b)\n\n################### Nested Model Comparison #########################\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n              Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit.weak     160 35691 36074 382.85                                  \nfit.partial1 171 35728 36056 441.15     58.446      11    1.8e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n             chisq.scaled df.scaled pvalue.scaled rmsea.robust cfi.robust\nfit.weak         330.756†       160          .000        .050†      .969†\nfit.partial1     384.540        171          .000        .054       .961 \n             tli.robust  srmr        aic        bic\nfit.weak          .964† .036† 35691.248† 36074.053 \nfit.partial1      .959  .041  35727.542  36056.361†\n\n################## Differences in Fit Indices #######################\n                        df.scaled rmsea.robust cfi.robust tli.robust  srmr\nfit.partial1 - fit.weak        11        0.004     -0.007     -0.006 0.004\n                           aic     bic\nfit.partial1 - fit.weak 36.294 -17.692\n\n\nWhat do the results indicate?\n\n\nLocal Fit Evaluation\nSince the fit worsened significantly when testing Strong Invariance, we will focus on problematic residuals in the mean vectors.\n\nresiduals(fit.partial1, type = \"cor.bollen\")$EnglishNative$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n-0.119  0.014  0.009 -0.023  0.067 -0.017 -0.041  0.021 -0.017 -0.013  0.069 \n   q12    q14    q18 \n-0.004 -0.083  0.000 \n\nresiduals(fit.partial1, type = \"cor.bollen\")$ELL$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n 0.108 -0.018 -0.013  0.022 -0.069  0.017  0.035 -0.019  0.018  0.012 -0.067 \n   q12    q14    q18 \n 0.005  0.072  0.000 \n\n\nWhat do you think the next indicator is that we need to focus on?"
  },
  {
    "objectID": "measurementinvariance_cont.html#partial-strong-invariance-round-2",
    "href": "measurementinvariance_cont.html#partial-strong-invariance-round-2",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.8 Partial Strong Invariance (Round 2)",
    "text": "7.8 Partial Strong Invariance (Round 2)\nSince the model fit indicated some remaining issues with retaining the Partial Strong Invariance model, we will do another round of partial invariance testing:\n\nlavTestScore(fit.partial1)$uni[5:31,]\n\nWarning in lavTestScore(fit.partial1): lavaan WARNING: se is not `standard';\nnot implemented yet; falling back to ordinary score test\n\n\n\nunivariate score tests:\n\n     lhs op   rhs     X2 df p.value\n5   .p1. == .p50. 17.693  1   0.000\n6   .p2. == .p51.  1.813  1   0.178\n7   .p3. == .p52.  0.151  1   0.697\n8   .p4. == .p53.  0.706  1   0.401\n9   .p5. == .p54. 16.953  1   0.000\n10  .p6. == .p55.  1.459  1   0.227\n11  .p7. == .p56.  4.822  1   0.028\n12  .p8. == .p57.  1.808  1   0.179\n13  .p9. == .p58.  0.825  1   0.364\n14 .p10. == .p59.  0.567  1   0.451\n15 .p11. == .p60. 10.119  1   0.001\n16 .p12. == .p61.  0.049  1   0.825\n17 .p13. == .p62. 12.957  1   0.000\n18 .p14. == .p63.  0.903  1   0.342\n19 .p15. == .p64. 18.311  1   0.000\n20 .p16. == .p65.  0.739  1   0.390\n21 .p17. == .p66.  0.116  1   0.733\n22 .p18. == .p67.  1.208  1   0.272\n23 .p19. == .p68. 19.398  1   0.000\n24 .p20. == .p69.  0.812  1   0.367\n25 .p21. == .p70.  4.142  1   0.042\n26 .p22. == .p71.  1.116  1   0.291\n27 .p23. == .p72.  0.761  1   0.383\n28 .p24. == .p73.  0.448  1   0.503\n29 .p25. == .p74. 11.478  1   0.001\n30 .p26. == .p75.  0.063  1   0.802\n31 .p27. == .p76. 11.226  1   0.001\n\n\nReleasing the equality constraint of .p19 and .p68 is associated with the largest expected change in the model Chi-square test (19.398), followed closely by the constraint of .p15 and .p64 (18.311). Let’s look at the alternative lavTestScore() output to find out what intercepts these are.\n\nlavTestScore(fit.partial1, epc = TRUE, standardized = FALSE)$epc %&gt;% \n  filter(str_detect(label, \"nu.\"))\n\nWarning in lavTestScore(fit.partial1, epc = TRUE, standardized = FALSE): lavaan\nWARNING: se is not `standard'; not implemented yet; falling back to ordinary\nscore test\n\n\n\nexpected parameter changes (epc) and expected parameter values (epv):\n\n   lhs op rhs block group free    label plabel    est    epc    epv\n1   q2 ~1         1     1   15     nu.1  .p15.  0.474 -0.136  0.338\n2   q4 ~1         1     1   16     nu.2  .p16. -0.181 -0.083 -0.263\n3   q7 ~1         1     1   17     nu.3  .p17. -0.082  0.005 -0.077\n4   q9 ~1         1     1   18     nu.4  .p18.  0.300 -0.074  0.226\n5  q15 ~1         1     1   19     nu.5  .p19. -0.456  0.147 -0.309\n6  q19 ~1         1     1   20     nu.6  .p20.  0.151  0.054  0.205\n7  q20 ~1         1     1   21     nu.7  .p21. -0.207  0.022 -0.186\n8   q1 ~1         1     1   22     nu.8  .p22. -0.089 -0.048 -0.137\n9   q6 ~1         1     1   23     nu.9  .p23.  0.054 -0.008  0.046\n10  q8 ~1         1     1   24    nu.10  .p24. -0.171  0.010 -0.161\n11 q11 ~1         1     1   25    nu.11  .p25.  0.044  0.139  0.184\n12 q12 ~1         1     1   26    nu.12  .p26. -0.099 -0.010 -0.109\n13 q14 ~1         1     1   27    nu.13  .p27.  0.262 -0.012  0.249\n14 q18 ~1         1     1   28 nu.14.g1  .p28.  0.327 -0.088  0.239\n15  q2 ~1         2     2   64     nu.1  .p64.  0.474  0.024  0.498\n16  q4 ~1         2     2   65     nu.2  .p65. -0.181  0.116 -0.064\n17  q7 ~1         2     2   66     nu.3  .p66. -0.082  0.031 -0.050\n18  q9 ~1         2     2   67     nu.4  .p67.  0.300  0.055  0.356\n19 q15 ~1         2     2   68     nu.5  .p68. -0.456 -0.081 -0.537\n20 q19 ~1         2     2   69     nu.6  .p69.  0.151 -0.066  0.085\n21 q20 ~1         2     2   70     nu.7  .p70. -0.207 -0.048 -0.255\n22  q1 ~1         2     2   71     nu.8  .p71. -0.089  0.068 -0.021\n23  q6 ~1         2     2   72     nu.9  .p72.  0.054 -0.012  0.042\n24  q8 ~1         2     2   73    nu.10  .p73. -0.171 -0.022 -0.194\n25 q11 ~1         2     2   74    nu.11  .p74.  0.044 -0.044  0.000\n26 q12 ~1         2     2   75    nu.12  .p75. -0.099  0.007 -0.093\n27 q14 ~1         2     2   76    nu.13  .p76.  0.262 -0.078  0.183\n28 q18 ~1         2     2   77 nu.14.g2  .p77.  0.607  0.085  0.692\n\n\nFrom this table, we can see that .p19 and .p68 are the parameter labels for the intercept of q15. This question did not necessarily have a large mean residual (that was q2, which is associated with the second largest drop in Chi Square based on the table above). However, if we look at the epv column, we can see that the intercepts are expected to be more different across groups for q15 compared to q2.\nItem q15 is worded as follows: ‘I felt I was close to panic’, and if released, the intercept would be lower for ELL speakers than for English Native speakers. This means that at a true level of 0 on Anxiety, ELL report less feelings of ‘panic’ compared to English Native speakers.\nItem q2 is worded as follows: ‘I was aware of dryness in my mouth’, and if released, the intercept would be higher for ELL speakers than for English Native speakers. This means that at a true level of 0 on Anxiety, ELL report more experience of ‘dry mouth’ than English Native speakers.\nI don’t have much theoretical justification for freeing either of these intercepts. Maybe they are both kind of strange statements for ELL speakers? We are definitely going into a more exploratory mode of invariance testing here. Given the fact that the expected change in fit between these two options is very similar, but the larger mean residual was associated with q2, I’ve decided to release the intercept of q2 next. Note that you might make a different decision.\nTo test if releasing this constraint improves the fit of the Partial Strong Model sufficiently, we need to estimate a second partial model. To do so, we can use the group.partial argument in the measEq.syntax() function and add this second intercept:\n\nfit.partial2 &lt;- measEq.syntax(configural.model = cfa_config, \n                              data = DASS21, \n                              group = \"engnat\", \n                              ID.fac = \"effects\", \n                              meanstructure = TRUE, \n                              return.fit = TRUE,\n                              estimator = \"mlr\",\n                              group.equal = c(\"loadings\", \"intercepts\"),\n                              group.partial = c(\"q18~1\", \"q2~1\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial2@call$model))\n\nLet’s compare the fit of this model to the Weak Invariance model\n\ncomp_23c &lt;- compareFit(fit.weak, fit.partial2)\nsummary(comp_23c)\n\n################### Nested Model Comparison #########################\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n              Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit.weak     160 35691 36074 382.85                                  \nfit.partial2 170 35711 36045 422.62     39.744      10   1.88e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n             chisq.scaled df.scaled pvalue.scaled rmsea.robust cfi.robust\nfit.weak         330.756†       160          .000        .050†      .969†\nfit.partial2     368.046        170          .000        .052       .964 \n             tli.robust  srmr        aic        bic\nfit.weak          .964† .036† 35691.248† 36074.053 \nfit.partial2      .961  .039  35711.011  36044.738†\n\n################## Differences in Fit Indices #######################\n                        df.scaled rmsea.robust cfi.robust tli.robust  srmr\nfit.partial2 - fit.weak        10        0.002     -0.005     -0.003 0.003\n                           aic     bic\nfit.partial2 - fit.weak 19.763 -29.314\n\n\nWhat do the results indicate?\n\nLocal Fit Evaluation\nAgain, we will focus on the residuals of the mean vectors.\n\nresiduals(fit.partial2, type = \"cor.bollen\")$EnglishNative$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n 0.000  0.006  0.001 -0.032  0.056 -0.025 -0.052  0.021 -0.017 -0.013  0.069 \n   q12    q14    q18 \n-0.004 -0.083  0.000 \n\nresiduals(fit.partial2, type = \"cor.bollen\")$ELL$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n 0.000 -0.008 -0.003  0.032 -0.058  0.025  0.044 -0.019  0.018  0.012 -0.067 \n   q12    q14    q18 \n 0.005  0.072  0.000 \n\n\nThis time, we don’t see any problems with the mean vector in terms of local fit.\n\n\nCFI and RMSEA Comparison\nNext, we will examine if the CFI and RMSEA change to a lesser extent than our criteria (decrease in CFI ≤ 0.010, increase in RMSEA ≤ 0.015):\n\n# Change in CFI\ncat(paste0(\"Change in CFI: \", comp_23c@fit.diff$cfi.robust))\n\nChange in CFI: -0.00471114055415356\n\n# Change in RMSEA\ncat(paste0(\"Change in RMSEA: \", comp_23c@fit.diff$rmsea.robust))\n\nChange in RMSEA: 0.00201878813551178\n\n\nThese are much smaller than our cutoff criteria (see statistical decision criteria above). They are also smaller than other suggested criteria (e.g., decrease in CFI ≤ 0.002 or increase in RMSEA ≤ 0.010). Based on this information, I will retain this partial strong invariant model with two freely estimated intercepts."
  },
  {
    "objectID": "measurementinvariance_cont.html#parameter-comparison-across-groups",
    "href": "measurementinvariance_cont.html#parameter-comparison-across-groups",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.9 Parameter Comparison Across Groups",
    "text": "7.9 Parameter Comparison Across Groups\nNow that we have finalized the invariance testing procedure (note that you could test higher levels of invariance, but that these offer few practical benefits), we can continue to compare latent factor variances, covariances, and means across groups.\n\nFactor Variances\nFirst, we will test if the factor variances of the Anxiety and Stress factors are equivalent across groups. We will do so by adding lv.variances to the group.equal argument of the previous partial strong invariance model.\n\nfit.partial2.lv &lt;- measEq.syntax(configural.model = cfa_config, \n                              data = DASS21, \n                              group = \"engnat\", \n                              ID.fac = \"effects\", \n                              meanstructure = TRUE, \n                              return.fit = TRUE,\n                              estimator = \"mlr\",\n                              group.equal = c(\"loadings\", \"intercepts\", \n                                          \"lv.variances\"),\n                              group.partial = c(\"q18~1\", \"q2~1\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial2.lv@call$model))\n\nWe can now compare the fit of this model to the previous partial strong invariance model:\n\ncomp_3c4 &lt;- compareFit(fit.partial2, fit.partial2.lv)\nsummary(comp_3c4)\n\n################### Nested Model Comparison #########################\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n                 Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)\nfit.partial2    170 35711 36045 422.62                              \nfit.partial2.lv 172 35709 36033 424.20     2.4853       2     0.2886\n\n####################### Model Fit Indices ###########################\n                chisq.scaled df.scaled pvalue.scaled rmsea.robust cfi.robust\nfit.partial2        368.046†       170          .000        .052       .964†\nfit.partial2.lv     371.348        172          .000        .051†      .964 \n                tli.robust  srmr        aic        bic\nfit.partial2         .961  .039† 35711.011  36044.738 \nfit.partial2.lv      .962† .047  35708.592† 36032.504†\n\n################## Differences in Fit Indices #######################\n                               df.scaled rmsea.robust cfi.robust tli.robust\nfit.partial2.lv - fit.partial2         2            0          0          0\n                                srmr    aic     bic\nfit.partial2.lv - fit.partial2 0.008 -2.419 -12.234\n\n\nWhat does the Chi-square Difference test tell us?\n\n\nFactor Covariances\nNext, we will test if the factor covariance between Anxiety and Stress is equivalent across groups. We will do so by adding lv.covariances to the group.equal argument of the previous partial strong invariance model with equivalent factor variances:\n\nfit.partial2.lcv &lt;- measEq.syntax(configural.model = cfa_config, \n                              data = DASS21, \n                              group = \"engnat\", \n                              ID.fac = \"effects\", \n                              meanstructure = TRUE, \n                              return.fit = TRUE,\n                              estimator = \"mlr\",\n                              group.equal = c(\"loadings\", \"intercepts\", \n                                          \"lv.variances\",\n                                          \"lv.covariances\"),\n                              group.partial = c(\"q18~1\", \"q2~1\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial2.lcv@call$model))\n\nWe can now compare the fit of this model to the previous partial strong invariance model with equivalent factor variances:\n\ncomp_45 &lt;- compareFit(fit.partial2.lv, fit.partial2.lcv)\nsummary(comp_45)\n\n################### Nested Model Comparison #########################\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n                  Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)\nfit.partial2.lv  172 35709 36033 424.20                              \nfit.partial2.lcv 173 35707 36026 424.58    0.27108       1     0.6026\n\n####################### Model Fit Indices ###########################\n                 chisq.scaled df.scaled pvalue.scaled rmsea.robust cfi.robust\nfit.partial2.lv      371.348        172          .000        .051       .964 \nfit.partial2.lcv     371.157†       173          .000        .051†      .964†\n                 tli.robust  srmr        aic        bic\nfit.partial2.lv       .962  .047  35708.592  36032.504 \nfit.partial2.lcv      .962† .046† 35706.978† 36025.982†\n\n################## Differences in Fit Indices #######################\n                                   df.scaled rmsea.robust cfi.robust tli.robust\nfit.partial2.lcv - fit.partial2.lv         1            0          0          0\n                                     srmr    aic    bic\nfit.partial2.lcv - fit.partial2.lv -0.001 -1.614 -6.522\n\n\nWhat does the Chi-square Difference test tell us?\n\n\nFactor Means\nFinally, we can compare the Anxiety and Stress latent factor means to each other. We can use the effect size formula from the book chapter to do so (which can be interpreted as a Cohen’s d effect size). For each of the latent factors, we need the latent mean estimates and an estimate of the factor variance (in our case, the factor variance is equivalent, but the book describes options that can be used if the factor variances are not equivalent). We will find these estimates using the group_by_groups function from the semhelpinghands package:\n\ngroup_by_groups(fit.partial2.lcv) %&gt;% \n  filter((op == \"~1\" & (lhs == \"stress\" | lhs == \"anxiety\")) | \n           op == \"~~\" & (lhs == \"stress\" | lhs == \"anxiety\"))\n\n      lhs op     rhs est_EnglishNative est_ELL\n1 anxiety ~~ anxiety             0.527   0.527\n2 anxiety ~~  stress             0.481   0.481\n3  stress ~~  stress             0.535   0.535\n4 anxiety ~1                     2.269   2.088\n5  stress ~1                     2.506   2.261\n\n\nHere are the computations of the effect size for the mean difference in Anxiety:\n\n# mean in English Native Speaker: 2.269\n# mean in ELL Speaker: 2.088\n# variance: 0.527\n\n(2.269 - 2.088) / sqrt(0.527)\n\n[1] 0.2493293\n\n\nThis indicates that the mean of the Anxiety factor of the English Native Speaker sample is about 0.25 standard deviations higher than that of the ELL Speaker sample.\nHere are the computations of the effect size for the mean difference in Stress:\n\n# mean in English Native Speaker: 2.506\n# mean in ELL Speaker: 2.261\n# variance: 0.535\n\n(2.506 - 2.261) / sqrt(0.535)\n\n[1] 0.3349571\n\n\nThis indicates that the mean of the Stress factor of the English Native Speaker sample is about 0.33 standard deviations higher than that of the ELL Speaker sample.\nWe can also test whether the mean differences are significant using a Wald test. This test is based on the difference in model chi-square that occurs when two parameters (in this case the latent factor means) are constrained to be equivalent.\n\n# H0: Average anxiety is equivalent across \n# English Native and ELL speakers\nlavTestWald(fit.partial2.lcv, constraints = \"alpha.1.g1 == alpha.1.g2\")\n\n$stat\n[1] 12.99259\n\n$df\n[1] 1\n\n$p.value\n[1] 0.0003127267\n\n$se\n[1] \"robust.huber.white\"\n\n# H0: Average stress is equivalent across \n# English Native and ELL speakers\nlavTestWald(fit.partial2.lcv, constraints = \"alpha.2.g1 == alpha.2.g2\")\n\n$stat\n[1] 23.89415\n\n$df\n[1] 1\n\n$p.value\n[1] 1.017804e-06\n\n$se\n[1] \"robust.huber.white\"\n\n\nBased on the results above, both tests were significant (p &lt; .05), so the mean differences are significant between groups."
  },
  {
    "objectID": "measurementinvariance_cont.html#conclusion",
    "href": "measurementinvariance_cont.html#conclusion",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.10 Conclusion",
    "text": "7.10 Conclusion\nIn this example, we found evidence of configural and weak invariance of the Anxiety and Stress factors from the DASS-21 over English native and ELL speaker samples. There is somewhat less convincing evidence of strong invariance, in that most, but not all, intercepts may be equivalent across groups. This means that the English native and ELL speaker samples did not have the same relative standing on one anxiety and one stress item, given the same position on the underlying conceptual variable (i.e., Anxiety/Stress).\nIn a paper, you would report all of the above, adding all unstandardized estimates + SEs of the final retained model (in a table)."
  },
  {
    "objectID": "measurementinvariance_cont.html#summary",
    "href": "measurementinvariance_cont.html#summary",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.11 Summary",
    "text": "7.11 Summary\nIn this R lab, you were introduced to the steps involved in testing measurement invariance with continuous indicators. Below, you’ll find a Bonus section that demonstrates how group mean differences based on the observed item responses differ from what we found using the CFA approach. In the next R Lab, you will learn all about structural after measurement models, which separate the measurement from the structural model in the estimation steps."
  },
  {
    "objectID": "measurementinvariance_cont.html#bonus-compare-findings-to-mean-difference-based-on-observed-mean-scores",
    "href": "measurementinvariance_cont.html#bonus-compare-findings-to-mean-difference-based-on-observed-mean-scores",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.12 Bonus: Compare Findings to Mean Difference Based on Observed Mean Scores",
    "text": "7.12 Bonus: Compare Findings to Mean Difference Based on Observed Mean Scores\nThe code below shows you how you can compare the two groups using mean scores based on the observed items (what you might typically have done), using t-tests. In this case, both Cohen’s D estimates are smaller compared to the difference estimates based on the latent factors. Thus, if we had ignored the measurement model and measurement invariance question, we would have concluded that the differences between native English speakers and ELL speaker were smaller.\n\n# Create mean score variables:\nDASS21 &lt;- DASS21 %&gt;%\n  rowwise() %&gt;%\n  mutate(anx_mean = mean(c(q2, q4, q7, q9, q15, q19, q20)),\n         str_mean = mean(c(q1, q6, q8, q11, q12, q14, q18)))\n\n# Test significance of mean difference (both significant)\nt.test(anx_mean ~ engnat, data = DASS21)\n\n\n    Welch Two Sample t-test\n\ndata:  anx_mean by engnat\nt = 2.5351, df = 994.7, p-value = 0.01139\nalternative hypothesis: true difference in means between group EnglishNative and group ELL is not equal to 0\n95 percent confidence interval:\n 0.02891907 0.22708093\nsample estimates:\nmean in group EnglishNative           mean in group ELL \n                   2.307714                    2.179714 \n\nt.test(str_mean ~ engnat, data = DASS21)\n\n\n    Welch Two Sample t-test\n\ndata:  str_mean by engnat\nt = 3.965, df = 994.77, p-value = 7.864e-05\nalternative hypothesis: true difference in means between group EnglishNative and group ELL is not equal to 0\n95 percent confidence interval:\n 0.09971799 0.29513916\nsample estimates:\nmean in group EnglishNative           mean in group ELL \n                   2.548857                    2.351429 \n\n# Get cohen's D \n# (both under-estimated compared to latent mean comparison):\npsych::cohen.d(DASS21$anx_mean, group = DASS21$engnat)\n\nCall: psych::cohen.d(x = DASS21$anx_mean, group = DASS21$engnat)\nCohen d statistic of difference between two means\n     lower effect upper\n[1,] -0.28  -0.16 -0.04\n\nMultivariate (Mahalanobis) distance between groups\n[1] 0.16\nr equivalent of difference between two means\n data \n-0.08 \n\npsych::cohen.d(DASS21$str_mean, group = DASS21$engnat)\n\nCall: psych::cohen.d(x = DASS21$str_mean, group = DASS21$engnat)\nCohen d statistic of difference between two means\n     lower effect upper\n[1,] -0.38  -0.25 -0.13\n\nMultivariate (Mahalanobis) distance between groups\n[1] 0.25\nr equivalent of difference between two means\n data \n-0.12"
  },
  {
    "objectID": "latentgrowthmodel.html",
    "href": "latentgrowthmodel.html",
    "title": "9  Latent Growth Modeling",
    "section": "",
    "text": "10 Bonus 2: Including a Residual Covariance Structure\nRelated, we can test if the residual covariances should be included in the model to account for any remaining associations between time points with different lags (after accounting for the main growth model). In the model below, covariances are structured such that those that have the same lag (e.g., adjacent time point) covary equivalently (by giving them a shared label). In addition, as the lag increases, we use a non-linear constraint to force the covariances to decrease (as more time passes, scores have less to do with each other).\nlgm_basis_eqc &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + psp2 + psp3 + psp4 + 1*psp5\n\npsp1 ~~ a*psp1\npsp2 ~~ a*psp2\npsp3 ~~ a*psp3\npsp4 ~~ a*psp4\npsp5 ~~ a*psp5\n\n# lag-1 residual covariances\npsp1 ~~ b*psp2\npsp2 ~~ b*psp3\npsp3 ~~ b*psp4\npsp4 ~~ b*psp5\n\n# lag-2 residual covariances\npsp1 ~~ c*psp3\npsp2 ~~ c*psp4\npsp3 ~~ c*psp5\n\n# lag-3 residual covariances\npsp1 ~~ d*psp4\npsp2 ~~ d*psp5\n\n# lag-4 residual covariances\npsp1 ~~ e*psp5\n\n# constraints to apply the reducing residual covariance over time assumption\nc == b^2\nd == b^3\ne == b^4\n'\n\nfit_basis_eqc &lt;- growth(lgm_basis_eqc, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\ncomp_eqc &lt;- compareFit(fit_basis_eq, fit_basis_eqc)\ncomp_eqc@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n              Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)  \nfit_basis_eqc 10 3518.7 3553.5 14.226                                \nfit_basis_eq  11 3526.5 3557.8 24.029     5.7598       1     0.0164 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nQuestion: Does the Chi-square difference test support the hypothesis of including a residual covariance structure?\n(Remember, the model with residual covariance structure is more complex than the model with just the residual variance structure, so we’re testing if making the model more complex is worth it or not.)\nsummary(fit_basis_eqc, std = T)\n\nlavaan 0.6.17 ended normally after 290 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                14.226       9.520\n  Degrees of freedom                                10          10\n  P-value (Chi-square)                           0.163       0.484\n  Scaling correction factor                                  1.494\n    Yuan-Bentler correction (Mplus variant)                       \n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    psp1              1.000                               1.352    0.806\n    psp2              1.000                               1.352    0.730\n    psp3              1.000                               1.352    0.704\n    psp4              1.000                               1.352    0.699\n    psp5              1.000                               1.352    0.689\n  s =~                                                                  \n    psp1              0.000                               0.000    0.000\n    psp2              0.768    0.075   10.276    0.000    0.781    0.422\n    psp3              0.916    0.063   14.573    0.000    0.932    0.486\n    psp4              0.946    0.058   16.423    0.000    0.963    0.498\n    psp5              1.000                               1.018    0.519\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .psp1 ~~                                                               \n   .psp2       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp2 ~~                                                               \n   .psp3       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp3 ~~                                                               \n   .psp4       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp4 ~~                                                               \n   .psp5       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp1 ~~                                                               \n   .psp3       (c)    0.040    0.044    0.910    0.363    0.040    0.041\n .psp2 ~~                                                               \n   .psp4       (c)    0.040    0.044    0.910    0.363    0.040    0.041\n .psp3 ~~                                                               \n   .psp5       (c)    0.040    0.044    0.910    0.363    0.040    0.041\n .psp1 ~~                                                               \n   .psp4       (d)    0.008    0.013    0.606    0.544    0.008    0.008\n .psp2 ~~                                                               \n   .psp5       (d)    0.008    0.013    0.606    0.544    0.008    0.008\n .psp1 ~~                                                               \n   .psp5       (e)    0.002    0.004    0.455    0.649    0.002    0.002\n  i ~~                                                                  \n    s                -0.001    0.186   -0.004    0.997   -0.001   -0.001\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    i                 4.480    0.108   41.335    0.000    3.313    3.313\n    s                -1.014    0.110   -9.237    0.000   -0.996   -0.996\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .psp1       (a)    0.989    0.154    6.427    0.000    0.989    0.351\n   .psp2       (a)    0.989    0.154    6.427    0.000    0.989    0.289\n   .psp3       (a)    0.989    0.154    6.427    0.000    0.989    0.268\n   .psp4       (a)    0.989    0.154    6.427    0.000    0.989    0.264\n   .psp5       (a)    0.989    0.154    6.427    0.000    0.989    0.257\n    i                 1.828    0.242    7.553    0.000    1.000    1.000\n    s                 1.036    0.336    3.081    0.002    1.000    1.000\n\nConstraints:\n                                               |Slack|\n    c - (b^2)                                    0.000\n    d - (b^3)                                    0.000\n    e - (b^4)                                    0.000"
  },
  {
    "objectID": "latentgrowthmodel.html#loading-r-packages",
    "href": "latentgrowthmodel.html#loading-r-packages",
    "title": "9  Latent Growth Modeling",
    "section": "9.1 Loading R packages",
    "text": "9.1 Loading R packages\nLoad the required packages for this lab into your R environment.\n\nlibrary(lavaan)         # used to estimate CFAs and SEMs\nlibrary(semTools)       # used to compare models\nlibrary(ggplot2)        # to visualize trajectories\nlibrary(dplyr)          # data wrangling\nlibrary(tidyr)          # data wrangling"
  },
  {
    "objectID": "latentgrowthmodel.html#loading-data",
    "href": "latentgrowthmodel.html#loading-data",
    "title": "9  Latent Growth Modeling",
    "section": "9.2 Loading Data",
    "text": "9.2 Loading Data\nWe’re going to look at a subset of time points from a 21-day daily diary study. Our data contains 4 measurement waves at 4-day intervals for 240 participants (with missing values at later time points). We will focus on two constructs: perfectionistic self-presentation (PSP), which (as operationalized in these data) measures an individual’s desire to hide their imperfections; and 2) state social anxiety (SSA), which measures transitory feelings of anxiety associated with social situations. You can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/longitudinal.csv. Make sure to save it in the folder you are using for this class. These data are part of a larger study, and the full data set can be found here: https://osf.io/hwkem/.\nWe will start by loading the data into our environment:\n\ndiary &lt;- rio::import(file = \"data/longitudinal.csv\")"
  },
  {
    "objectID": "latentgrowthmodel.html#visualizing-the-data",
    "href": "latentgrowthmodel.html#visualizing-the-data",
    "title": "9  Latent Growth Modeling",
    "section": "9.3 Visualizing the data",
    "text": "9.3 Visualizing the data\nFor this example, we will focus on the development of perfectionistic self-presentation (PSP) over time. We will first look at the distribution of this variable at each time point:\n\ndiary %&gt;%\n  select(psp1:psp5) %&gt;%\n  pivot_longer(everything()) %&gt;%\n  ggplot(aes(x=value)) +\n  geom_histogram(bins = 10) + \n  facet_wrap(vars(name), scales = \"free\")\n\nWarning: Removed 166 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nQuestion: Do the variables look Normally distributed?\nWe can also use the functions from the semTools package to explore the distributions further:\n\n# Univariate skew and kurtosis\napply(diary[,2:5], 2, skew)\n\n               sexm        psp1      psp2      psp3\nskew (g1) 1.5765565 -0.40015823 0.1261088 0.2233847\nse        0.1581139  0.15811388 0.1662822 0.1719205\nz         9.9710190 -2.53082285 0.7584025 1.2993491\np         0.0000000  0.01137953 0.4482101 0.1938241\n\napply(diary[,2:5], 2, kurtosis)\n\n                     sexm        psp1         psp2          psp3\nExcess Kur (g2) 0.4895404 -0.68049195 -1.072857005 -1.1489708600\nse              0.3162278  0.31622777  0.332564397  0.3438409530\nz               1.5480627 -2.15190450 -3.226012809 -3.3415765338\np               0.1216072  0.03140488  0.001255277  0.0008330405\n\n\nNext, to inform our initial model growth factors, we can visualize the average change over time in our sample using the average scores at each time point.\n\ndiary %&gt;% select(id:psp5) %&gt;%\n  summarize(across(psp1:psp5, ~mean(.x, na.rm = T))) %&gt;%\n  pivot_longer(cols = psp1:psp5, \n               names_to = \"time\", names_prefix = \"psp\", \n               names_transform = as.numeric, \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = time, y = score)) + \n  geom_point() +\n  geom_line() +\n  labs(x = \"Time Point\", y = \"Average PSP Score\") +\n  theme_bw()\n\n\n\n\nQuestion: What kind of shape does the developmental trajectory look like?"
  },
  {
    "objectID": "latentgrowthmodel.html#basic-latent-growth-models",
    "href": "latentgrowthmodel.html#basic-latent-growth-models",
    "title": "9  Latent Growth Modeling",
    "section": "9.4 Basic Latent Growth Models",
    "text": "9.4 Basic Latent Growth Models\n\nSpecification\nWe can estimate several latent growth models and compare their fit, starting with a linear growth model, followed by a quadratic growth model, a cubic growth model, and finally a latent basis model. Below is the code to specify each of these three models:\n\nlgm_linear &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + 1*psp2 + 2*psp3 + 3*psp4 + 4*psp5\n'\n\nlgm_quad &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + 1*psp2 + 2*psp3 + 3*psp4 + 4*psp5\nq =~ 0*psp1 + 1*psp2 + 4*psp3 + 9*psp4 + 16*psp5\n'\n\nlgm_cube &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + 1*psp2 + 2*psp3 + 3*psp4 + 4*psp5\nq =~ 0*psp1 + 1*psp2 + 4*psp3 + 9*psp4 + 16*psp5\nc =~ 0*psp1 + 1*psp2 + 8*psp3 + 27*psp4 + 64*psp5\n'\n\nlgm_basis &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + psp2 + psp3 + psp4 + 1*psp5\n'\n\nNote that covariances between intercept and slope(s) are automatically included and don’t need to be explicitly specified.\nQuestion: Should we also include a piecewise growth structure?\n\n\nEstimation\nNext, we can estimate these models using the growth() function. This function tells lavaan that you want to estimate a growth model, which ensures that certain components (e.g., the latent variable mean structure) are automatically included. We will use the mlr estimator to account for non-Normality and fiml to account for missing data.\n\n# Fit the linear LGM using the growth() function\nfit_linear &lt;- growth(lgm_linear, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\n# Fit the quadratic LGM using the growth() function\nfit_quad &lt;- growth(lgm_quad, data = diary, \n                   estimator = \"mlr\", missing = \"fiml\")\n\n# Fit the quadratic LGM using the growth() function\nfit_cube &lt;- growth(lgm_cube, data = diary, \n                   estimator = \"mlr\", missing = \"fiml\")\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\n# Fit the basis LGM using the growth() function\nfit_basis &lt;- growth(lgm_basis, data = diary, \n                    estimator = \"mlr\", missing = \"fiml\")\n\nQuestion: Did you encounter any estimation issues?\n\n\nCompare LGM growth structures\nBefore we compare the fit of the three models, we need to make sure that all three models are nested. If models are not nested, we can compare them using the BIC and AIC instead. Note that I am ignoring any estimation issues for this section for illustration sake, but you should not do that! Model fit indices based on inadmissible/impossible estimates are not useful.\n\nnet(fit_linear, fit_quad, fit_cube, fit_basis)\n\n\n        If cell [R, C] is TRUE, the model in row R is nested within column C.\n\n        If the models also have the same degrees of freedom, they are equivalent.\n\n        NA indicates the model in column C did not converge when fit to the\n        implied means and covariance matrix from the model in row R.\n\n        The hidden diagonal is TRUE because any model is equivalent to itself.\n        The upper triangle is hidden because for models with the same degrees\n        of freedom, cell [C, R] == cell [R, C].  For all models with different\n        degrees of freedom, the upper diagonal is all FALSE because models with\n        fewer degrees of freedom (i.e., more parameters) cannot be nested\n        within models with more degrees of freedom (i.e., fewer parameters).\n        \n                     fit_cube fit_quad fit_basis fit_linear\nfit_cube (df = 1)                                          \nfit_quad (df = 6)    TRUE                                  \nfit_basis (df = 7)   FALSE    FALSE                        \nfit_linear (df = 10) TRUE     TRUE     TRUE                \n\n\nQuestion: Which models can we compare using a Chi-square difference test? And which models do we need to compare with BIC/AIC?\n\nComparing Linear to Quadratic\n\ncomp_lq &lt;- compareFit(fit_linear, fit_quad)\ncomp_lq@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n           Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit_quad    6 3529.6 3578.3 17.107                                  \nfit_linear 10 3580.5 3615.3 76.048     42.632       4  1.234e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nComparing Linear to Cubic\n\ncomp_lc &lt;- compareFit(fit_linear, fit_cube)\ncomp_lc@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n           Df    AIC    BIC   Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit_cube    1 3522.8 3588.9  0.3288                                  \nfit_linear 10 3580.5 3615.3 76.0476     63.717       9  2.561e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nComparing Linear to Basis\n\ncomp_lb &lt;- compareFit(fit_linear, fit_basis)\ncomp_lb@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n           Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit_basis   7 3531.5 3576.8 21.073                                  \nfit_linear 10 3580.5 3615.3 76.048     49.804       3  8.794e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nComparing Quadratic and Cubic to Basis\n\ncomp_qcb &lt;- compareFit(fit_quad, fit_cube, fit_basis)\ncomp_qcb@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n          Df    AIC    BIC   Chisq Chisq diff Df diff Pr(&gt;Chisq)   \nfit_cube   1 3522.8 3588.9  0.3288                                 \nfit_quad   6 3529.6 3578.3 17.1065    16.2418       5   0.006187 **\nfit_basis  7 3531.5 3576.8 21.0731     1.7877       1   0.181209   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuestion: Which of the three models fits best (taking into account estimation issues)?\n\n\nEvaluating the appropriateness of the latent basis model\nWu and Lang (2016) have shown that the proportionality assumption of the latent basis model (i.e., the percentage of growth attained at each time point is constrained to be equal across all people) can be tenable if, in a quadratic growth model, the linear and quadratic slope variances are non-significant. This would indicate that there is no between-individual variation in the amount of change across time points, in line with the proportionality assumption. All of this rests on the assumption that a quadratic model is the correct model. We can look at the significance of the linear and quadratic variances using the summary function:\n\nsummary(fit_quad)\n\nlavaan 0.6-19 ended normally after 70 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                17.107      16.433\n  Degrees of freedom                                 6           6\n  P-value (Chi-square)                           0.009       0.012\n  Scaling correction factor                                  1.041\n    Yuan-Bentler correction (Mplus variant)                       \n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    psp1              1.000                           \n    psp2              1.000                           \n    psp3              1.000                           \n    psp4              1.000                           \n    psp5              1.000                           \n  s =~                                                \n    psp1              0.000                           \n    psp2              1.000                           \n    psp3              2.000                           \n    psp4              3.000                           \n    psp5              4.000                           \n  q =~                                                \n    psp1              0.000                           \n    psp2              1.000                           \n    psp3              4.000                           \n    psp4              9.000                           \n    psp5             16.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                 0.395    0.225    1.757    0.079\n    q                -0.088    0.048   -1.841    0.066\n  s ~~                                                \n    q                -0.042    0.040   -1.037    0.300\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 4.392    0.110   39.989    0.000\n    s                -0.677    0.080   -8.467    0.000\n    q                 0.115    0.018    6.253    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .psp1              1.288    0.280    4.597    0.000\n   .psp2              0.766    0.125    6.151    0.000\n   .psp3              0.742    0.164    4.535    0.000\n   .psp4              0.922    0.267    3.450    0.001\n   .psp5              0.172    0.351    0.490    0.624\n    i                 1.669    0.297    5.615    0.000\n    s                 0.209    0.202    1.037    0.300\n    q                 0.014    0.010    1.401    0.161\n\n\nQuestion: Is it OK to move forward with the latent basis model?\n\n\n\nModel Fit Evaluation\nFocusing on the best-fitting model according to our comparisons above, the latent basis model, we will now examine global and local fit.\n\nsummary(fit_basis, fit.measures = T, estimates = F)\n\nlavaan 0.6-19 ended normally after 44 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                21.073      17.426\n  Degrees of freedom                                 7           7\n  P-value (Chi-square)                           0.004       0.015\n  Scaling correction factor                                  1.209\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                               730.786     346.167\n  Degrees of freedom                                10          10\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  2.111\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.980       0.969\n  Tucker-Lewis Index (TLI)                       0.972       0.956\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.982\n  Robust Tucker-Lewis Index (TLI)                            0.974\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1752.772   -1752.772\n  Scaling correction factor                                  1.541\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -1742.236   -1742.236\n  Scaling correction factor                                  1.425\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                3531.545    3531.545\n  Bayesian (BIC)                              3576.793    3576.793\n  Sample-size adjusted Bayesian (SABIC)       3535.586    3535.586\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.092       0.079\n  90 Percent confidence interval - lower         0.048       0.037\n  90 Percent confidence interval - upper         0.138       0.122\n  P-value H_0: RMSEA &lt;= 0.050                    0.056       0.115\n  P-value H_0: RMSEA &gt;= 0.080                    0.704       0.526\n                                                                  \n  Robust RMSEA                                               0.099\n  90 Percent confidence interval - lower                     0.037\n  90 Percent confidence interval - upper                     0.162\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.084\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.741\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.022       0.022\n\n\nQuestion: Does global fit look good? Or bad?\n\nresiduals(fit_basis, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       psp1   psp2   psp3   psp4   psp5\npsp1  0.000                            \npsp2  0.001  0.000                     \npsp3  0.008  0.046  0.000              \npsp4  0.004 -0.015 -0.025  0.000       \npsp5 -0.012 -0.049 -0.009  0.038  0.000\n\n$mean\n  psp1   psp2   psp3   psp4   psp5 \n 0.001 -0.010 -0.012  0.003  0.023 \n\n\nQuestion: Does local fit look good? Or bad?\n\n\nParameter Estimate Interpretation\nNext, we can look at the parameter estimates and interpret them to see what they tell us about the development of PSP over the course of 16 days.\n\nsummary(fit_basis, std = T, rsquare = T)\n\nlavaan 0.6-19 ended normally after 44 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                21.073      17.426\n  Degrees of freedom                                 7           7\n  P-value (Chi-square)                           0.004       0.015\n  Scaling correction factor                                  1.209\n    Yuan-Bentler correction (Mplus variant)                       \n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    psp1              1.000                               1.620    0.966\n    psp2              1.000                               1.620    0.869\n    psp3              1.000                               1.620    0.852\n    psp4              1.000                               1.620    0.836\n    psp5              1.000                               1.620    0.825\n  s =~                                                                  \n    psp1              0.000                               0.000    0.000\n    psp2              0.743    0.085    8.720    0.000    1.058    0.567\n    psp3              0.904    0.071   12.684    0.000    1.287    0.677\n    psp4              0.948    0.047   20.162    0.000    1.349    0.696\n    psp5              1.000                               1.423    0.725\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i ~~                                                                  \n    s                -0.810    0.499   -1.622    0.105   -0.351   -0.351\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    i                 4.480    0.108   41.452    0.000    2.766    2.766\n    s                -1.028    0.112   -9.168    0.000   -0.722   -0.722\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .psp1              0.188    0.446    0.422    0.673    0.188    0.067\n   .psp2              0.938    0.141    6.633    0.000    0.938    0.270\n   .psp3              0.802    0.188    4.258    0.000    0.802    0.222\n   .psp4              0.848    0.262    3.239    0.001    0.848    0.226\n   .psp5              0.826    0.207    3.998    0.000    0.826    0.214\n    i                 2.623    0.494    5.312    0.000    1.000    1.000\n    s                 2.025    0.519    3.899    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    psp1              0.933\n    psp2              0.730\n    psp3              0.778\n    psp4              0.774\n    psp5              0.786\n\n\n(See example write-up below for details.)\n\n\nComparing the observed to estimated trajectory\nWe can visualize the model-implied, or predicted, trajectory and compare it to the observed trajectory, to get a better idea of how closely the estimated trajectory matches onto the observed trajectory.\n\n# Get observed growth curve\nobs_curve &lt;- diary %&gt;% select(id:psp5) %&gt;%\n  summarize(across(psp1:psp5, ~mean(.x, na.rm = T))) %&gt;%\n  pivot_longer(cols = psp1:psp5, \n               names_to = \"time\", names_prefix = \"psp\", \n               names_transform = as.numeric)\n\n# Get predicted growth curve\npred_curve &lt;- lavPredict(fit_basis) %&gt;% as.data.frame() %&gt;% \n  rowwise() %&gt;%\n  mutate(t1 = i + 0*s,\n         t2 = i + .743*s,\n         t3 = i + .904*s,\n         t4 = i + .948*s,\n         t5 = i + 1*s) %&gt;%\n  pivot_longer(cols = t1:t5, \n               names_to = \"time\", names_prefix = \"t\", \n               names_transform = as.numeric) %&gt;%\n  group_by(time) %&gt;%\n  summarize(value = mean(value)) %&gt;%\n  select(time, value)\n\n# Create the plot:\nbind_rows(obs_curve, pred_curve, .id = \"type\") %&gt;%\n  mutate(type = ifelse(type == \"1\", \"Observed\", \"Predicted\")) %&gt;%\n  ggplot(aes(x = time, group = type, color = type, linetype = type)) +\n  geom_line(aes(y = value), \n            linewidth = .8) +\n  geom_point(aes(y = value), \n             size = 1) +\n  labs(y = \"Average PSP Score\") +\n  scale_x_continuous(\"Day\", breaks = c(1, 2, 3, 4,5), \n                     labels = c(1,5,9,13,17)) +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nWe can compare this figure to one based on the quadratic growth model estimates to understand how each model differs in the predictions they make about the trajectory of change in perfectionistic self-presentation.\n\n# Get predicted growth curve\npred_curve2 &lt;- lavPredict(fit_quad) %&gt;% as.data.frame() %&gt;% \n  rowwise() %&gt;%\n  mutate(t1 = i + 0*s + 0*q,\n         t2 = i + 1*s + 1*q,\n         t3 = i + 2*s + 4*q,\n         t4 = i + 3*s + 9*q,\n         t5 = i + 4*s + 16*q) %&gt;%\n  pivot_longer(cols = t1:t5, \n               names_to = \"time\", names_prefix = \"t\", \n               names_transform = as.numeric) %&gt;%\n  group_by(time) %&gt;%\n  summarize(value = mean(value)) %&gt;%\n  select(time, value)\n\n# Create the plot:\nbind_rows(obs_curve, pred_curve2, .id = \"type\") %&gt;%\n  mutate(type = ifelse(type == \"1\", \"Observed\", \"Predicted\")) %&gt;%\n  ggplot(aes(x = time, group = type, color = type, linetype = type)) +\n  geom_line(aes(y = value), \n            linewidth = .8) +\n  geom_point(aes(y = value), \n             size = 1) +\n  labs(y = \"Average PSP Score\") +\n  scale_x_continuous(\"Day\", breaks = c(1, 2, 3, 4,5), \n                     labels = c(1,5,9,13,17)) +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nQuestion: What are the main differences between the predicted trajectories?"
  },
  {
    "objectID": "latentgrowthmodel.html#extending-the-lgm-with-covariates",
    "href": "latentgrowthmodel.html#extending-the-lgm-with-covariates",
    "title": "9  Latent Growth Modeling",
    "section": "9.5 Extending the LGM with covariates",
    "text": "9.5 Extending the LGM with covariates\nBelow we will go over three options for extending the basic LGM. In a typical study, you would have already determined which of these aligns with your hypotheses. However, since this is a lab, I want to show you all the options.\n\nIncluding a Time-Invariant Covariate: Sex\nWe can include the participant’s self-reported sex (0 = female, 1 = male) as a time-invariant covariate and see if it can explain individual differences in the initial level of or change in PSP.\n\nlgm_ti_cov &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + psp2 + psp3 + psp4 + 1*psp5\n\ni ~ sexm\ns ~ sexm\n'\n\nfit_ti_cov &lt;- growth(lgm_ti_cov, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\nsummary(fit_ti_cov, fit.measures = T, rsquare = T, std = T)\n\nlavaan 0.6-19 ended normally after 52 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                26.729      24.671\n  Degrees of freedom                                10          10\n  P-value (Chi-square)                           0.003       0.006\n  Scaling correction factor                                  1.083\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                               738.606     438.423\n  Degrees of freedom                                15          15\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.685\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.977       0.965\n  Tucker-Lewis Index (TLI)                       0.965       0.948\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.977\n  Robust Tucker-Lewis Index (TLI)                            0.966\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1751.690   -1751.690\n  Scaling correction factor                                  1.455\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -1738.326   -1738.326\n  Scaling correction factor                                  1.306\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                3533.381    3533.381\n  Bayesian (BIC)                              3585.590    3585.590\n  Sample-size adjusted Bayesian (SABIC)       3538.044    3538.044\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.083       0.078\n  90 Percent confidence interval - lower         0.046       0.041\n  90 Percent confidence interval - upper         0.123       0.116\n  P-value H_0: RMSEA &lt;= 0.050                    0.068       0.097\n  P-value H_0: RMSEA &gt;= 0.080                    0.599       0.508\n                                                                  \n  Robust RMSEA                                               0.093\n  90 Percent confidence interval - lower                     0.045\n  90 Percent confidence interval - upper                     0.142\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.068\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.707\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.025       0.025\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    psp1              1.000                               1.620    0.966\n    psp2              1.000                               1.620    0.869\n    psp3              1.000                               1.620    0.852\n    psp4              1.000                               1.620    0.837\n    psp5              1.000                               1.620    0.826\n  s =~                                                                  \n    psp1              0.000                               0.000    0.000\n    psp2              0.743    0.085    8.686    0.000    1.058    0.568\n    psp3              0.902    0.071   12.627    0.000    1.286    0.676\n    psp4              0.948    0.047   20.181    0.000    1.352    0.698\n    psp5              1.000                               1.425    0.726\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i ~                                                                   \n    sexm             -0.319    0.260   -1.227    0.220   -0.197   -0.077\n  s ~                                                                   \n    sexm             -0.114    0.264   -0.434    0.664   -0.080   -0.032\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .i ~~                                                                  \n   .s                -0.819    0.494   -1.658    0.097   -0.356   -0.356\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .i                 4.541    0.122   37.270    0.000    2.802    2.802\n   .s                -1.008    0.123   -8.182    0.000   -0.707   -0.707\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .psp1              0.186    0.442    0.420    0.674    0.186    0.066\n   .psp2              0.940    0.141    6.653    0.000    0.940    0.270\n   .psp3              0.810    0.190    4.255    0.000    0.810    0.224\n   .psp4              0.840    0.261    3.215    0.001    0.840    0.224\n   .psp5              0.824    0.206    4.005    0.000    0.824    0.214\n   .i                 2.610    0.491    5.320    0.000    0.994    0.994\n   .s                 2.029    0.516    3.930    0.000    0.999    0.999\n\nR-Square:\n                   Estimate\n    psp1              0.934\n    psp2              0.730\n    psp3              0.776\n    psp4              0.776\n    psp5              0.786\n    i                 0.006\n    s                 0.001\n\n\nQuestion: What do you conclude about the effect of a person’s sex on their PSP trajectory?\n\n\nIncluding a Time-Varying Covariate: State-Social Anxiety\nWe can also include SSA as a time-varying covariate and see to what extent it is associated with concurrent (i.e., at the same time) levels of PSP after the main developmental trajectory has already been accounted for by the growth model.\n\nlgm_tv_cov &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + psp2 + psp3 + psp4 + 1*psp5\n\n# regression paths\npsp1 ~ ssa1\npsp2 ~ ssa2\npsp3 ~ ssa3\npsp4 ~ ssa4\npsp5 ~ ssa5\n\n# covariances between time-varying covariate\nssa1 ~~ ssa2 + ssa3 + ssa4 + ssa5\nssa2 ~~ ssa3 + ssa4 + ssa5\nssa3 ~~ ssa4 + ssa5\nssa4 ~~ ssa5\n\n# means of time varying covariate\nssa1 ~ 1\nssa2 ~ 1\nssa3 ~ 1\nssa4 ~ 1\nssa5 ~ 1\n'\n\nfit_tv_cov &lt;- growth(lgm_tv_cov, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\nsummary(fit_tv_cov, fit.measures = T, rsquare = T, std = T)\n\nlavaan 0.6-19 ended normally after 56 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        38\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               100.722      83.676\n  Degrees of freedom                                27          27\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.204\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1719.080    1185.277\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.450\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.956       0.950\n  Tucker-Lewis Index (TLI)                       0.927       0.917\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.961\n  Robust Tucker-Lewis Index (TLI)                            0.935\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2821.490   -2821.490\n  Scaling correction factor                                  1.270\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -2771.129   -2771.129\n  Scaling correction factor                                  1.242\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                5718.981    5718.981\n  Bayesian (BIC)                              5851.245    5851.245\n  Sample-size adjusted Bayesian (SABIC)       5730.794    5730.794\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.107       0.094\n  90 Percent confidence interval - lower         0.085       0.073\n  90 Percent confidence interval - upper         0.129       0.115\n  P-value H_0: RMSEA &lt;= 0.050                    0.000       0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.977       0.868\n                                                                  \n  Robust RMSEA                                               0.111\n  90 Percent confidence interval - lower                     0.083\n  90 Percent confidence interval - upper                     0.140\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.000\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.966\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.170       0.170\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    psp1              1.000                               1.176    0.754\n    psp2              1.000                               1.176    0.721\n    psp3              1.000                               1.176    0.690\n    psp4              1.000                               1.176    0.669\n    psp5              1.000                               1.176    0.671\n  s =~                                                                  \n    psp1              0.000                               0.000    0.000\n    psp2              0.752    0.095    7.934    0.000    0.778    0.477\n    psp3              0.961    0.088   10.943    0.000    0.994    0.583\n    psp4              0.964    0.077   12.550    0.000    0.996    0.567\n    psp5              1.000                               1.034    0.590\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  psp1 ~                                                                \n    ssa1              0.725    0.096    7.557    0.000    0.725    0.462\n  psp2 ~                                                                \n    ssa2              0.891    0.084   10.586    0.000    0.891    0.584\n  psp3 ~                                                                \n    ssa3              0.944    0.084   11.199    0.000    0.944    0.602\n  psp4 ~                                                                \n    ssa4              0.965    0.100    9.690    0.000    0.965    0.568\n  psp5 ~                                                                \n    ssa5              0.988    0.091   10.918    0.000    0.988    0.628\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  ssa1 ~~                                                               \n    ssa2              0.651    0.067    9.650    0.000    0.651    0.612\n    ssa3              0.632    0.070    9.031    0.000    0.632    0.585\n    ssa4              0.610    0.071    8.642    0.000    0.610    0.593\n    ssa5              0.616    0.084    7.346    0.000    0.616    0.557\n  ssa2 ~~                                                               \n    ssa3              0.845    0.074   11.467    0.000    0.845    0.727\n    ssa4              0.765    0.077    9.956    0.000    0.765    0.691\n    ssa5              0.752    0.086    8.763    0.000    0.752    0.631\n  ssa3 ~~                                                               \n    ssa4              0.759    0.080    9.526    0.000    0.759    0.675\n    ssa5              0.808    0.088    9.201    0.000    0.808    0.668\n  ssa4 ~~                                                               \n    ssa5              0.831    0.095    8.723    0.000    0.831    0.721\n  i ~~                                                                  \n    s                -0.603    0.441   -1.367    0.172   -0.497   -0.497\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    ssa1              1.651    0.064   25.744    0.000    1.651    1.662\n    ssa2              1.392    0.070   19.741    0.000    1.392    1.301\n    ssa3              1.370    0.073   18.755    0.000    1.370    1.261\n    ssa4              1.301    0.071   18.236    0.000    1.301    1.257\n    ssa5              1.327    0.077   17.321    0.000    1.327    1.193\n    i                 3.284    0.198   16.624    0.000    2.793    2.793\n    s                -1.098    0.218   -5.042    0.000   -1.062   -1.062\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .psp1              0.532    0.413    1.289    0.197    0.532    0.219\n   .psp2              0.671    0.083    8.057    0.000    0.671    0.253\n   .psp3              0.645    0.129    5.008    0.000    0.645    0.222\n   .psp4              0.882    0.226    3.905    0.000    0.882    0.285\n   .psp5              0.619    0.100    6.179    0.000    0.619    0.201\n    ssa1              0.987    0.067   14.725    0.000    0.987    1.000\n    ssa2              1.144    0.079   14.527    0.000    1.144    1.000\n    ssa3              1.181    0.083   14.178    0.000    1.181    1.000\n    ssa4              1.072    0.091   11.788    0.000    1.072    1.000\n    ssa5              1.239    0.110   11.260    0.000    1.239    1.000\n    i                 1.382    0.438    3.152    0.002    1.000    1.000\n    s                 1.068    0.438    2.437    0.015    1.000    1.000\n\nR-Square:\n                   Estimate\n    psp1              0.781\n    psp2              0.747\n    psp3              0.778\n    psp4              0.715\n    psp5              0.799\n\n\nQuestion: What do you conclude about the effect of a SSA on their concurrent PSP levels?\n\n\nIncluding a (Distal) Outcome: State-Social Anxiety\nFinally, we can include SSA on Day 16 as an outcome variable that is predicted by the initial level of and changes in PSP. Note that it is more typical for such an outcome to be measured at a time point that is later than the final time point included in the growth model.\n\nlgm_outcome &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + psp2 + psp3 + psp4 + + 1*psp5\n\n# regression path to distal outcome\nssa5 ~ i + s\n\n# intercept of distal outcome\nssa5 ~ 1 \n'\n\nfit_outcome &lt;- growth(lgm_outcome, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\nWarning: lavaan-&gt;lav_model_vcov():  \n   Could not compute standard errors! The information matrix could not be \n   inverted. This may be a symptom that the model is not identified.\n\n\nWarning: lavaan-&gt;lav_test_yuan_bentler():  \n   could not invert information [matrix needed for robust test statistic\n\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nsummary(fit_outcome, fit.measures = T, rsquare = T, std = T)\n\nWarning: lavaan-&gt;lav_fit_cfi_lavobject():  \n   computation of robust CFI failed.\n\n\nWarning: lavaan-&gt;lav_fit_rmsea_lavobject():  \n   computation of robust RMSEA failed.\n\n\nlavaan 0.6-19 ended normally after 1232 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        17\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                58.529          NA\n  Degrees of freedom                                10          10\n  P-value (Chi-square)                           0.000          NA\n  Scaling correction factor                                     NA\n                                                                  \n\nModel Test Baseline Model:\n\n  Test statistic                               880.001     498.066\n  Degrees of freedom                                15          15\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.767\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.944          NA\n  Tucker-Lewis Index (TLI)                       0.916          NA\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1979.714   -1979.714\n  Loglikelihood unrestricted model (H1)      -1950.450   -1950.450\n                                                                  \n  Akaike (AIC)                                3993.428    3993.428\n  Bayesian (BIC)                              4052.599    4052.599\n  Sample-size adjusted Bayesian (SABIC)       3998.713    3998.713\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.142          NA\n  90 Percent confidence interval - lower         0.108          NA\n  90 Percent confidence interval - upper         0.178          NA\n  P-value H_0: RMSEA &lt;= 0.050                    0.000          NA\n  P-value H_0: RMSEA &gt;= 0.080                    0.998          NA\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                        NA\n  90 Percent confidence interval - upper                        NA\n  P-value H_0: Robust RMSEA &lt;= 0.050                            NA\n  P-value H_0: Robust RMSEA &gt;= 0.080                            NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.039       0.039\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    psp1              1.000                               1.131    0.669\n    psp2              1.000                               1.131    0.609\n    psp3              1.000                               1.131    0.592\n    psp4              1.000                               1.131    0.581\n    psp5              1.000                               1.131    0.573\n  s =~                                                                  \n    psp1              0.000                               0.000    0.000\n    psp2              0.685       NA                      0.438    0.236\n    psp3              0.845       NA                      0.541    0.283\n    psp4              0.885       NA                      0.566    0.291\n    psp5              1.000                               0.640    0.324\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  ssa5 ~                                                                \n    i                77.289       NA                     87.385   79.777\n    s              -135.163       NA                    -86.487  -78.958\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i ~~                                                                  \n    s                 0.726       NA                      1.004    1.004\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .ssa5           -483.211       NA                   -483.211 -441.144\n    i                 4.450       NA                      3.936    3.936\n    s                -1.041       NA                     -1.626   -1.626\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .psp1              1.580       NA                      1.580    0.553\n   .psp2              0.981       NA                      0.981    0.285\n   .psp3              0.848       NA                      0.848    0.233\n   .psp4              0.897       NA                      0.897    0.237\n   .psp5              0.749       NA                      0.749    0.193\n   .ssa5             62.964       NA                     62.964   52.479\n    i                 1.278       NA                      1.000    1.000\n    s                 0.409       NA                      1.000    1.000\n\nR-Square:\n                   Estimate\n    psp1              0.447\n    psp2              0.715\n    psp3              0.767\n    psp4              0.763\n    psp5              0.807\n    ssa5            -51.479\n\n\nQuestion: What do you conclude about the association between initial levels of and changes in PSP and final time point SSA?"
  },
  {
    "objectID": "latentgrowthmodel.html#example-write-up",
    "href": "latentgrowthmodel.html#example-write-up",
    "title": "9  Latent Growth Modeling",
    "section": "9.6 Example Write-Up",
    "text": "9.6 Example Write-Up\nBased on the observed mean trajectory, we estimated four different growth structures, (1) linear, (2) quadratic, (3) cubic, and (4) latent basis. The cubic model resulted in inadmissible estimates (negative variances), likely due to the complexity of the model. Thus, we did not include this model in subsequent comparisons. The linear model fit significantly worse than both the quadratic (\\(\\Delta\\chi^2(4) = 42.63, p &lt; .001\\)) and latent basis (\\(\\Delta\\chi^2(2) = 49.80, p &lt; .001\\)) models. As the quadratic and latent basis models are not nested, we used the AIC and BIC to compare the relative fit of these two models. The AIC preferred the quadratic model ((\\(\\Delta AIC = -1.97\\)) whereas the BIC preferred the latent basis model (\\(\\Delta BIC = -1.51\\)). We placed more weight on the BIC as it has a stronger penalty against overly complex models. This decision was further supported by confirming that the linear and quadratic slope variance of the quadratic model were both non-significant, indicating that there are no significant between-person differences in change in PSP over time, supporting the proportionality assumption of the latent basis model. Thus, we selected the latent basis model for further analyses.\nThe latent basis model fit the data well, \\(\\chi^2(7) = 17.43, p = .015, CFI = .982, RMSEA = .099, 90\\% CI [.037, .112], SRMR = .022\\). None of the correlation residuals were greater than \\(|0.10|\\), indicating good local fit. The mean intercept was 4.80 (SE = 0.11), and there was significant between-person variation around the mean intercept (\\(\\psi_{11} = 2.62, SE = 0.549, p = .001\\)), indicating that initial levels of PSP varied across participants. The mean slope was -1.03 (\\(SE = 0.11, p &lt; .001\\)), indicating that between the first and last diary entry, participants levels of PSP declined, on average, by about 1 point. There was significant between-person variation in the slope (\\(\\psi_{22} = 2.03, SE = 0.52, p &lt; .001\\)). This suggests that, although the proportionality assumption was met, the total change between the first and final time point did vary across participants. Based on the model implied slope loadings, about 74% (\\(\\lambda_{22} = 0.74\\)) of that decrease occurred during the first four days. The proportion of decrease then declined between day 5 and 9 (16%), between day 9 and 13 (4%), and stabilized between day 13 and 17 (5%). The covariance between the intercept and slope was not significant (\\(\\psi_{21} = 0.81, SE = 0.50, p = .105, r = -.351\\)), indicating that the initial level of PSP was not significantly associated with subsequent changes in PSP. R-squared values indicate that between 63-93% of the variance in the observed PSP scores could be explained by the growth factors.\nTo evaluate the potential effect of sex on the initial level and changes in PSP, we included participant self-reported sex as a time-invariant covariate. The model fit the data well (\\(\\chi^2(10) = 24.67, p = .006, CFI = .965, RMSEA = .078, 90\\% CI [.041, .116], SRMR = .025\\)). None of the correlation residuals were greater than \\(|0.10|\\), indicating good local fit. Sex was not a significant predictor of the initial level of PSP (\\(B = -0.32, SE = 0.26, p = .220, \\beta = -.08\\)) or subsequent change in PSP (\\(B = -0.11, SE = 0.26, p = .664, \\beta = -.03\\)). These findings indicate that those identifying as male do not differ from those identifying as female in their initial level of or subsequent changes in PSP during this 17-day study period. A full overview of all parameter estimates can be found in (fictional) Table XX."
  },
  {
    "objectID": "latentgrowthmodel.html#summary",
    "href": "latentgrowthmodel.html#summary",
    "title": "9  Latent Growth Modeling",
    "section": "9.7 Summary",
    "text": "9.7 Summary\nIn this R lab, you were introduced to the steps involved in specifying, estimating, evaluating, comparing and interpreting the results of latent growth models. In addition, you have seen some ways in which you can expand the basic growth model to include additional predictors or outcomes. Below, you’ll find three Bonus sections that demonstrate how to test the equivalence of residual variances in a growth model, how to include residual covariances, and how to set-up and estimate a parallel growth model. In the next R Lab, you will learn all about measurement invariance testing with ordinal indicators."
  },
  {
    "objectID": "latentgrowthmodel.html#bonus-1-residual-variance-structure",
    "href": "latentgrowthmodel.html#bonus-1-residual-variance-structure",
    "title": "9  Latent Growth Modeling",
    "section": "9.8 Bonus 1: Residual Variance Structure",
    "text": "9.8 Bonus 1: Residual Variance Structure\nFocusing once again on a single growth model, we can test if the residual variances can be fixed to be equal across the four time points, by giving all residuals the same label (a). Doing this simplifies the model (instead of estimating 5 residual variances, we estimate 1 residual variance), and simple models (if they fit equally well) should be preferred.\n\nlgm_basis_eq &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + psp2 + psp3 + psp4 + 1*psp5\n\npsp1 ~~ a*psp1\npsp2 ~~ a*psp2\npsp3 ~~ a*psp3\npsp4 ~~ a*psp4\npsp5 ~~ a*psp5\n'\n\nfit_basis_eq &lt;- growth(lgm_basis_eq, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\ncomp_bbeq &lt;- compareFit(fit_basis, fit_basis_eq)\ncomp_bbeq@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n             Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)\nfit_basis     7 3531.5 3576.8 21.073                              \nfit_basis_eq 11 3526.5 3557.8 24.029     1.4454       4     0.8363\n\n\nQuestion: Does the Chi-square difference test support the hypothesis of equal residual variances?"
  },
  {
    "objectID": "latentgrowthmodel.html#bonus-3-parallel-growth-models",
    "href": "latentgrowthmodel.html#bonus-3-parallel-growth-models",
    "title": "9  Latent Growth Modeling",
    "section": "9.10 Bonus 3: Parallel Growth Models",
    "text": "9.10 Bonus 3: Parallel Growth Models\nWhen you collect data about multiple constructs across a period of time, you can also model the association between the two constructs using a parallel growth model. In this type of model, each construct gets its own growth model, and the intercept of one is used to predict the slope of the other model. This helps you answer the research question: Do initial levels of X predict subsequent changes in Y? We can try this out with PSP and SSA. We already know the optimal growth structure for PSP, but we still need to evaluate this question for SSA.\n\nlgm_linear2 &lt;- '\ni =~ 1*ssa1 + 1*ssa2 + 1*ssa3 + 1*ssa4 + 1*ssa5\ns =~ 0*ssa1 + 1*ssa2 + 2*ssa3 + 3*ssa4 + 4*ssa5\n'\n\nlgm_quad2 &lt;- '\ni =~ 1*ssa1 + 1*ssa2 + 1*ssa3 + 1*ssa4 + 1*ssa5\ns =~ 0*ssa1 + 1*ssa2 + 2*ssa3 + 3*ssa4 + 4*ssa5\nq =~ 0*ssa1 + 1*ssa2 + 4*ssa3 + 9*ssa4 + 16*ssa5\n'\n\nlgm_cube2 &lt;- '\ni =~ 1*ssa1 + 1*ssa2 + 1*ssa3 + 1*ssa4 + 1*ssa5\ns =~ 0*ssa1 + 1*ssa2 + 2*ssa3 + 3*ssa4 + 4*ssa5\nq =~ 0*ssa1 + 1*ssa2 + 4*ssa3 + 9*ssa4 + 16*ssa5\nc =~ 0*ssa1 + 1*ssa2 + 8*ssa3 + 27*ssa4 + 64*ssa5\n'\n\nlgm_basis2 &lt;- '\ni =~ 1*ssa1 + 1*ssa2 + 1*ssa3 + 1*ssa4 + 1*ssa5\ns =~ 0*ssa1 + ssa2 + ssa3 + ssa4 + 1*ssa5\n'\n\n# Fit the linear LGM using the growth() function\nfit_linear2 &lt;- growth(lgm_linear2, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\n# Fit the quadratic LGM using the growth() function\nfit_quad2 &lt;- growth(lgm_quad2, data = diary, \n                   estimator = \"mlr\", missing = \"fiml\")\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\n# Fit the quadratic LGM using the growth() function\nfit_cube2 &lt;- growth(lgm_cube2, data = diary, \n                   estimator = \"mlr\", missing = \"fiml\")\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\n# Fit the basis LGM using the growth() function\nfit_basis2 &lt;- growth(lgm_basis2, data = diary, \n                    estimator = \"mlr\", missing = \"fiml\")\n\ncomp2_lq &lt;- compareFit(fit_linear2, fit_quad2)\ncomp2_lq@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n            Df    AIC    BIC   Chisq Chisq diff Df diff Pr(&gt;Chisq)   \nfit_quad2    6 2505.8 2554.5  8.9613                                 \nfit_linear2 10 2513.8 2548.6 25.0069     14.339       4   0.006287 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncomp2_lc &lt;- compareFit(fit_linear2, fit_cube2)\ncomp2_lc@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n            Df    AIC    BIC   Chisq Chisq diff Df diff Pr(&gt;Chisq)   \nfit_cube2    1 2508.3 2574.5  1.5359                                 \nfit_linear2 10 2513.8 2548.6 25.0069     22.184       9   0.008313 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncomp2_lb &lt;- compareFit(fit_linear2, fit_basis2)\ncomp2_lb@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n            Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)   \nfit_basis2   7 2504.4 2549.7  9.664                                 \nfit_linear2 10 2513.8 2548.6 25.007     15.133       3   0.001706 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncomp2_qc &lt;- compareFit(fit_quad2, fit_cube2)\ncomp2_qc@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n          Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)\nfit_cube2  1 2508.3 2574.5 1.5359                              \nfit_quad2  6 2505.8 2554.5 8.9613     7.3576       5     0.1954\n\ncomp2_qcb &lt;- compareFit(fit_quad2, fit_cube2, fit_basis2)\ncomp2_qcb@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n           Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)\nfit_cube2   1 2508.3 2574.5 1.5359                              \nfit_quad2   6 2505.8 2554.5 8.9613     7.3576       5     0.1954\nfit_basis2  7 2504.4 2549.7 9.6640     0.4899       1     0.4840\n\n# Look at variances of linear and quadratic slope in quad model to check proportionality assumption\nparameterEstimates(fit_quad2) %&gt;% filter((lhs == \"s\" | lhs == \"q\") & op == \"~~\")\n\n  lhs op rhs    est    se      z pvalue ci.lower ci.upper\n1   s ~~   s  0.026 0.090  0.286  0.775   -0.150    0.202\n2   q ~~   q  0.004 0.005  0.753  0.451   -0.006    0.013\n3   s ~~   q -0.009 0.019 -0.444  0.657   -0.046    0.029\n\n\nBased on the analyses and comparisons above, I select the latent basis model, as it fit the data best (based on AIC and BIC), did not have computational issues (which the quadratic and cubic model did have), and the proportionality assumption is met.\nNext, we can specify and estimate the parallel growth model with both constructs. Make sure you give each construct’s intercept and slope a different name! Note that I include the code and output here for illustrative purposes. This model is likely to complex to estimate with this relatively small sample, which is resulting is impossible covariance/correlation estimates (see summary output below).\n\nlgm_parallel &lt;- '\nissa =~ 1*ssa1 + 1*ssa2 + 1*ssa3 + 1*ssa4 + 1*ssa5\nsssa =~ 0*ssa1 + ssa2 + ssa3 + ssa4 + 1*ssa5\n\nipsp =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\nspsp =~ 0*psp1 + psp2 + psp3 + psp4 + 1*psp5\n\n# covariances between pairs of intercept and slope\nissa ~~ ipsp\nsssa ~~ spsp\n\n# regression paths\nsssa ~ ipsp\nspsp ~ issa\n'\n\n# Fit the basis LGM using the growth() function\nfit_parallel &lt;- growth(lgm_parallel, data = diary, \n                    estimator = \"mlr\", missing = \"fiml\")\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nsummary(fit_parallel, fit.measures = T, std = T, rsquare = T)\n\nlavaan 0.6-19 ended normally after 60 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        28\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               172.804     174.997\n  Degrees of freedom                                37          37\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.987\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1719.080    1185.277\n  Degrees of freedom                                45          45\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.450\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.919       0.879\n  Tucker-Lewis Index (TLI)                       0.901       0.853\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.920\n  Robust Tucker-Lewis Index (TLI)                            0.902\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2857.531   -2857.531\n  Scaling correction factor                                  1.579\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -2771.129   -2771.129\n  Scaling correction factor                                  1.242\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                5771.062    5771.062\n  Bayesian (BIC)                              5868.520    5868.520\n  Sample-size adjusted Bayesian (SABIC)       5779.767    5779.767\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.124       0.125\n  90 Percent confidence interval - lower         0.105       0.106\n  90 Percent confidence interval - upper         0.143       0.144\n  P-value H_0: RMSEA &lt;= 0.050                    0.000       0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000       1.000\n                                                                  \n  Robust RMSEA                                               0.136\n  90 Percent confidence interval - lower                     0.113\n  90 Percent confidence interval - upper                     0.160\n  P-value H_0: Robust RMSEA &lt;= 0.050                         0.000\n  P-value H_0: Robust RMSEA &gt;= 0.080                         1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.041       0.041\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  issa =~                                                               \n    ssa1              1.000                               0.851    0.847\n    ssa2              1.000                               0.851    0.813\n    ssa3              1.000                               0.851    0.798\n    ssa4              1.000                               0.851    0.810\n    ssa5              1.000                               0.851    0.766\n  sssa =~                                                               \n    ssa1              0.000                               0.000    0.000\n    ssa2              0.672    0.174    3.863    0.000    0.420    0.402\n    ssa3              0.784    0.156    5.014    0.000    0.490    0.460\n    ssa4              0.864    0.102    8.510    0.000    0.540    0.514\n    ssa5              1.000                               0.625    0.563\n  ipsp =~                                                               \n    psp1              1.000                               1.383    0.818\n    psp2              1.000                               1.383    0.750\n    psp3              1.000                               1.383    0.728\n    psp4              1.000                               1.383    0.706\n    psp5              1.000                               1.383    0.695\n  spsp =~                                                               \n    psp1              0.000                               0.000    0.000\n    psp2              0.653    0.113    5.802    0.000    0.721    0.391\n    psp3              0.827    0.110    7.493    0.000    0.913    0.480\n    psp4              0.888    0.066   13.414    0.000    0.980    0.501\n    psp5              1.000                               1.104    0.555\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  sssa ~                                                                \n    ipsp             -0.126    0.060   -2.109    0.035   -0.280   -0.280\n  spsp ~                                                                \n    issa              0.037    0.171    0.215    0.830    0.028    0.028\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  issa ~~                                                               \n    ipsp              1.012    0.121    8.366    0.000    0.859    0.859\n .sssa ~~                                                               \n   .spsp              0.678    0.171    3.970    0.000    1.023    1.023\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    issa              1.645    0.065   25.493    0.000    1.934    1.934\n   .sssa              0.209    0.248    0.842    0.400    0.334    0.334\n    ipsp              4.455    0.112   39.601    0.000    3.220    3.220\n   .spsp             -1.128    0.292   -3.865    0.000   -1.022   -1.022\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .ssa1              0.284    0.055    5.137    0.000    0.284    0.282\n   .ssa2              0.366    0.060    6.063    0.000    0.366    0.334\n   .ssa3              0.372    0.055    6.769    0.000    0.372    0.327\n   .ssa4              0.310    0.058    5.331    0.000    0.310    0.281\n   .ssa5              0.373    0.099    3.778    0.000    0.373    0.303\n   .psp1              0.949    0.164    5.772    0.000    0.949    0.331\n   .psp2              0.916    0.131    6.981    0.000    0.916    0.270\n   .psp3              0.806    0.175    4.606    0.000    0.806    0.223\n   .psp4              0.893    0.249    3.584    0.000    0.893    0.233\n   .psp5              0.757    0.190    3.978    0.000    0.757    0.191\n    issa              0.724    0.078    9.253    0.000    1.000    1.000\n   .sssa              0.360    0.100    3.611    0.000    0.922    0.922\n    ipsp              1.914    0.254    7.532    0.000    1.000    1.000\n   .spsp              1.218    0.286    4.256    0.000    0.999    0.999\n\nR-Square:\n                   Estimate\n    ssa1              0.718\n    ssa2              0.666\n    ssa3              0.673\n    ssa4              0.719\n    ssa5              0.697\n    psp1              0.669\n    psp2              0.730\n    psp3              0.777\n    psp4              0.767\n    psp5              0.809\n    sssa              0.078\n    spsp              0.001\n\n\nThis model does not fit well (e.g., CFI &lt; .95). Local fit results (see below) indicate that the model does not adequately represent the associations between psp2 and ssa and ssa5. Given the good fit of each individual growth model, there appears to be something in the interplay between the two constructs that our parallel growth model is not capturing. Alternative models such as a random-intercept cross-lagged panel model could be explored.\n\nresiduals(fit_parallel, type = \"cor.bollen\")\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       ssa1   ssa2   ssa3   ssa4   ssa5   psp1   psp2   psp3   psp4   psp5\nssa1  0.000                                                               \nssa2  0.003  0.000                                                        \nssa3  0.003  0.055  0.000                                                 \nssa4  0.012  0.004 -0.018  0.000                                          \nssa5  0.022 -0.032 -0.007  0.015  0.000                                   \npsp1 -0.010 -0.007  0.001  0.001 -0.055  0.000                            \npsp2 -0.006  0.129 -0.008 -0.051 -0.105  0.026  0.000                     \npsp3  0.034  0.038  0.098 -0.051 -0.077 -0.004  0.043  0.000              \npsp4  0.028 -0.016 -0.036  0.041 -0.040 -0.014 -0.014 -0.022  0.000       \npsp5 -0.005 -0.048 -0.030 -0.008  0.070 -0.040 -0.062 -0.019  0.029  0.000\n\n$mean\n  ssa1   ssa2   ssa3   ssa4   ssa5   psp1   psp2   psp3   psp4   psp5 \n 0.006 -0.011  0.003 -0.034  0.040  0.016 -0.033 -0.022  0.005  0.052"
  },
  {
    "objectID": "measurementinvariance_cont.html#strong-scalar-invariance",
    "href": "measurementinvariance_cont.html#strong-scalar-invariance",
    "title": "7  Measurement Invariance Testing with Continuous Indicators",
    "section": "7.6 Strong (Scalar) Invariance",
    "text": "7.6 Strong (Scalar) Invariance\nAgain, all we need to do to estimate the Weak Invariance model is change the arguments of the function a little bit:\n\nfit.strong &lt;- measEq.syntax(configural.model = cfa_config, \n                            data = DASS21, \n                            group = \"engnat\", \n                            ID.fac = \"effects\", \n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"mlr\",\n                            group.equal = c(\"loadings\", \"intercepts\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.strong@call$model))\n\n\nModel Comparison\nTo test if we can retain the Strong Invariance model, we compare its fit to that of the Weak Invariance model:\n\ncomp_23 &lt;- compareFit(fit.weak, fit.strong)\nsummary(comp_23)\n\n################### Nested Model Comparison #########################\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan NOTE:\n    The \"Chisq\" column contains standard test statistics, not the\n    robust test that should be reported per model. A robust difference\n    test is a function of two standard (not robust) statistics.\n \n            Df   AIC   BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit.weak   160 35691 36074 382.85                                  \nfit.strong 172 35748 36072 463.60     81.276      12  2.356e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n           chisq.scaled df.scaled pvalue.scaled rmsea.robust cfi.robust\nfit.weak       330.756†       160          .000        .050†      .969†\nfit.strong     404.514        172          .000        .056       .958 \n           tli.robust  srmr        aic        bic\nfit.weak        .964† .036† 35691.248† 36074.053 \nfit.strong      .955  .042  35747.993  36071.905†\n\n################## Differences in Fit Indices #######################\n                      df.scaled rmsea.robust cfi.robust tli.robust  srmr    aic\nfit.strong - fit.weak        12        0.006     -0.011     -0.009 0.006 56.745\n                         bic\nfit.strong - fit.weak -2.148\n\n\nWhat does the Chi-square difference test result tell us?\n\n\nLocal Fit Comparison\nSince the fit worsened significantly when testing Strong Invariance, we will focus on problematic residuals in the mean vectors, since constraining the intercepts will affect model fit by changing the model implied means.\n\nresiduals(fit.strong, type = \"cor.bollen\")$EnglishNative$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n-0.119  0.014  0.009 -0.023  0.067 -0.017 -0.042  0.032 -0.006 -0.002  0.080 \n   q12    q14    q18 \n 0.006 -0.074 -0.118 \n\nresiduals(fit.strong, type = \"cor.bollen\")$ELL$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n 0.108 -0.018 -0.012  0.022 -0.069  0.017  0.035 -0.030  0.007  0.002 -0.078 \n   q12    q14    q18 \n-0.007  0.064  0.116 \n\n\nYou will notice that mean residuals for a specific indicator are negative for one group and positive for the other. When we constrain intercepts to be equal across groups, the estimate tends to find a compromise between the two group intercepts. Thus, one group will always have an observed mean that is above that estimate while the other has an observed mean that is below that estimate.\nWhich intercepts appear to be different across groups?"
  },
  {
    "objectID": "measurementinvariance_ord.html#loading-r-packages",
    "href": "measurementinvariance_ord.html#loading-r-packages",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.1 Loading R packages",
    "text": "10.1 Loading R packages\nLoad the required packages for this lab into your R environment.\n\nlibrary(rio)\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(semhelpinghands)\nlibrary(ggdist)"
  },
  {
    "objectID": "measurementinvariance_ord.html#loading-data",
    "href": "measurementinvariance_ord.html#loading-data",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.2 Loading Data",
    "text": "10.2 Loading Data\nLoad the data into your environment. For this lab we will use a dataset of N = 1000 individuals who completed the Depression-Anxiety-Stress Scales (DASS-21). For this lab, we will focus on the Anxiety and Stress subscales. We will see if there is measurement invariance across participants whose native language is English (1) versus participants who have a different native language/ELL (2).\nYou can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/DASS21.csv. Make sure to save it in the folder you are using for this class.\n\nDASS21 &lt;- import(file = \"data/DASS21.csv\")\n\nDASS21$engnat &lt;- factor(DASS21$engnat, \n                        levels = c(\"EnglishNative\", \"ELL\"))\n\nHere is an overview of the questions on the Anxiety subscale:\n\nq2: I was aware of dryness in my mouth\nq4: I experienced breathing difficulty (eg, excessively rapid breathing, breathlessness in the absence of physical exertion)\nq7: I experienced trembling (e.g., in the hands)\nq9: I was worried about situations in which I might panic and make a fool of myself.\nq15: I felt I was close to panic.\nq19: I was aware of the action of my heart in the absence of physical exertion (eg, sense of heart rate increase, heart missing a beat).\nq20: I felt scared without any good reason.\n\nAnd the questions on the Stress subscale:\n\nq1: I found it hard to wind down.\nq6: I tended to over-react to situations.\nq8: I felt that I was using a lot of nervous energy.\nq11: I found myself getting agitated.\nq12: I found it difficult to relax.\nq14: I was intolerant of anything that kept me from getting on with what I was doing.\nq18: I felt that I was rather touchy.\n\nYou may remember that we used this data when we talked about measurement invariance with continuous indicators. In reality, the responses to these items are on a four-point Likert-type scale, ranging from Never to Almost Always. As I’ve mentioned before, with fewer than 5 response options, assuming that data can be treated as though they are continuous is tenuous at best. In addition, the response distributions for some of these items are skewed (see plots below). Thus, in this lab, we will examine if levels of measurement invariance can be retained when we properly model the data as ordinal instead of continuous.\n\nDASS21 %&gt;%\n  select(q2, q4, q7, q9, q15, q19, q20) %&gt;%\n  pivot_longer(cols = q2:q20) %&gt;%\n  ggplot(aes(x = value)) + \n  geom_bar() + \n  facet_wrap(vars(name)) +\n  ggtitle(\"Anxiety Subscale\")\n\n\n\nDASS21 %&gt;%\n  select(q1, q6, q8, q11, q12, q14, q18) %&gt;%\n  pivot_longer(cols = q1:q18) %&gt;%\n  ggplot(aes(x = value)) + \n  geom_bar() + \n  facet_wrap(vars(name)) +\n  ggtitle(\"Stress Subscale\")"
  },
  {
    "objectID": "measurementinvariance_ord.html#statistical-decision-criteria",
    "href": "measurementinvariance_ord.html#statistical-decision-criteria",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.3 Statistical Decision Criteria",
    "text": "10.3 Statistical Decision Criteria\nFor this lab, I will use the following statistical decision criteria for the model comparison tests between levels of invariance. These are based on the knowledge that our samples are relatively large (N = 500 per group), and are informed by the textbook and Chen (2007):\n\nLook at Chi-square Difference test.\n\nIf not significant: retain next level of invariance\nIf significant, look at other fit information\n\nAre there any patterns of problematic correlation residuals &gt; |.10|? Reject next level of invariance, test partial invariance\nDoes CFI decrease ≤ 0.010 or does RMSEA increase by ≥ 0.015? Reject next level of invariance, test partial invariance"
  },
  {
    "objectID": "measurementinvariance_ord.html#configural-invariance",
    "href": "measurementinvariance_ord.html#configural-invariance",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.4 Configural Invariance",
    "text": "10.4 Configural Invariance\nWe will specify a two-factor CFA using lavaan syntax. Based on previous research, this two-factor model already includes residual covariances between two pairs of items. What these items have in common is that they focus on physical symptoms of anxiety, which causes them to share more commmon variance with each other (especially with q4) than with the other anxiety items.\n\ncfa_config &lt;- '\nanxiety =~ q2 + q4 + q7 + q9 + q15 + q19 + q20\nstress =~ q1 + q6 + q8 + q11 + q12 + q14 + q18\n\nq4 ~~ q19\nq4 ~~ q7\n'\n\nWe are going to use a function from the semTools package that will help us set the scale for our latent factors and apply the equality constraint labels. This saves us A LOT of typing. Given the ordinal nature of our indicators, we will use the Wu & Estabrook (2016) approach for model identification, which is typically combined with the unit-variance scaling of the latent factors (so the variances of the factors are [initially] fixed to 1, factor means are [initially] fixed to zero, and all loadings are estimated in both groups). In addition, we use Delta parameterization, which scales the latent response variables to follow a standard Normal distribution.\nWe also have to declare that the indicators are ordinal, which we can do by adding ordered = T. If you have a mix of ordinal and continuous items in your analysis, you need to specify which variables are ordinal: ordered = c(\"q1\", \"q2\").\nFinally, we switch the estimator to wlsmv, which stands for weighted least sqaures-mean and variance adjusted. This is the recommended estimator for analyses with ordinal endogenous variables.\n\nfit.config &lt;- measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\")\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\ncat(as.character(fit.config@call$model))\n\n## LOADINGS:\n\nanxiety =~ c(NA, NA)*q2 + c(lambda.1_1.g1, lambda.1_1.g2)*q2\nanxiety =~ c(NA, NA)*q4 + c(lambda.2_1.g1, lambda.2_1.g2)*q4\nanxiety =~ c(NA, NA)*q7 + c(lambda.3_1.g1, lambda.3_1.g2)*q7\nanxiety =~ c(NA, NA)*q9 + c(lambda.4_1.g1, lambda.4_1.g2)*q9\nanxiety =~ c(NA, NA)*q15 + c(lambda.5_1.g1, lambda.5_1.g2)*q15\nanxiety =~ c(NA, NA)*q19 + c(lambda.6_1.g1, lambda.6_1.g2)*q19\nanxiety =~ c(NA, NA)*q20 + c(lambda.7_1.g1, lambda.7_1.g2)*q20\nstress =~ c(NA, NA)*q1 + c(lambda.8_2.g1, lambda.8_2.g2)*q1\nstress =~ c(NA, NA)*q6 + c(lambda.9_2.g1, lambda.9_2.g2)*q6\nstress =~ c(NA, NA)*q8 + c(lambda.10_2.g1, lambda.10_2.g2)*q8\nstress =~ c(NA, NA)*q11 + c(lambda.11_2.g1, lambda.11_2.g2)*q11\nstress =~ c(NA, NA)*q12 + c(lambda.12_2.g1, lambda.12_2.g2)*q12\nstress =~ c(NA, NA)*q14 + c(lambda.13_2.g1, lambda.13_2.g2)*q14\nstress =~ c(NA, NA)*q18 + c(lambda.14_2.g1, lambda.14_2.g2)*q18\n\n## THRESHOLDS:\n\nq2 | c(NA, NA)*t1 + c(q2.thr1.g1, q2.thr1.g2)*t1\nq2 | c(NA, NA)*t2 + c(q2.thr2.g1, q2.thr2.g2)*t2\nq2 | c(NA, NA)*t3 + c(q2.thr3.g1, q2.thr3.g2)*t3\nq4 | c(NA, NA)*t1 + c(q4.thr1.g1, q4.thr1.g2)*t1\nq4 | c(NA, NA)*t2 + c(q4.thr2.g1, q4.thr2.g2)*t2\nq4 | c(NA, NA)*t3 + c(q4.thr3.g1, q4.thr3.g2)*t3\nq7 | c(NA, NA)*t1 + c(q7.thr1.g1, q7.thr1.g2)*t1\nq7 | c(NA, NA)*t2 + c(q7.thr2.g1, q7.thr2.g2)*t2\nq7 | c(NA, NA)*t3 + c(q7.thr3.g1, q7.thr3.g2)*t3\nq9 | c(NA, NA)*t1 + c(q9.thr1.g1, q9.thr1.g2)*t1\nq9 | c(NA, NA)*t2 + c(q9.thr2.g1, q9.thr2.g2)*t2\nq9 | c(NA, NA)*t3 + c(q9.thr3.g1, q9.thr3.g2)*t3\nq15 | c(NA, NA)*t1 + c(q15.thr1.g1, q15.thr1.g2)*t1\nq15 | c(NA, NA)*t2 + c(q15.thr2.g1, q15.thr2.g2)*t2\nq15 | c(NA, NA)*t3 + c(q15.thr3.g1, q15.thr3.g2)*t3\nq19 | c(NA, NA)*t1 + c(q19.thr1.g1, q19.thr1.g2)*t1\nq19 | c(NA, NA)*t2 + c(q19.thr2.g1, q19.thr2.g2)*t2\nq19 | c(NA, NA)*t3 + c(q19.thr3.g1, q19.thr3.g2)*t3\nq20 | c(NA, NA)*t1 + c(q20.thr1.g1, q20.thr1.g2)*t1\nq20 | c(NA, NA)*t2 + c(q20.thr2.g1, q20.thr2.g2)*t2\nq20 | c(NA, NA)*t3 + c(q20.thr3.g1, q20.thr3.g2)*t3\nq1 | c(NA, NA)*t1 + c(q1.thr1.g1, q1.thr1.g2)*t1\nq1 | c(NA, NA)*t2 + c(q1.thr2.g1, q1.thr2.g2)*t2\nq1 | c(NA, NA)*t3 + c(q1.thr3.g1, q1.thr3.g2)*t3\nq6 | c(NA, NA)*t1 + c(q6.thr1.g1, q6.thr1.g2)*t1\nq6 | c(NA, NA)*t2 + c(q6.thr2.g1, q6.thr2.g2)*t2\nq6 | c(NA, NA)*t3 + c(q6.thr3.g1, q6.thr3.g2)*t3\nq8 | c(NA, NA)*t1 + c(q8.thr1.g1, q8.thr1.g2)*t1\nq8 | c(NA, NA)*t2 + c(q8.thr2.g1, q8.thr2.g2)*t2\nq8 | c(NA, NA)*t3 + c(q8.thr3.g1, q8.thr3.g2)*t3\nq11 | c(NA, NA)*t1 + c(q11.thr1.g1, q11.thr1.g2)*t1\nq11 | c(NA, NA)*t2 + c(q11.thr2.g1, q11.thr2.g2)*t2\nq11 | c(NA, NA)*t3 + c(q11.thr3.g1, q11.thr3.g2)*t3\nq12 | c(NA, NA)*t1 + c(q12.thr1.g1, q12.thr1.g2)*t1\nq12 | c(NA, NA)*t2 + c(q12.thr2.g1, q12.thr2.g2)*t2\nq12 | c(NA, NA)*t3 + c(q12.thr3.g1, q12.thr3.g2)*t3\nq14 | c(NA, NA)*t1 + c(q14.thr1.g1, q14.thr1.g2)*t1\nq14 | c(NA, NA)*t2 + c(q14.thr2.g1, q14.thr2.g2)*t2\nq14 | c(NA, NA)*t3 + c(q14.thr3.g1, q14.thr3.g2)*t3\nq18 | c(NA, NA)*t1 + c(q18.thr1.g1, q18.thr1.g2)*t1\nq18 | c(NA, NA)*t2 + c(q18.thr2.g1, q18.thr2.g2)*t2\nq18 | c(NA, NA)*t3 + c(q18.thr3.g1, q18.thr3.g2)*t3\n\n## INTERCEPTS:\n\nq2 ~ c(0, 0)*1 + c(nu.1.g1, nu.1.g2)*1\nq4 ~ c(0, 0)*1 + c(nu.2.g1, nu.2.g2)*1\nq7 ~ c(0, 0)*1 + c(nu.3.g1, nu.3.g2)*1\nq9 ~ c(0, 0)*1 + c(nu.4.g1, nu.4.g2)*1\nq15 ~ c(0, 0)*1 + c(nu.5.g1, nu.5.g2)*1\nq19 ~ c(0, 0)*1 + c(nu.6.g1, nu.6.g2)*1\nq20 ~ c(0, 0)*1 + c(nu.7.g1, nu.7.g2)*1\nq1 ~ c(0, 0)*1 + c(nu.8.g1, nu.8.g2)*1\nq6 ~ c(0, 0)*1 + c(nu.9.g1, nu.9.g2)*1\nq8 ~ c(0, 0)*1 + c(nu.10.g1, nu.10.g2)*1\nq11 ~ c(0, 0)*1 + c(nu.11.g1, nu.11.g2)*1\nq12 ~ c(0, 0)*1 + c(nu.12.g1, nu.12.g2)*1\nq14 ~ c(0, 0)*1 + c(nu.13.g1, nu.13.g2)*1\nq18 ~ c(0, 0)*1 + c(nu.14.g1, nu.14.g2)*1\n\n## SCALING FACTORS:\n\nq2 ~*~ c(1, 1)*q2\nq4 ~*~ c(1, 1)*q4\nq7 ~*~ c(1, 1)*q7\nq9 ~*~ c(1, 1)*q9\nq15 ~*~ c(1, 1)*q15\nq19 ~*~ c(1, 1)*q19\nq20 ~*~ c(1, 1)*q20\nq1 ~*~ c(1, 1)*q1\nq6 ~*~ c(1, 1)*q6\nq8 ~*~ c(1, 1)*q8\nq11 ~*~ c(1, 1)*q11\nq12 ~*~ c(1, 1)*q12\nq14 ~*~ c(1, 1)*q14\nq18 ~*~ c(1, 1)*q18\n\n\n## UNIQUE-FACTOR COVARIANCES:\n\nq4 ~~ c(NA, NA)*q7 + c(theta.3_2.g1, theta.3_2.g2)*q7\nq4 ~~ c(NA, NA)*q19 + c(theta.6_2.g1, theta.6_2.g2)*q19\n\n## LATENT MEANS/INTERCEPTS:\n\nanxiety ~ c(0, 0)*1 + c(alpha.1.g1, alpha.1.g2)*1\nstress ~ c(0, 0)*1 + c(alpha.2.g1, alpha.2.g2)*1\n\n## COMMON-FACTOR VARIANCES:\n\nanxiety ~~ c(1, 1)*anxiety + c(psi.1_1.g1, psi.1_1.g2)*anxiety\nstress ~~ c(1, 1)*stress + c(psi.2_2.g1, psi.2_2.g2)*stress\n\n## COMMON-FACTOR COVARIANCES:\n\nanxiety ~~ c(NA, NA)*stress + c(psi.2_1.g1, psi.2_1.g2)*stress\n\n\nTo see if the configural model is tenable, we will first inspect indices of global (exact and approximate) fit. With WLSMV, we focus on scaled (but NOT robust) fit indices. To save space, we will use the fitMeasures function, which prints out just the fit indices we ask for.\n\nfitMeasures(fit.config, \n            fit.measures = c(\"chisq.scaled\", \"df.scaled\", \n                             \"pvalue.scaled\", \"cfi.scaled\", \n                             \"rmsea.scaled\", \"rmsea.ci.lower.scaled\", \n                             \"rmsea.ci.upper.scaled\", \"srmr\"))\n\n         chisq.scaled             df.scaled         pvalue.scaled \n              428.078               148.000                 0.000 \n           cfi.scaled          rmsea.scaled rmsea.ci.lower.scaled \n                0.982                 0.062                 0.055 \nrmsea.ci.upper.scaled                  srmr \n                0.068                 0.037 \n\n\nThe Chi-square test is significant, but other indices look better. Our sample is relatively large, so we will look at the local fit indices to see if any remaining misfit is trivial, or if there are major issues. With ordinal data, we get residuals for the covariances, means, and thresholds. Right now, our model only constrains the covariances, so we will focus on that output.\n\nresiduals(fit.config, type = \"cor.bollen\")$EnglishNative$cov\n\n        q2     q4     q7     q9    q15    q19    q20     q1     q6     q8\nq2   0.000                                                               \nq4   0.081  0.000                                                        \nq7   0.055  0.000  0.000                                                 \nq9  -0.047 -0.051  0.020  0.000                                          \nq15 -0.086  0.026 -0.017 -0.014  0.000                                   \nq19  0.040  0.000  0.076 -0.047 -0.034  0.000                            \nq20 -0.087  0.024 -0.040  0.032  0.007 -0.025  0.000                     \nq1  -0.033 -0.051 -0.045 -0.018 -0.006  0.016 -0.010  0.000              \nq6  -0.008 -0.035 -0.036  0.040  0.009 -0.007 -0.020 -0.034  0.000       \nq8   0.001  0.014  0.093  0.040  0.065  0.029  0.064 -0.062 -0.061  0.000\nq11  0.004 -0.048 -0.088  0.013 -0.028 -0.031 -0.004 -0.009  0.061 -0.060\nq12 -0.040  0.007 -0.056 -0.037  0.018 -0.027 -0.038  0.095 -0.014 -0.037\nq14  0.063 -0.036 -0.013 -0.021 -0.044  0.021 -0.024  0.026 -0.003 -0.121\nq18  0.043  0.028  0.001  0.018 -0.060  0.002 -0.010 -0.043  0.057 -0.050\n       q11    q12    q14    q18\nq2                             \nq4                             \nq7                             \nq9                             \nq15                            \nq19                            \nq20                            \nq1                             \nq6                             \nq8                             \nq11  0.000                     \nq12 -0.016  0.000              \nq14  0.107 -0.037  0.000       \nq18  0.014 -0.015  0.038  0.000\n\nresiduals(fit.config, type = \"cor.bollen\")$ELL$cov\n\n        q2     q4     q7     q9    q15    q19    q20     q1     q6     q8\nq2   0.000                                                               \nq4   0.080  0.000                                                        \nq7   0.027  0.000  0.000                                                 \nq9  -0.024 -0.030 -0.022  0.000                                          \nq15 -0.052  0.008  0.013  0.045  0.000                                   \nq19  0.024  0.000  0.039 -0.087  0.001  0.000                            \nq20  0.007 -0.048 -0.017  0.020  0.006 -0.052  0.000                     \nq1  -0.029 -0.016 -0.032 -0.061 -0.051 -0.014 -0.019  0.000              \nq6  -0.003  0.001 -0.032 -0.001 -0.020 -0.011  0.004  0.041  0.000       \nq8   0.012  0.023  0.063  0.062  0.048  0.049  0.015 -0.073 -0.070  0.000\nq11  0.025 -0.012 -0.056 -0.017 -0.016  0.018  0.033  0.038 -0.028 -0.031\nq12 -0.055  0.004 -0.028 -0.026 -0.012  0.024  0.005  0.077 -0.016 -0.025\nq14 -0.020  0.005  0.003  0.005 -0.054 -0.031 -0.005  0.039  0.047 -0.029\nq18  0.002  0.005  0.007  0.015 -0.049  0.033  0.009 -0.042  0.092 -0.068\n       q11    q12    q14    q18\nq2                             \nq4                             \nq7                             \nq9                             \nq15                            \nq19                            \nq20                            \nq1                             \nq6                             \nq8                             \nq11  0.000                     \nq12  0.005  0.000              \nq14  0.003  0.001  0.000       \nq18  0.026 -0.049  0.006  0.000\n\n\nOverall, the correlation residuals look good. Only the correlation residuals of q14 with q8 and q11 were &gt; |.1| in the English native speaker group. There is no a priori justification why these three items share an omitted cause (that could be accommodated via a residual covariance). In addition, the correlation residuals were relatively close to |.1|, indicating that adding a residual covariance would likely only have a small impact on global model fit. Thus, we will retain the configural invariance model, and examine threshold invariance.\n\nParameter Estimate Interpretation\nUsing the function below, we can compare the estimates across groups and see that all the measurement-related parameters are still varying across groups (as we have not included any equality constraints yet).\n\ngroup_by_groups(fit.config)\n\n        lhs  op     rhs est_EnglishNative est_ELL\n1   anxiety  =~     q15             0.869   0.854\n2   anxiety  =~     q19             0.660   0.683\n3   anxiety  =~      q2             0.574   0.566\n4   anxiety  =~     q20             0.782   0.809\n5   anxiety  =~      q4             0.742   0.686\n6   anxiety  =~      q7             0.720   0.677\n7   anxiety  =~      q9             0.772   0.735\n8    stress  =~      q1             0.799   0.776\n9    stress  =~     q11             0.760   0.763\n10   stress  =~     q12             0.820   0.791\n11   stress  =~     q14             0.656   0.692\n12   stress  =~     q18             0.655   0.608\n13   stress  =~      q6             0.779   0.742\n14   stress  =~      q8             0.824   0.829\n15  anxiety  ~~ anxiety             1.000   1.000\n16  anxiety  ~~  stress             0.902   0.917\n17       q1  ~~      q1             0.361   0.397\n18      q11  ~~     q11             0.423   0.418\n19      q12  ~~     q12             0.327   0.375\n20      q14  ~~     q14             0.570   0.521\n21      q15  ~~     q15             0.246   0.270\n22      q18  ~~     q18             0.571   0.631\n23      q19  ~~     q19             0.565   0.534\n24       q2  ~~      q2             0.671   0.680\n25      q20  ~~     q20             0.389   0.346\n26       q4  ~~     q19             0.183   0.174\n27       q4  ~~      q4             0.449   0.529\n28       q4  ~~      q7             0.047   0.144\n29       q6  ~~      q6             0.393   0.449\n30       q7  ~~      q7             0.481   0.541\n31       q8  ~~      q8             0.321   0.313\n32       q9  ~~      q9             0.405   0.460\n33   stress  ~~  stress             1.000   1.000\n34  anxiety  ~1                     0.000   0.000\n35       q1  ~1                     0.000   0.000\n36      q11  ~1                     0.000   0.000\n37      q12  ~1                     0.000   0.000\n38      q14  ~1                     0.000   0.000\n39      q15  ~1                     0.000   0.000\n40      q18  ~1                     0.000   0.000\n41      q19  ~1                     0.000   0.000\n42       q2  ~1                     0.000   0.000\n43      q20  ~1                     0.000   0.000\n44       q4  ~1                     0.000   0.000\n45       q6  ~1                     0.000   0.000\n46       q7  ~1                     0.000   0.000\n47       q8  ~1                     0.000   0.000\n48       q9  ~1                     0.000   0.000\n49   stress  ~1                     0.000   0.000\n50       q1   |      t1            -0.820  -0.713\n51       q1   |      t2             0.025   0.440\n52       q1   |      t3             0.700   1.080\n53      q11   |      t1            -1.054  -0.693\n54      q11   |      t2            -0.065   0.332\n55      q11   |      t3             0.530   0.986\n56      q12   |      t1            -0.915  -0.739\n57      q12   |      t2            -0.070   0.238\n58      q12   |      t3             0.559   0.834\n59      q14   |      t1            -0.693  -0.687\n60      q14   |      t2             0.285   0.321\n61      q14   |      t3             0.878   1.019\n62      q15   |      t1            -0.674  -0.305\n63      q15   |      t2             0.111   0.457\n64      q15   |      t3             0.772   1.071\n65      q18   |      t1            -0.662  -0.923\n66      q18   |      t2             0.050   0.045\n67      q18   |      t3             0.674   0.700\n68      q19   |      t1            -0.451  -0.353\n69      q19   |      t2             0.212   0.316\n70      q19   |      t3             0.820   0.954\n71       q2   |      t1            -0.217  -0.490\n72       q2   |      t2             0.407   0.274\n73       q2   |      t3             0.793   0.856\n74      q20   |      t1            -0.530  -0.542\n75      q20   |      t2             0.176   0.305\n76      q20   |      t3             0.726   0.900\n77       q4   |      t1            -0.238  -0.055\n78       q4   |      t2             0.418   0.631\n79       q4   |      t3             0.994   1.195\n80       q6   |      t1            -0.938  -0.779\n81       q6   |      t2            -0.080   0.192\n82       q6   |      t3             0.565   0.772\n83       q7   |      t1            -0.321  -0.100\n84       q7   |      t2             0.490   0.668\n85       q7   |      t3             1.019   1.136\n86       q8   |      t1            -0.745  -0.643\n87       q8   |      t2            -0.025   0.285\n88       q8   |      t3             0.625   0.915\n89       q9   |      t1            -0.849  -0.962\n90       q9   |      t2            -0.187  -0.010\n91       q9   |      t3             0.348   0.571\n92       q1 ~*~      q1             1.000   1.000\n93      q11 ~*~     q11             1.000   1.000\n94      q12 ~*~     q12             1.000   1.000\n95      q14 ~*~     q14             1.000   1.000\n96      q15 ~*~     q15             1.000   1.000\n97      q18 ~*~     q18             1.000   1.000\n98      q19 ~*~     q19             1.000   1.000\n99       q2 ~*~      q2             1.000   1.000\n100     q20 ~*~     q20             1.000   1.000\n101      q4 ~*~      q4             1.000   1.000\n102      q6 ~*~      q6             1.000   1.000\n103      q7 ~*~      q7             1.000   1.000\n104      q8 ~*~      q8             1.000   1.000\n105      q9 ~*~      q9             1.000   1.000"
  },
  {
    "objectID": "measurementinvariance_ord.html#threshold-invariance",
    "href": "measurementinvariance_ord.html#threshold-invariance",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.5 Threshold Invariance",
    "text": "10.5 Threshold Invariance\nAll we need to do to estimate the Threshold Invariance model is change the arguments of the function a little bit (add group.equal = \"thresholds\"):\n\nfit.thresh &lt;- measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\",\n                            group.equal = \"thresholds\")\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.thresh@call$model))\n\nIn the model syntax above (if you remove the # and run the line of code), you can see that each factor loading now has the same label across the two groups, ensuring that they are constraint to be equal.\n\nModel Comparison\nTo test if we can retain the Threshold Invariance model, we compare its fit to that of the Configural Invariance model:\n\ncomp_12 &lt;- compareFit(fit.config, fit.thresh)\ncomp_12@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n            Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)\nfit.config 148         227.63                              \nfit.thresh 162         234.16     18.999      14      0.165\n\n\nWhat does the Chi-square difference test result tell us?\n\n\nParameter Estimate Interpretation\nUsing the function below, we can easily compare the estimates across groups and see that all the thresholds are now exactly the same (because we constrained them to be).\n\n# Look at threshold parameter estimates across groups by using filter \n# to include only results with the threshold operator \"|\"\ngroup_by_groups(fit.thresh) %&gt;% filter(op == \"|\")\n\n   lhs op rhs est_EnglishNative est_ELL\n1   q1  |  t1            -0.843  -0.843\n2   q1  |  t2             0.070   0.070\n3   q1  |  t3             0.667   0.667\n4  q11  |  t1            -1.050  -1.050\n5  q11  |  t2            -0.072  -0.072\n6  q11  |  t3             0.535   0.535\n7  q12  |  t1            -0.928  -0.928\n8  q12  |  t2            -0.047  -0.047\n9  q12  |  t3             0.544   0.544\n10 q14  |  t1            -0.686  -0.686\n11 q14  |  t2             0.269   0.269\n12 q14  |  t3             0.890   0.890\n13 q15  |  t1            -0.677  -0.677\n14 q15  |  t2             0.115   0.115\n15 q15  |  t3             0.769   0.769\n16 q18  |  t1            -0.678  -0.678\n17 q18  |  t2             0.082   0.082\n18 q18  |  t3             0.653   0.653\n19 q19  |  t1            -0.449  -0.449\n20 q19  |  t2             0.208   0.208\n21 q19  |  t3             0.823   0.823\n22  q2  |  t1            -0.209  -0.209\n23  q2  |  t2             0.386   0.386\n24  q2  |  t3             0.807   0.807\n25 q20  |  t1            -0.535  -0.535\n26 q20  |  t2             0.187   0.187\n27 q20  |  t3             0.718   0.718\n28  q4  |  t1            -0.241  -0.241\n29  q4  |  t2             0.424   0.424\n30  q4  |  t3             0.990   0.990\n31  q6  |  t1            -0.953  -0.953\n32  q6  |  t2            -0.054  -0.054\n33  q6  |  t3             0.548   0.548\n34  q7  |  t1            -0.323  -0.323\n35  q7  |  t2             0.496   0.496\n36  q7  |  t3             1.015   1.015\n37  q8  |  t1            -0.763  -0.763\n38  q8  |  t2             0.008   0.008\n39  q8  |  t3             0.603   0.603\n40  q9  |  t1            -0.865  -0.865\n41  q9  |  t2            -0.155  -0.155\n42  q9  |  t3             0.328   0.328\n\n\nWhen we retain the Threshold Invariance model, we can conclude that participants in both groups switch from one response option to the next at equivalent locations on the latent response variable. Confirming this level of invariance allows us to movee to the more familiar weak (loadings) and strong (intercepts) variance."
  },
  {
    "objectID": "measurementinvariance_ord.html#weak-metric-invariance",
    "href": "measurementinvariance_ord.html#weak-metric-invariance",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.6 Weak (Metric) Invariance",
    "text": "10.6 Weak (Metric) Invariance\nAgain, all we need to do to estimate the Loading Invariance model is change the arguments of the function a little bit:\n\nfit.weak &lt;- measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\",\n                            group.equal = c(\"thresholds\",\"loadings\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.weak@call$model))\n\n\nModel Comparison\nTo test if we can retain the Strong Invariance model, we compare its fit to that of the Weak Invariance model:\n\ncomp_23 &lt;- compareFit(fit.thresh, fit.weak)\ncomp_23@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n            Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)  \nfit.thresh 162         234.16                                \nfit.weak   174         252.28     18.577      12    0.09925 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat does the Chi-square difference test result tell us?\nWhen we retain the Weak Invariance model, we can conclude that the measured concepts (Anxiety and Stress) have the same meaning across groups, because the item-factor associations can be considered equivalent (the same amount of common variance is extracted across groups)."
  },
  {
    "objectID": "measurementinvariance_ord.html#strong-scalar-invariance",
    "href": "measurementinvariance_ord.html#strong-scalar-invariance",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.7 Strong (Scalar) Invariance",
    "text": "10.7 Strong (Scalar) Invariance\n\nfit.strong &lt;- measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\",\n                            group.equal = c(\"thresholds\", \n                                            \"loadings\", \n                                            \"intercepts\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.strong@call$model))\n\n\nModel Comparison\nTo test if we can retain the Strong Invariance model, we compare its fit to that of the Weak Invariance model:\n\ncomp_34 &lt;- compareFit(fit.weak, fit.strong)\ncomp_34@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n            Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit.weak   174         252.28                                  \nfit.strong 186         347.39     88.083      12  1.159e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat does the Chi-square difference test result tell us?\n\n\nLocal Fit Comparison\nTypically, we would look at mean residuals here. However, since the observed means depend on the latent response variable intercept and the thresholds, large residuals may be due to a combinations of small misfit in each of these parameter types. So, large values may not neccessarily point towards a problem with the latent response variable intercepts.\n\nresiduals(fit.strong, type = \"cor.bollen\")$EnglishNative$mean\n\n q2  q4  q7  q9 q15 q19 q20  q1  q6  q8 q11 q12 q14 q18 \n  0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n\nresiduals(fit.strong, type = \"cor.bollen\")$ELL$mean\n\n   q2    q4    q7    q9   q15   q19   q20    q1    q6    q8   q11   q12   q14 \n0.094 0.122 0.119 0.126 0.143 0.109 0.128 0.203 0.199 0.210 0.195 0.209 0.169 \n  q18 \n0.164 \n\n\nYou will notice that mean residuals for a specific indicator are 0 for the first group and a different value for the second group. When we constrain intercepts of the latent response variables to be equal across groups, with ordinal variables, the latent response variable intercept will map onto the observed mean (resulting in a mean residual of 0 for that group). In the analysis, this step is implemented by fixing the intercept to 0 in both groups.\nTo better understand how the equivalence of the latent response variable intercepts affected local fit, we can use the difference between the mean residuals of the Weak and Strong model. This shows which mean residuals changed most as a consequence of fixing the intercepts to 0:\n\nresiduals(fit.weak, type = \"cor.bollen\")$ELL$mean - residuals(fit.strong, type = \"cor.bollen\")$ELL$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n-0.239  0.066  0.047 -0.009  0.171 -0.029 -0.058  0.078  0.012  0.005  0.183 \n   q12    q14    q18 \n 0.038 -0.140 -0.234 \n\n\nWhich intercepts appear to be most different across groups (in an absolute sense)?"
  },
  {
    "objectID": "measurementinvariance_ord.html#partial-strong-invariance-round-1",
    "href": "measurementinvariance_ord.html#partial-strong-invariance-round-1",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.8 Partial Strong Invariance (Round 1)",
    "text": "10.8 Partial Strong Invariance (Round 1)\nSince the fit worsened significantly when testing Strong Invariance, we will focus on identifying problematic latent response variable intercepts. In this case, we can use the modindices function. This is different from measurement invariance with continuous indicators. With continuous indicators, we use an equivalence constraint to force the intercepts to be equivalent, and we need to use lavTestScore to see what would happen to model fit if the equivalence constraint was removed. With ordinal indicators, latent response variable invariance is accomplished by fixing the intercepts to 0 in both groups (instead of 0 in one group and freely estimated in the other). Thus, with ordinal variables, the intercept is not estimated, so we can use modification indices to examine to what extent model fit would improve if an intercept is freely estimated.\n\nmodificationIndices(fit.strong, sort. = TRUE, op = \"~1\", \n                    minimum.value = 15)\n\nWarning: lavaan-&gt;modificationIndices():  \n   the modindices() function ignores equality constraints; use lavTestScore() \n   to assess the impact of releasing one or multiple constraints.\n\n\n    lhs op rhs block group level     mi    epc sepc.lv sepc.all sepc.nox\n57   q2 ~1         1     1     1 28.618  0.266   0.266    0.266    0.266\n162  q2 ~1         2     2     1 28.618 -0.266  -0.266   -0.289   -0.289\n70  q18 ~1         1     1     1 27.358  0.261   0.261    0.261    0.261\n175 q18 ~1         2     2     1 27.358 -0.261  -0.261   -0.280   -0.280\n67  q11 ~1         1     1     1 17.439 -0.214  -0.214   -0.214   -0.214\n172 q11 ~1         2     2     1 17.439  0.214   0.214    0.241    0.241\n166 q15 ~1         2     2     1 15.841  0.212   0.212    0.231    0.231\n61  q15 ~1         1     1     1 15.840 -0.212  -0.212   -0.212   -0.212\n\n\nWhich intercepts appear to be different across groups?\nIn our previous analyses of these data (treating the data as continuous), we found that item 18 and item 2 had non-invariant intercepts. Those same intercepts emerge as problematic in this analysis.\n\nModel Comparison\nTo test if releasing the constraint for item 2 improves the fit of the Partial Strong Model sufficiently, we need to estimate the partial model. To do so, we can use the group.partial argument in the measEq.syntax() function:\n\nfit.partial1 &lt;- measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\",\n                            group.equal = c(\"thresholds\", \n                                            \"loadings\", \n                                            \"intercepts\"),\n                            group.partial = c(\"q2 ~ 1\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial1@call$model))\n\nLet’s compare the fit of this model to the Weak Invariance model\n\ncomp_34b &lt;- compareFit(fit.weak, fit.partial1)\ncomp_34b@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n              Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit.weak     174         252.28                                  \nfit.partial1 185         318.72     64.682      11  1.236e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat do the results indicate?"
  },
  {
    "objectID": "measurementinvariance_ord.html#partial-strong-invariance-round-2",
    "href": "measurementinvariance_ord.html#partial-strong-invariance-round-2",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.9 Partial Strong Invariance (Round 2)",
    "text": "10.9 Partial Strong Invariance (Round 2)\nSince the model fit indicated some remaining issues with retaining the Partial Strong Invariance model, we will do another round of partial invariance testing:\n\nmodificationIndices(fit.partial1, sort. = TRUE, op = \"~1\", \n                    minimum.value = 15)\n\nWarning: lavaan-&gt;modificationIndices():  \n   the modindices() function ignores equality constraints; use lavTestScore() \n   to assess the impact of releasing one or multiple constraints.\n\n\n    lhs op rhs block group level     mi    epc sepc.lv sepc.all sepc.nox\n70  q18 ~1         1     1     1 27.356  0.262   0.262    0.262    0.262\n175 q18 ~1         2     2     1 27.356 -0.262  -0.262   -0.280   -0.280\n172 q11 ~1         2     2     1 17.437  0.214   0.214    0.241    0.241\n67  q11 ~1         1     1     1 17.437 -0.214  -0.214   -0.214   -0.214\n\n\n\nModel Comparison\nThe intercept of item 18 remains the most problematic. To test if releasing this constraint improves the fit of the Partial Strong Model sufficiently, we need to estimate a second partial model. To do so, we can use the group.partial argument in the measEq.syntax() function and add this second intercept:\n\nfit.partial2 &lt;- measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\",\n                            group.equal = c(\"thresholds\", \n                                            \"loadings\", \n                                            \"intercepts\"),\n                            group.partial = c(\"q2 ~ 1\", \"q18 ~ 1\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial2@call$model))\n\nLet’s compare the fit of this model to the Weak Invariance model\n\ncomp_34c &lt;- compareFit(fit.weak, fit.partial2)\nprint(comp_34c@nested)\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n              Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    \nfit.weak     174         252.28                                  \nfit.partial2 184         291.31     39.063      10  2.475e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat do the results indicate?"
  },
  {
    "objectID": "measurementinvariance_ord.html#partial-strong-invariance-round-3",
    "href": "measurementinvariance_ord.html#partial-strong-invariance-round-3",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.10 Partial Strong Invariance (Round 3)",
    "text": "10.10 Partial Strong Invariance (Round 3)\nSince the model fit indicated some remaining issues with retaining the Partial Strong Invariance model, we will do another round of partial invariance testing (note that I had to lower the minimum.value to still see modifications; you may choose to stop here and argue that remaining modifications wouldn’t improve fit enough to be warranted):\n\nmodificationIndices(fit.partial2, sort. = TRUE, op = \"~1\", \n                    minimum.value = 10)\n\nWarning: lavaan-&gt;modificationIndices():  \n   the modindices() function ignores equality constraints; use lavTestScore() \n   to assess the impact of releasing one or multiple constraints.\n\n\n    lhs op rhs block group level     mi    epc sepc.lv sepc.all sepc.nox\n174 q14 ~1         2     2     1 14.616 -0.192  -0.192   -0.222   -0.222\n69  q14 ~1         1     1     1 14.616  0.192   0.192    0.192    0.192\n67  q11 ~1         1     1     1 12.147 -0.181  -0.181   -0.181   -0.181\n172 q11 ~1         2     2     1 12.147  0.181   0.181    0.203    0.203\n61  q15 ~1         1     1     1 10.118 -0.171  -0.171   -0.171   -0.171\n166 q15 ~1         2     2     1 10.118  0.171   0.171    0.188    0.188\n\n\n\nModel Comparison\nThe intercept of item 14 is now most problematic. To test if releasing this constraint improves the fit of the Partial Strong Model sufficiently, we need to estimate a third partial model. To do so, we can use the group.partial argument in the measEq.syntax() function and add this second intercept:\n\nfit.partial3 &lt;- measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\",\n                            group.equal = c(\"thresholds\", \n                                            \"loadings\", \n                                            \"intercepts\"),\n                            group.partial = c(\"q2 ~ 1\", \"q18 ~ 1\", \"q14 ~ 1\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial3@call$model))\n\nLet’s compare the fit of this model to the Weak Invariance model\n\ncomp_34d &lt;- compareFit(fit.weak, fit.partial3)\nprint(comp_34d@nested)\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n              Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)   \nfit.weak     174         252.28                                 \nfit.partial3 183         276.66     24.761       9   0.003247 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat do the results indicate?"
  },
  {
    "objectID": "measurementinvariance_ord.html#partial-strong-invariance-round-4",
    "href": "measurementinvariance_ord.html#partial-strong-invariance-round-4",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.11 Partial Strong Invariance (Round 4)",
    "text": "10.11 Partial Strong Invariance (Round 4)\nSince the model fit indicated some remaining issues with retaining the third Partial Strong Invariance model, we will do another round of partial invariance testing:\n\nmodificationIndices(fit.partial3, sort. = TRUE, op = \"~1\", \n                    minimum.value = 5)\n\nWarning: lavaan-&gt;modificationIndices():  \n   the modindices() function ignores equality constraints; use lavTestScore() \n   to assess the impact of releasing one or multiple constraints.\n\n\n    lhs op rhs block group level     mi    epc sepc.lv sepc.all sepc.nox\n166 q15 ~1         2     2     1 10.116  0.171   0.171    0.188    0.188\n61  q15 ~1         1     1     1 10.116 -0.171  -0.171   -0.171   -0.171\n67  q11 ~1         1     1     1  8.401 -0.152  -0.152   -0.152   -0.152\n172 q11 ~1         2     2     1  8.401  0.152   0.152    0.172    0.172\n\n\n\nModel Comparison\nThe intercept of item 15 is now most problematic. To test if releasing this constraint improves the fit of the Partial Strong Model sufficiently, we need to estimate a second partial model. To do so, we can use the group.partial argument in the measEq.syntax() function and add this fourth intercept:\n\nfit.partial4 &lt;-measEq.syntax(configural.model = cfa_config, data = DASS21, \n                            group = \"engnat\", ordered = T,\n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, \n                            return.fit = TRUE,\n                            estimator = \"wlsmv\",\n                            group.equal = c(\"thresholds\", \n                                            \"loadings\", \n                                            \"intercepts\"),\n                            group.partial = c(\"q2 ~ 1\", \"q18 ~ 1\", \n                                              \"q14 ~ 1\", \"q15 ~ 1\"))\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial4@call$model))\n\nLet’s compare the fit of this model to the Weak Invariance model\n\ncomp_34e &lt;- compareFit(fit.weak, fit.partial4)\nprint(comp_34e@nested)\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n              Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)  \nfit.weak     174         252.28                                \nfit.partial4 182         266.52     14.256       8    0.07534 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat do the results indicate?\n\n\nLocal Fit Evaluation\nAgain, we will focus on the difference in residuals of the mean vectors.\n\nresiduals(fit.weak, type = \"cor.bollen\")$ELL$mean - residuals(fit.partial4, type = \"cor.bollen\")$ELL$mean\n\n    q2     q4     q7     q9    q15    q19    q20     q1     q6     q8    q11 \n 0.002  0.070  0.052 -0.004  0.004 -0.025 -0.054  0.017 -0.047 -0.058  0.124 \n   q12    q14    q18 \n-0.025  0.000  0.000 \n\n\nThis time, we don’t see any problems with the mean vector in terms of local fit.\n\n\nCFI and RMSEA Comparison\nNext, we will examine if the CFI and RMSEA change to a lesser extent then our criteria (decrease in CFI ≤ 0.010, increase in RMSEA ≤ 0.015):\n\n# Change in CFI\ncat(paste0(\"Change in CFI: \", round(comp_34e@fit.diff$cfi.scaled, 3)))\n\nChange in CFI: 0\n\n# Change in RMSEA\ncat(paste0(\"Change in RMSEA: \", round(comp_34e@fit.diff$rmsea.scaled, 3)))\n\nChange in RMSEA: -0.002\n\n\nThese are much smaller than our cutoff criteria. They are also smaller than other suggested criteria (e.g., decrease in CFI ≤ 0.002 or increase in RMSEA ≤ 0.010). Based on this information, I will retain this partial strong invariant model with four freely estimated intercepts."
  },
  {
    "objectID": "measurementinvariance_ord.html#what-do-differences-in-intercepts-mean",
    "href": "measurementinvariance_ord.html#what-do-differences-in-intercepts-mean",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.12 What do differences in intercepts mean?",
    "text": "10.12 What do differences in intercepts mean?\nIt can be difficult to understand what differences in the intercept mean, especially when the thresholds are equivalent across groups. The figure below aims to help improve understanding of this situation, using item 18 as an example.\n\n# Get item 18 intercept value for ELL group\nell_int2 &lt;- parameterEstimates(fit.partial4) %&gt;% \n  filter(op == \"~1\" & lhs == \"q18\" & group == 2) %&gt;% \n  select(est) %&gt;% as.numeric()\n\n# Get item 18 thresholds (invariant across groups)\nell_thresh2 &lt;- parameterEstimates(fit.partial4) %&gt;% \n  filter(op == \"|\" & lhs == \"q18\" & group == 2) %&gt;% \n  select(est) %&gt;% unlist()\n\n# Set up the latent response variable normal distribution \n# for each group\ntribble(\n  ~ dist, ~args,~group,~int,\n  \"norm\", list(0, 1),\"1. English\",0,\n  \"norm\", list(ell_int2,1),\"2. ELL\",ell_int2\n) %&gt;% ggplot() +\n  # Change the fill color of the distribution at each threshold \n  # value by cutting up the distribution\n  ggdist::stat_slab(aes(xdist = dist, args = args, \n                        fill = after_stat(cut(x, c(-Inf, ell_thresh2, Inf)))), \n                    show.legend = FALSE) + \n  # Colors of the different sections of the latent response variable\n  scale_fill_manual(values = c(\"#494B69\",\"#9F5B72\", \n                               \"#D8707C\",\"#FD9B41\")) +\n  # Add vertical lines at each threshold value\n  geom_vline(xintercept = ell_thresh2[1]) +\n  geom_vline(xintercept = ell_thresh2[2]) +\n  geom_vline(xintercept = ell_thresh2[3]) +\n  # Add a dashed vertical line at the latent response variable \n  # intercept value\n  geom_vline(aes(xintercept = int), linetype = \"dashed\") +\n  # Plot both groups separately\n  facet_grid(rows = vars(group)) +\n  # Add axis labels\n  labs(x = \"Underlying Latent Response Variable\", y = \"Density\") +\n  # Change plot theme/some formatting\n  theme_classic() +\n  theme(text = element_text(size = 20),\n        axis.title = element_text(face = \"bold\"),\n        plot.title = element_text(face = \"bold\", hjust = .5))\n\n\n\n\nThis figure shows that, when the underlying latent factor, Stress, is equal to zero (which in this case indicates the average Stress level, because we used unit-variance factor scaling), English native speakers are most likely to select the second response option (Sometimes), whereas ELL speakers are most likely to select the third response option (Often), in response to item 18 (I felt that I was rather touchy). Thus, at average levels of stress, ELL speakers report often feeling rather touchy whereas English native speakers rerport sometimes feeling rather touchy."
  },
  {
    "objectID": "measurementinvariance_ord.html#parameter-comparison-across-groups",
    "href": "measurementinvariance_ord.html#parameter-comparison-across-groups",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.13 Parameter Comparison Across Groups",
    "text": "10.13 Parameter Comparison Across Groups\nNow that we have finalized the invariance testing procedure (note that you could test higher levels of invariance, but that these offer few practical benefits), we can continue to compare latent factor variances, covariances, and means across groups.\n\nFactor Variances\nFirst, we will test if the factor variances of the Anxiety and Stress factors are equivalent across groups. We will do so by adding lv.variances to the group.equal argument of the previous partial strong invariance model.\n\nfit.partial4.lv &lt;- measEq.syntax(cfa_config, data = DASS21, \n                            ID.fac = \"std.lv\", \n                            ID.cat = \"Wu.Estabrook.2016\",\n                            group = \"engnat\", \n                            group.equal = c(\"thresholds\", \"loadings\", \n                                            \"intercepts\", \"lv.variances\"),\n                            group.partial = c(\"q2 ~ 1\", \"q18 ~ 1\", \n                                              \"q14 ~ 1\", \"q15 ~ 1\"),\n                            ordered = T,\n                            parameterization = \"delta\",\n                            meanstructure = TRUE, return.fit = TRUE,\n                            estimator = \"wlsmv\")\n\n# Print out the model syntax, so you can\n# see what semTools is helping us do:\n# cat(as.character(fit.partial4.lv@call$model))\n\nWe can now compare the fit of this model to the previous partial strong invariance model:\n\ncomp_4e5 &lt;- compareFit(fit.partial4, fit.partial4.lv)\ncomp_4e5@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.2000\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n                 Df AIC BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)  \nfit.partial4    182         266.52                                \nfit.partial4.lv 184         292.03     6.9603       2     0.0308 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat does the Chi-square Difference test tell us?\nBased on these results, we will continue with a model with freely estimated factor variances (and covariances). This still allows us to compare the means across groups. We just need to use a slightly more complicated formula to compute Cohen’s d.\n\n\nFactor Means\nWe can use the effect size formula from the book chapter to do so (which can be interpreted as a Cohen’s d). For each of the latent factors, we need the latent mean estimates and an estimate of the factor variances. We will find these estimates using the group_by_groups function from the semhelpinghands package and filtering the results:\n\ngroup_by_groups(fit.partial4) %&gt;% \n  filter((op == \"~1\" & (lhs == \"stress\" | lhs == \"anxiety\")) | \n           op == \"~~\" & (lhs == \"stress\" | lhs == \"anxiety\"))\n\n      lhs op     rhs est_EnglishNative est_ELL\n1 anxiety ~~ anxiety             1.000   0.795\n2 anxiety ~~  stress             0.902   0.722\n3  stress ~~  stress             1.000   0.778\n4 anxiety ~1                     0.000  -0.159\n5  stress ~1                     0.000  -0.332\n\n\nHere are the computations of the effect size for the mean difference in Anxiety:\n\n# mean in English Native Speaker: 0 (reference group)\n# mean in ELL Speaker: -0.159\n# variance: 1 (reference group), 0.795 (ELL)\n\n(0 - (-.159)) / sqrt((499*1 + 499*.795)/(499 + 499))\n\n[1] 0.167834\n\n\nThis indicates that the mean of the Anxiety factor of the English Native Speaker sample is about 0.16 standard deviations higher than that of the ELL Speaker sample.\nHere are the computations of the effect size for the mean difference in Stress:\n\n# mean in English Native Speaker: 0 (reference group)\n# mean in ELL Speaker: -0.332\n# variance: 1 (reference group), 0.778 (ELL)\n\n(0 - (-.332)) / sqrt((499*1 + 499*.778)/(499 + 499))\n\n[1] 0.3521172\n\n\nThis indicates that the mean of the Stress factor of the English Native Speaker sample is about 0.35 standard deviations higher than that of the ELL Speaker sample.\nWe can also test whether the mean differences are significant using a Wald test. This test is based on the difference in model chi-square that occurs when two parameters (in this case the latent factor means) are constrained to be equivalent.\n\n# H0: Average anxiety is equivalent across \n# English Native and ELL speakers\nlavTestWald(fit.partial4, constraints = \"alpha.1.g1 == alpha.1.g2\")\n\n$stat\n[1] 5.286136\n\n$df\n[1] 1\n\n$p.value\n[1] 0.02149586\n\n$se\n[1] \"robust.sem\"\n\n# H0: Average stress is equivalent across \n# English Native and ELL speakers\nlavTestWald(fit.partial4, constraints = \"alpha.2.g1 == alpha.2.g2\")\n\n$stat\n[1] 25.04656\n\n$df\n[1] 1\n\n$p.value\n[1] 5.596256e-07\n\n$se\n[1] \"robust.sem\"\n\n\nBased on the results above, both tests were significant (p &lt; .05), so the mean differences are significant between groups."
  },
  {
    "objectID": "measurementinvariance_ord.html#conclusion",
    "href": "measurementinvariance_ord.html#conclusion",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.14 Conclusion",
    "text": "10.14 Conclusion\nIn this example, we found evidence of configural, threshold, and weak invariance of the Anxiety and Stress factors from the DASS-21 over English native and ELL speaker samples. There is somewhat less convincing evidence of strong invariance, in that the majority, but not all, latent response variable intercepts may be equivalent across groups. This means that the English native and ELL speaker samples did not have the same relative standing (i.e., expected response) on four items, given the same position on the underlying conceptual variable (i.e., Anxiety/Stress).\nIn a paper, you would report all of the above, adding all unstandardized estimates + SEs of the final retained model (in a table)."
  },
  {
    "objectID": "measurementinvariance_ord.html#summary",
    "href": "measurementinvariance_ord.html#summary",
    "title": "10  Measurement Invariance Testing with Ordinal Indicators",
    "section": "10.15 Summary",
    "text": "10.15 Summary\nIn this R lab, you were introduced to the steps involved in testing measurement invariance with ordinal indicators. In the next R Lab, you will learn all about a very different kind of model, a latent profile analysis, which is used to detect unobserved subgroups that share a similar response pattern to a set of continuous items."
  },
  {
    "objectID": "lca.html#loading-r-packages",
    "href": "lca.html#loading-r-packages",
    "title": "12  Latent Class Analysis",
    "section": "12.1 Loading R Packages",
    "text": "12.1 Loading R Packages\nLoad the required packages for this lab into your R environment.\n\nlibrary(tidySEM)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "lca.html#loading-data",
    "href": "lca.html#loading-data",
    "title": "12  Latent Class Analysis",
    "section": "12.2 Loading Data",
    "text": "12.2 Loading Data\nLoad the data into your environment. For this lab we will use a dataset based on N = 972 children whose caregivers completed a survey about their socio-emotional development. You can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/preschool.csv. Make sure to save it in the folder you are using for this class.\nThe full dataset and more information about this project can be found here: https://ldbase.org/datasets/38d4a723-c167-4908-a250-2cf29a4ff49b.\n\nplbs &lt;- read.csv(\"data/preschool.csv\")\n\nplbs &lt;- plbs %&gt;% mutate(across(everything(), ~if_else(.x == 1.5, 1, .x)),\n                across(everything(), ~ factor(.x, \n                                              labels = c(\"Does not Apply\", \n                                                         \"Sometimes Applies\", \n                                                         \"Most Often Applies\"),\n                                              ordered = T\n                                              )\n                       )\n                )\n\ncolnames(plbs) &lt;- c(\"dontcare\", \"cooperates\", \"distracted\", \"willinghelp\", \"silly\", \"acceptnew\")\n\nWe will focus on six items of the Preschool Learning Behaviors Scale (PLBS). Here are the items:\n\nAdopts a don’t care attitude to success and failure.\nCooperates in group activities.\nIs distracted too easily by what is going on in the room, or seeks distractions.\nIs willing to be helped.\nInvents silly ways of doing things\nAccepts new activities without fear or resistance\n\nCaregivers could respond with one of three options: Does Not Apply, Sometimes Applies, Most Often Applies.\nThe tidySEM package has a function descriptives() that we can use to get some basic descriptive statistics for our items:\n\ndesc &lt;- descriptives(plbs)\ndesc &lt;- desc[, c(\"name\", \"n\", \"missing\", \"unique\", \"mode\", \"mode_value\")]\ndesc\n\n         name   n missing unique mode         mode_value\n1    dontcare 972       0      4  639     Does not Apply\n2  cooperates 972       0      4  610 Most Often Applies\n3  distracted 972       0      4  411  Sometimes Applies\n4 willinghelp 972       0      4  624 Most Often Applies\n5       silly 972       0      4  443     Does not Apply\n6   acceptnew 972       0      4  492 Most Often Applies\n\n\nWe can also use ggplot() to visualize the distribution of item responses:\n\nplbs_plot &lt;- plbs\nplbs_plot &lt;- pivot_longer(plbs_plot, everything())\n\nggplot(plbs_plot, aes(x = value)) + \n  geom_histogram(stat=\"count\") + \n  facet_wrap(~name) +\n  theme_bw()"
  },
  {
    "objectID": "lca.html#estimate-range-of-latent-class-solutions",
    "href": "lca.html#estimate-range-of-latent-class-solutions",
    "title": "12  Latent Class Analysis",
    "section": "12.3 Estimate range of latent class solutions",
    "text": "12.3 Estimate range of latent class solutions\nWe typically come into an LCA with some theory-based expectations for how many classes might exist in the population. In addition, our overall sample size might put some restrictions on how many classes can feasibly be estimated.\n\nset.seed(9710)\nres &lt;- mx_lca(data = plbs, classes = 1:6)\nsaveRDS(res, file = \"data/LCA_results.RDS\")\n\nInstead of running the code below, you can download the results by right-clicking here and saving it into the data folder.\n\nres &lt;- readRDS(\"data/LCA_results.RDS\")"
  },
  {
    "objectID": "lca.html#class-solution-comparison",
    "href": "lca.html#class-solution-comparison",
    "title": "12  Latent Class Analysis",
    "section": "12.4 Class Solution Comparison",
    "text": "12.4 Class Solution Comparison\n\nfit &lt;- table_fit(res)  # model fit table\nfit[, c(\"Name\", \"LL\", \"Parameters\", \"n\",\"AIC\", \"BIC\", \"saBIC\", \"Entropy\", \"prob_min\",\n    \"prob_max\", \"n_min\", \"n_max\", \"np_ratio\", \"np_local\")]\n\n  Name        LL Parameters   n       AIC      BIC     saBIC   Entropy\n1    1 -5197.036         12 972 10418.072 10476.62 10438.512 1.0000000\n2    2 -4946.100         25 972  9942.199 10064.18  9984.783 0.6514148\n3    3 -4906.229         38 972  9888.457 10073.87  9953.185 0.6825587\n4    4 -4873.592         51 972  9849.184 10098.03  9936.056 0.6264103\n5    5 -4856.184         64 972  9840.367 10152.65  9949.382 0.6686257\n6    6 -4847.063         77 972  9848.126 10223.84  9979.284 0.7046337\n   prob_min  prob_max      n_min     n_max np_ratio  np_local\n1 1.0000000 1.0000000 1.00000000 1.0000000 81.00000 81.000000\n2 0.8918582 0.9022232 0.49588477 0.5041152 38.88000 40.166667\n3 0.6625695 0.9015618 0.08436214 0.5000000 25.57895  6.833333\n4 0.6602120 0.8180830 0.04629630 0.3456790 19.05882  3.750000\n5 0.7194970 0.8397305 0.04320988 0.3364198 15.18750  3.500000\n6 0.5899152 0.8377095 0.02366255 0.3353909 12.62338  1.916667\n\n\nWhat class solution is preferred according to the BIC?\nWe might want to explore additional class solutions, but we can see that, starting with four classes, there are &lt; 5 observations per parameter in every class, which is quite low, especially given the total sample size. Estimating additional classes may cause the model to not be identified within classes. We can visualize the drop in BIC across class solutions using the plot() function:\n\nplot(fit)\n\n\n\n\nThe output above also gives us information about the entropy of the model. This value provides a summary of class separation. It actually represents \\(1-entropyy\\) but most people who use it for mixture models report it as simply entropy. If entropy is 0, there is no separations between classes, their response distributions overlap fully. If entropy is 1, all classes are fully separated, their response distributions are completely separated. So, higher values are preferred.\n\nLo-Mendell-Rubin Likelihood Ratio Test\nWe can also use the Lo-Mendell-Rubin Likelihood Ratio Test (LMR-LRT) to make pairwise comparisons across model solutions to test the Null hypothesis that two class solutions have equivalent fit (so a p-value &lt; .05 indicates that one model fits better than the other).\n\nlr_lmr(res)\n\nLo-Mendell-Rubin adjusted Likelihood Ratio Test:\n\n null  alt   lr df        p    w2     p_w2\n mix1 mix2 10.5 13 2.22e-16 0.588 2.22e-16\n mix2 mix3   NA NA       NA    NA       NA\n mix3 mix4   NA NA       NA    NA       NA\n mix4 mix5   NA NA       NA    NA       NA\n mix5 mix6   NA NA       NA    NA       NA\n\n\n\n\nBootstrapped Likelihood Ratio Test\nAn alternative to the LMR-LRT is the bootstrapped likelihood ratio test. This approach is very computationally expensive (i.e., slow), so we only ask for 10 bootstrapped samples here. For a publication you should use a much higher number (1000+). You can use packages such as the future package to use multiple CPUs and speed things up with parallel computing.\n\nset.seed(1)\nres_blrt &lt;- BLRT(res, replications = 5)"
  },
  {
    "objectID": "lca.html#interpreting-final-model-results",
    "href": "lca.html#interpreting-final-model-results",
    "title": "12  Latent Class Analysis",
    "section": "12.5 Interpreting Final Model Results",
    "text": "12.5 Interpreting Final Model Results\nBefore interpreting final estimates, we reorder the latent classes so that they are arranged from largest to smallest:\n\nres_final &lt;- mx_switch_labels(res[[2]])\n\n\nClassification Diagnostics\nWe can look at several indicators of classification accuracy and reliability. First, we can look at how many individuals are classified into each class based on their highest posterior probability:\n\nclass_prob(res_final, type = \"sum.mostlikely\") # assumes no classification error\n\n$sum.mostlikely\n   class count proportion\n1 class1   490  0.5041152\n2 class2   482  0.4958848\n\n\nThe estimates above assume that each participant is classified into the correct class (does not incorporate any uncertainty). We can also ask for estimates that do account for that uncertainty. If there is no classification error (i.e., every person is classified into 1 class with 100% certainty), the above table would be identical to the below table (which does account for error):\n\nclass_prob(res_final, type = \"sum.posterior\") # includes classification error\n\n$sum.posterior\n   class    count proportion\n1 class1 497.3807  0.5117086\n2 class2 474.6193  0.4882914\n\n#class_prob(res_final, type = \"individual\") # classification probabilities for each individual\n\nAre there any major differences between the two classification tables? What does that say about the severity of classification errors?\nNext, we can use a cross-table to understand the certainty of our classifications better. Again, we can either ignore classification error, using the functions below:\n\nclass_prob(res_final, type = \"mostlikely.class\") # values on diagonal should be &gt; .7\n\n$mostlikely.class\n          assigned.1 assigned.2\navgprob.1 0.89185824  0.1081418\navgprob.2 0.09777682  0.9022232\n\n\nOr we can include classification error, using the function below:\n\nclass_prob(res_final, type = \"avg.mostlikely\") # values on diagonal should be &gt; .7\n\n$avg.mostlikely\n           meanprob.class1 meanprob.class2\nassigned.1       0.9052924      0.09470764\nassigned.2       0.1115926      0.88840737\n\n\nFor both tables, values on the diagonal represent classification certainty and should be close to 1.\nFor which of these classes is classification certainty lowest?\n\n\nParameter Estimates\nNow that we’ve evaluated the classification diagnostics, we can interpret the parameter estimates, using the table_results() function. With ordinal indicators in LCA, the most relevant estimates are the thresholds. Finding differences in thresholds across classes indicates that persons in different classes switch from one response to the next at a different point along the latent response scale. The code below allows us to focus on those Thresholds:\n\ntable_results(res_final, columns = c(\"label\", \"est\", \"confint\",\n    \"class\")) %&gt;% filter(stringr::str_detect(label, \"Thresholds\")) %&gt;% \n  mutate(label = stringr::str_split_i(label, \"\\\\.\", 2)) %&gt;%\n  pivot_wider(id_cols = label, names_from = class, values_from = est:confint, names_vary = \"slowest\")\n\n# A tibble: 12 × 5\n   label           est_class1 confint_class1 est_class2 confint_class2\n   &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;         \n 1 Thresholds[1,1] 1.04       [0.85, 1.24]   -0.12      [-0.26, 0.02] \n 2 Thresholds[1,2] -2.86      [-3.91, -1.80] -1.35      [-1.52, -1.18]\n 3 Thresholds[1,3] 0.05       [-0.10, 0.20]  -1.24      [-1.45, -1.03]\n 4 Thresholds[1,4] -2.26      [-2.60, -1.91] -1.70      [-1.91, -1.49]\n 5 Thresholds[1,5] 0.00       [-0.12, 0.13]  -0.23      [-0.36, -0.11]\n 6 Thresholds[1,6] -1.69      [-1.90, -1.47] -1.09      [-1.25, -0.94]\n 7 Thresholds[2,1] 2.10       [1.69, 2.52]   1.07       [0.92, 1.23]  \n 8 Thresholds[2,2] -1.62      [-2.02, -1.21] 0.55       [0.34, 0.75]  \n 9 Thresholds[2,3] 1.58       [1.26, 1.91]   0.07       [-0.07, 0.21] \n10 Thresholds[2,4] -0.90      [-1.06, -0.74] 0.10       [-0.04, 0.24] \n11 Thresholds[2,5] 1.56       [1.34, 1.78]   0.96       [0.81, 1.11]  \n12 Thresholds[2,6] -0.59      [-0.74, -0.43] 0.58       [0.42, 0.74]  \n\n\nTo make it easier to see if response patterns vary across classes, we can use the table_prob() function, which transforms the thresholds into response probabilities. These do not come with a confidence interval, so ideally you first examine the thresholds to note relevant differences across classes and then look at these probabilities to see what they really mean:\n\ntable_prob(res_final) %&gt;% \n  pivot_wider(names_from = group, \n              values_from = Probability)\n\n# A tibble: 18 × 4\n   Variable    Category  class1 class2\n   &lt;chr&gt;          &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 dontcare           1 0.852   0.454 \n 2 dontcare           2 0.131   0.405 \n 3 dontcare           3 0.0178  0.141 \n 4 cooperates         1 0.00213 0.0884\n 5 cooperates         2 0.0507  0.619 \n 6 cooperates         3 0.947   0.293 \n 7 distracted         1 0.519   0.107 \n 8 distracted         2 0.424   0.422 \n 9 distracted         3 0.0569  0.471 \n10 willinghelp        1 0.0120  0.0443\n11 willinghelp        2 0.173   0.496 \n12 willinghelp        3 0.815   0.460 \n13 silly              1 0.502   0.408 \n14 silly              2 0.439   0.423 \n15 silly              3 0.0597  0.169 \n16 acceptnew          1 0.0457  0.138 \n17 acceptnew          2 0.233   0.581 \n18 acceptnew          3 0.721   0.281 \n\n\nThe threshold results above indicate that all thresholds are significantly different across classes (this aligns with the very high entropy for this class solution). Focusing on the response probabilities, it appears that caregivers in class 1 are more likely to endorse positive learning behaviors (cooperates, wiling to accept help, accept new), whereas caregivers in class 2 are more likely to endorse negative learning behaviors (don’t care, distracted). The two classes’ responses are similar for the silly item.\n\n\nVisualize the classes\nTables can provide a lot of detail, but it can be challenging to unnderstand the bigger picture. That’s why we like to visualize response patterns of the latent classes. The plot_prob() function includes all classes in one plot, using subplots. The theme() element was added to make the item labels more readable.\n\nplot_prob(res_final) +\n  theme(axis.text.x = element_text(angle=45, vjust = 0.5))\n\n\n\n\nWhat label would you give each of these classes?"
  },
  {
    "objectID": "lca.html#predicting-membership-for-new-individuals",
    "href": "lca.html#predicting-membership-for-new-individuals",
    "title": "12  Latent Class Analysis",
    "section": "12.6 Predicting membership for new individuals",
    "text": "12.6 Predicting membership for new individuals\nFinally, you can use the LCA results to predict most likely class membership of new cases, as long as you have their scores on the indicator items. Below, I define a new participant (using an existing case from the original sample so the variables are ordered factors) who has a somewhat inconsistent class (e.g., the distracted item Sometimes Applies):\n\nplbs_new &lt;- plbs[10,]\nplbs_new\n\n         dontcare         cooperates        distracted        willinghelp\n10 Does not Apply Most Often Applies Sometimes Applies Most Often Applies\n            silly         acceptnew\n10 Does not Apply Sometimes Applies\n\npredict(res_final, newdata = plbs_new)\n\nRunning mix2 with 0 parameters\n\n\n        class1    class2 predicted\n[1,] 0.8485255 0.1514745         1"
  },
  {
    "objectID": "lca.html#summary",
    "href": "lca.html#summary",
    "title": "12  Latent Class Analysis",
    "section": "12.7 Summary",
    "text": "12.7 Summary\nIn this R lab, you were introduced to the steps involved in specifying, estimating, evaluating, comparing and interpreting the results of latent class analyses. For now, this is the final lab for this class!"
  },
  {
    "objectID": "lpa.html#loading-r-packages",
    "href": "lpa.html#loading-r-packages",
    "title": "11  Latent Profile Analysis",
    "section": "11.1 Loading R Packages",
    "text": "11.1 Loading R Packages\nLoad the required packages for this lab into your R environment.\n\nlibrary(tidySEM)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "lpa.html#loading-data",
    "href": "lpa.html#loading-data",
    "title": "11  Latent Profile Analysis",
    "section": "11.2 Loading Data",
    "text": "11.2 Loading Data\nLoad the data into your environment. For this lab we will use a dataset based on N = 441 children whose caregivers completed a survey about family environment and child behavior. You can download the data by right-clicking this link and selecting “Save Link As…” in the drop-down menu: data/projectkids.csv. Make sure to save it in the folder you are using for this class.\nThe full dataset and more information about this project can be found here: https://www.ldbase.org/datasets/72ab9852-8ebc-4ba0-bb1f-5f1c347e2572.\n\nkids &lt;- read.csv(\"data/projectkids.csv\")\n\n# data frame with auxiliary outcome included\nkids_aux &lt;- kids %&gt;% select(chaos1:chaos6, hpc_mean) %&gt;%\n  drop_na()\n\n# data frame with just PLA indicators\nkids_chaos &lt;- kids_aux %&gt;% select(chaos1:chaos6) %&gt;%\n  mutate(chaos1 = 6 - chaos1,\n         chaos4 = 6 - chaos4,\n         chaos6 = 6 - chaos6)\n\ncolnames(kids_chaos) &lt;- c(\"bedtimeroutine\", \"hearthink\", \"zoo\", \"stayontop\", \"tvon\", \"calm\")\ncolnames(kids_aux) &lt;- c(\"bedtimeroutine\", \"hearthink\", \"zoo\", \"stayontop\", \"tvon\", \"calm\", \"hpc_mean\")\n\nWe will focus on the six items of the Confusion, Hubbub, and Order Scale (CHAOS). I had originally re-coded 3 items for our use of these in CFA and SEM models, but we will un-recode them here so we can interpret them according to the original item content:\n\nMy child has a regular bedtime routine (e.g. same bedtime each night, brushing teeth, reading a story)\nYou can’t hear yourself think in our home\nIt’s a real zoo in our home\nWe are usually able to stay on top of things\nThere is usually a television turned on somewhere in our home\nThe atmosphere in our house is calm\n\nThe tidySEM package has a function descriptives() that we can use to get some basic descriptive statistics for our items:\n\ndesc &lt;- descriptives(kids_chaos)\ndesc &lt;- desc[, c(\"name\", \"n\", \"missing\", \"unique\", \"mean\", \"median\",\n    \"sd\", \"min\", \"max\")]\ndesc\n\n            name   n missing unique     mean median        sd min max\n1 bedtimeroutine 429       0      5 4.170163      4 1.0305816   1   5\n2      hearthink 429       0      5 1.939394      1 1.2365390   1   5\n3            zoo 429       0      5 1.731935      1 1.1024320   1   5\n4      stayontop 429       0      5 4.081585      4 0.9717319   1   5\n5           tvon 429       0      5 3.706294      4 1.2237840   1   5\n6           calm 429       0      5 3.902098      4 1.0275278   1   5\n\n\nWe can also use ggplot() to visualize the distribution of item responses:\n\nchaos_plot &lt;- kids_chaos\nnames(chaos_plot) &lt;- paste0(\"Value.\", names(chaos_plot))\nchaos_plot &lt;- reshape(chaos_plot, \n                      varying = names(chaos_plot), \n                      direction = \"long\", \n                      timevar = \"Variable\")\n\nggplot(chaos_plot, aes(x = Value)) + \n  geom_histogram() + \n  facet_wrap(~Variable) +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWhy is it not a problem for LPA that the item responses are not normally distributed?"
  },
  {
    "objectID": "lpa.html#estimate-range-of-latent-profile-solutions",
    "href": "lpa.html#estimate-range-of-latent-profile-solutions",
    "title": "11  Latent Profile Analysis",
    "section": "11.3 Estimate range of latent profile solutions",
    "text": "11.3 Estimate range of latent profile solutions\nWe typically come into an LPA with some theory-based expectations for how many profiles might exist in the population. In addition, our overall sample size might put some restrictions on how many classes can feasibly be estimated.\n\nset.seed(9710)\nres &lt;- mx_profiles(data = kids_chaos, classes = 1:4)\nsaveRDS(res, file = \"data/LPA_results.RDS\")\n\nInstead of running the code below, you can download the results by right-clicking here and saving it into the data folder.\n\nres &lt;- readRDS(\"data/LPA_results.RDS\")"
  },
  {
    "objectID": "lpa.html#profile-solution-comparison",
    "href": "lpa.html#profile-solution-comparison",
    "title": "11  Latent Profile Analysis",
    "section": "11.4 Profile Solution Comparison",
    "text": "11.4 Profile Solution Comparison\n\nfit &lt;- table_fit(res)  # model fit table\nfit[, c(\"Name\", \"LL\", \"Parameters\", \"n\", \"BIC\", \"Entropy\", \"prob_min\",\n    \"prob_max\", \"n_min\", \"n_max\", \"np_ratio\", \"np_local\")]\n\n         Name        LL Parameters   n      BIC   Entropy  prob_min  prob_max\n1 equal var 1 -3881.170         12 429 7835.077 1.0000000 1.0000000 1.0000000\n2 equal var 2 -3661.732         19 429 7438.632 0.9218451 0.9569456 0.9868002\n3 equal var 3 -3621.222         26 429 7400.042 0.8642157 0.8670854 0.9686615\n4 equal var 4 -3561.982         33 429 7323.992 0.8823549 0.8545100 0.9644465\n       n_min     n_max np_ratio np_local\n1 1.00000000 1.0000000 35.75000 35.75000\n2 0.26806527 0.7319347 22.57895 12.77778\n3 0.18648019 0.5664336 16.50000 10.00000\n4 0.07692308 0.5361305 13.00000  4.40000\n\n\nWhat profile solution is preferred according to the BIC?\nWe might want to explore additional profile solutions, but we can see that, with four profiles, there are only about 4.4 observations per parameter in every profile, which is already quite low. Estimating additional profiles may cause the model to not be identified within profiles. We can visualize the drop in BIC across profile solutions using the plot() function:\n\nplot(fit)\n\n\n\n\nThe output above also gives us information about the entropy of the model. This value provides a summary of profile separation. It actually represents \\(1-entropyy\\) but most people who use it for mixture models report it as simply entropy. If entropy is 0, there is no separations between profiles, their response distributions overlap fully. If entropy is 1, all profiles are fully separated, their response distributions are completely separated. So, higher values are preferred.\n\nLo-Mendell-Rubin Likelihood Ratio Test\nWe can also use the Lo-Mendell-Rubin Likelihood Ratio Test (LMR-LRT) to make pairwise comparisons across model solutions to test the Null hypothesis that two profile solutions have equivalent fit (so a p-value &lt; .05 indicates that one model fits better than the other).\n\nlr_lmr(res)\n\nLo-Mendell-Rubin adjusted Likelihood Ratio Test:\n\n null  alt   lr df        p    w2     p_w2\n mix1 mix2 8.27  7 2.22e-16 1.641 9.63e-09\n mix2 mix3 3.20  7 6.92e-04 0.374 3.98e-04\n mix3 mix4 4.05  7 2.54e-05 0.498 2.39e-02\n\n\n\n\nBootstrapped Likelihood Ratio Test\nAn alternative to the LMR-LRT is the bootstrapped likelihood ratio test. This approach is very computationally expensive (i.e., slow), so we only ask for 10 bootstrapped samples here. For a publication you should use a much higher number (1000+). You can use packages such as the future package to use multiple CPUs and speed things up with parallel computing.\n\nset.seed(1)\nres_blrt &lt;- BLRT(res, replications = 5)"
  },
  {
    "objectID": "lpa.html#alternative-model-specification",
    "href": "lpa.html#alternative-model-specification",
    "title": "11  Latent Profile Analysis",
    "section": "11.5 Alternative Model Specification",
    "text": "11.5 Alternative Model Specification\nWe assumed that the indicators would have equivalent variances across profiles and that there would not be any covariances among indicators within a profile. However, a reviewer might doubt those assumptions and ask to compare the selected profile-solution to a model with the same number of profiles, but allowing the variances to vary across profiles. Note that allowing varying variances (or covariances within profiles) result in more complex models (i.e., we need to estimate more parameters), which may be challenging to estimate with smaller samples.\n\nres_alt &lt;- mx_profiles(kids_chaos, classes = 4, variances = \"varying\")\n\nRunning mix4 with 51 parameters\nRunning mix4 with 51 parameters\n\n\nWarning: In model 'mix4' Optimizer returned a non-zero status code 6. The model\ndoes not satisfy the first-order optimality conditions to the required\naccuracy, and no improved point for the merit function could be found during\nthe final linesearch (Mx status RED)\n\n# The example below shows you how to have varying variances + covariances within classes\n#res_alt &lt;- mx_profiles(kids_chaos, classes = 4, variances = \"varying\", covariances = \"varying\")\n\ncompare &lt;- list(res[[4]], res_alt)\ntable_fit(compare)\n\n  Name Classes         LL   n Parameters      AIC      BIC    saBIC   Entropy\n1    1       4 -3561.9821 429         33 7189.964 7323.992 7219.270 0.8823549\n2    2       4  -595.8179 429         51 1293.636 1500.770 1338.927 0.9445174\n   prob_min  prob_max      n_min     n_max warning  np_ratio np_local\n1 0.8545100 0.9644465 0.07692308 0.5361305      NA 13.000000      4.4\n2 0.8295987 1.0000000 0.11188811 0.5034965    TRUE  8.411765      4.0"
  },
  {
    "objectID": "lpa.html#interpreting-final-model-results",
    "href": "lpa.html#interpreting-final-model-results",
    "title": "11  Latent Profile Analysis",
    "section": "11.6 Interpreting Final Model Results",
    "text": "11.6 Interpreting Final Model Results\nBefore interpreting final estimates, we reorder the latent profiles so that they are arranged from largest to smallest:\n\nres_final &lt;- mx_switch_labels(res[[4]])\n\n\nClassification Diagnostics\nWe can look at several indicators of classification accuracy and reliability. First, we can look at how many individuals are classified into each profile based on their highest posterior probability:\n\nclass_prob(res_final, type = \"sum.mostlikely\") # assumes no classification error\n\n$sum.mostlikely\n   class count proportion\n1 class1   230 0.53613054\n2 class2   105 0.24475524\n3 class3    61 0.14219114\n4 class4    33 0.07692308\n\n\nThe estimates above assume that each participant is classified into the correct profile (does not incorporate any uncertainty). We can also ask for estimates that do account for that uncertainty. If there is no classification error (i.e., every person is classified into 1 profile with 100% certainty), the above table would be identical to the below table (which does account for error):\n\nclass_prob(res_final, type = \"sum.posterior\") # includes classification error\n\n$sum.posterior\n   class     count proportion\n1 class1 224.62794 0.52360825\n2 class2 105.39364 0.24567283\n3 class3  64.42088 0.15016523\n4 class4  34.55753 0.08055369\n\n#class_prob(res_final, type = \"individual\") # classification probabilities for each individual\n\nAre there any major differences between the two classification tables? What does that say about the severity of classification errors?\nNext, we can use a cross-table to understand the certainty of our classifications better. Again, we can either ignore classification error, using the functions below:\n\nclass_prob(res_final, type = \"mostlikely.class\") # values on diagonal should be &gt; .7\n\n$mostlikely.class\n          assigned.1 assigned.2  assigned.3   assigned.4\navgprob.1 0.96444654 0.01305278 0.021596558 0.0009041203\navgprob.2 0.04098968 0.94543631 0.009017845 0.0045561610\navgprob.3 0.11814948 0.02026233 0.854509954 0.0070782420\navgprob.4 0.04109700 0.03245069 0.004305713 0.9221465912\n\n\nOr we can include classification error, using the function below:\n\nclass_prob(res_final, type = \"avg.mostlikely\") # values on diagonal should be &gt; .7\n\n$avg.mostlikely\n           meanprob.class1 meanprob.class2 meanprob.class3 meanprob.class4\nassigned.1     0.941950580      0.01878253      0.03309330     0.006173593\nassigned.2     0.027924892      0.94896524      0.01243186     0.010678011\nassigned.3     0.079530277      0.01558046      0.90245049     0.002438771\nassigned.4     0.006154462      0.01455099      0.01381808     0.965476476\n\n\nFor both tables, values on the diagonal represent classification certainty and should be close to 1.\nFor which of these classes is classification certainty lowest?\n\n\nParameter Estimates\nNow that we’ve evaluated the classification diagnostics, we can interpret the parameter estimates, using the table_results() function:\n\ntable_results(res_final, columns = c(\"label\", \"est\", \"se\", \"confint\",\n    \"class\")) %&gt;% pivot_wider(id_cols = label, names_from = class, values_from = est:confint, names_vary = \"slowest\")\n\n# A tibble: 16 × 16\n   label est_class1 se_class1 confint_class1 est_class2 se_class2 confint_class2\n   &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;         \n 1 Mean… 4.27       0.07      [4.13, 4.41]   3.99       0.11      [3.78, 4.19]  \n 2 Mean… 1.25       0.05      [1.15, 1.35]   3.71       0.08      [3.55, 3.87]  \n 3 Mean… 1.18       0.06      [1.07, 1.30]   3.02       0.09      [2.84, 3.20]  \n 4 Mean… 4.40       0.05      [4.32, 4.49]   4.00       0.07      [3.85, 4.14]  \n 5 Mean… 4.14       0.07      [4.00, 4.28]   4.18       0.09      [3.99, 4.36]  \n 6 Mean… 4.17       0.07      [4.04, 4.30]   3.25       0.10      [3.06, 3.44]  \n 7 Vari… 1.04       0.07      [0.90, 1.18]   &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n 8 Vari… 0.48       0.05      [0.38, 0.59]   &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n 9 Vari… 0.64       0.05      [0.54, 0.74]   &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n10 Vari… 0.43       0.04      [0.36, 0.50]   &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n11 Vari… 0.72       0.06      [0.60, 0.85]   &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n12 Vari… 0.88       0.06      [0.76, 1.00]   &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n13 mix4… &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;           &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n14 mix4… &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;           &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n15 mix4… &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;           &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n16 mix4… &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;           &lt;NA&gt;       &lt;NA&gt;      &lt;NA&gt;          \n# ℹ 9 more variables: est_class3 &lt;chr&gt;, se_class3 &lt;chr&gt;, confint_class3 &lt;chr&gt;,\n#   est_class4 &lt;chr&gt;, se_class4 &lt;chr&gt;, confint_class4 &lt;chr&gt;, est_NA &lt;chr&gt;,\n#   se_NA &lt;chr&gt;, confint_NA &lt;chr&gt;\n\n\nThe output above includes mean estimates for the 6 CHAOS items for each of the four profiles. In addition, this model estimated one set of variance estimates for the 6 CHAOS items that apply to all four profiles. Finally, there is a set of relative weights which repesent the profile sizes relative to the largest class (i.e., class 4 is 15% of the size of class 1).\nTo make it easier to see if estimates vary across profiles, we can reorganize this table and focus on the confidence intervals (i.e., if intervals do not overlap then that estimate differs across those profiles):\n\ntable_results(res_final, columns = c(\"label\", \"confint\", \"class\")) %&gt;% \n  filter(stringr::str_detect(label, \"Means\")) %&gt;%\n  pivot_wider(id_cols = label, \n              names_from = class, \n              values_from = confint)\n\n# A tibble: 6 × 5\n  label                class1       class2       class3       class4      \n  &lt;chr&gt;                &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;       \n1 Means.bedtimeroutine [4.13, 4.41] [3.78, 4.19] [4.01, 4.54] [3.52, 4.29]\n2 Means.hearthink      [1.15, 1.35] [3.55, 3.87] [1.38, 1.80] [1.35, 2.00]\n3 Means.zoo            [1.07, 1.30] [2.84, 3.20] [1.49, 1.94] [1.11, 1.70]\n4 Means.stayontop      [4.32, 4.49] [3.85, 4.14] [4.18, 4.53] [1.47, 1.98]\n5 Means.tvon           [4.00, 4.28] [3.99, 4.36] [1.44, 1.99] [2.87, 3.48]\n6 Means.calm           [4.04, 4.30] [3.06, 3.44] [3.99, 4.49] [3.19, 3.85]\n\n\n\nWe can see that the 95% CIs for the bedtime routine item all overlap, so this item is not really differentiating between profiles.\nIn contrast, the 95% CI the can’t hear myself think item do not overlap when comparing profile 1 to profiles 2, 3, and 4. In addition, profile 2 and 4 also do not have overlapping CIs. People assigned to profile 1 (and to a lesser extent profile 4) do not endorse this item to the same extend as those classified in the other profiles.\nFor the zoo item, the 95% CI of profile 1 does not overlap with profile 2 and 3. And profile 2 does not overlap with profiles 3 and 4. Overall, it seems the people assigned to profile 2 endorse this item more than those classified in other profiles.\nFor the stay on top of things item, it appears that those classified in profile 4 do not endorse this item to the same extent as the other profiles. Profile 3 endorses it more than profile 2 but the CI overlaps with that of profile 1.\nThe TV is always on item is least endorsed by those in profile 3, followed by profile 4, and finally profiles 1 and 2. Thus, this part of “chaos” is not characteristic of profiles 3 and 4.\nFinally, the calm atmosphere item is least endorsed by profiles 2 and 4, and most endorsed by profiles 1 and 3.\n\nBased on these results it appears that all parents, regardless of profile, have a good bedtime routine down. But responses to other items seem to differentiate between different profiles quite well.\n\n\nVisualize the Profiles\nTables can provide a lot of detail, but it can be challenging to unnderstand the bigger picture. That’s why we like to visualize response patterns of the latent profiles. The plot_profile() function includes all profiles in one plot, which can be difficult to decipher. For that reason, I save the original plot into object p and then use the facet_wrap() function from the ggplot2 package to split the plot into separate subplots for each class:\n\np &lt;- plot_profiles(res_final) \n\n\n\np + facet_wrap(~Class)\n\nWarning: Using shapes for an ordinal variable is not advised\n\n\n\n\n\nWhat label would you give each of these profiles?"
  },
  {
    "objectID": "lpa.html#auxiliary-analyses",
    "href": "lpa.html#auxiliary-analyses",
    "title": "11  Latent Profile Analysis",
    "section": "11.7 Auxiliary Analyses",
    "text": "11.7 Auxiliary Analyses\nWe can extend the LPA with auxiliary variables or analyses. For example, we can see if kids of parents in different profiles report different amounts of homework problems using the hpc_mean variable. We use the Bolck, Croon, and Hagenaars (BCH) approach, which separates the LPA model from the auxiliary analysis and incorporates classification uncertainty (conceptually similar to SAM).\n\naux_hpc &lt;- BCH(res_final, data = kids_aux$hpc_mean)\n\nRunning aux with 8 parameters\n\nsummary(aux_hpc)\n\nSummary of aux \n \nfree parameters:\n           name   matrix row col  Estimate  Std.Error A\n1 class1.S[1,1] class1.S   y   y 0.3227898 0.03045759  \n2 class1.M[1,1] class1.M   1   y 1.6409456 0.03790711  \n3 class2.S[1,1] class2.S   y   y 0.5796778 0.07985333  \n4 class2.M[1,1] class2.M   1   y 1.8342364 0.07416326  \n5 class3.S[1,1] class3.S   y   y 0.2788413 0.04913082  \n6 class3.M[1,1] class3.M   1   y 1.5031372 0.06579004  \n7 class4.S[1,1] class4.S   y   y 0.3768246 0.09066187  \n8 class4.M[1,1] class4.M   1   y 1.7839324 0.10443393  \n\nModel Statistics: \n               |  Parameters  |  Degrees of Freedom  |  Fit (-2lnL units)\n       Model:              8                    419              789.9786\n   Saturated:             NA                     NA                    NA\nIndependence:             NA                     NA                    NA\nNumber of observations/statistics: 1716/427\n\nInformation Criteria: \n      |  df Penalty  |  Parameters Penalty  |  Sample-Size Adjusted\nAIC:      -48.02136               805.9786                 806.0630\nBIC:    -2330.62915               849.5606                 824.1455\nCFI: NA \nTLI: 1   (also known as NNFI) \nRMSEA:  0  [95% CI (NA, NA)]\nProb(RMSEA &lt;= 0.05): NA\nTo get additional fit indices, see help(mxRefModels)\ntimestamp: 2025-02-04 10:27:16 \nWall clock time: 0.397243 secs \noptimizer:  SLSQP \nOpenMx version number: 2.21.13 \nNeed help?  See help(mxSummary) \n\n\nWe can test the equivalence of the homework problem means across profiles using the lr_test() function. It compares a model in which all means are fixed to be equal to a model where the means are freely estimated for an overall test, followed by pairwise comparisons in which two specific profile’s are compared.\n\nlr_test(aux_hpc, compare = \"M\")\n\nRunning aux with 5 parameters\n\n\nRunning aux with 7 parameters\nRunning aux with 7 parameters\nRunning aux with 7 parameters\nRunning aux with 7 parameters\nRunning aux with 7 parameters\nRunning aux with 7 parameters\n\n\nBCH test for equality of means across classes\n\nOverall likelihood ratio test:\n LL_baseline LL_restricted   LL_dif df           p\n    789.9786      802.4116 12.43296  3 0.006038032\n\nPairwise comparisons using likelihood ratio tests:\n Model1 Model2 LL_baseline LL_restricted     LL_dif df           p\n class1 class2    789.9786      795.2763  5.2976155  1 0.021354638\n class1 class3    789.9786      793.2242  3.2455609  1 0.071617175\n class2 class3    789.9786      800.7757 10.7970384  1 0.001016626\n class1 class4    789.9786      791.6045  1.6258622  1 0.202276317\n class2 class4    789.9786      790.1327  0.1540711  1 0.694674830\n class3 class4    789.9786      794.9453  4.9666828  1 0.025840160\n\n\nThe global test suggests that there are differences between the profiles. Based on the pairwise comparison results, it appears that kids of parents in profile 3 have fewer homework problems than kids of parents in profile 2 and 4. And kids of parents in profile 1 have fewer homework problems than kids of parents in profile 2. Differences between other pairs of profiles are not significant.\nYou can test more complex auxiliary models as well, such as a linear regression model with homework problems as the outcome and sex or age of the child (or both!) as predictors."
  },
  {
    "objectID": "lpa.html#predicting-membership-for-new-individuals",
    "href": "lpa.html#predicting-membership-for-new-individuals",
    "title": "11  Latent Profile Analysis",
    "section": "11.8 Predicting membership for new individuals",
    "text": "11.8 Predicting membership for new individuals\nFinally, you can use the LPA results to predict most likely class membership of new cases, as long as you have their scores on the indicator items. Below, I define a new participant with a somewhat inconsistent response pattern to see where they would end up:\n\nkids_chaos_new &lt;- data.frame(bedtimeroutine = 1, \n                             hearthink = 4, \n                             zoo = 3, \n                             stayontop = 4, \n                             tvon = 1, \n                             calm = 1)\n\npredict(res_final, newdata = kids_chaos_new)\n\nRunning mix4 with 0 parameters\n\n\n          class1    class2      class3       class4 predicted\n[1,] 1.70066e-06 0.9945138 0.005473939 1.052268e-05         2"
  },
  {
    "objectID": "lpa.html#summary",
    "href": "lpa.html#summary",
    "title": "11  Latent Profile Analysis",
    "section": "11.9 Summary",
    "text": "11.9 Summary\nIn this R lab, you were introduced to the steps involved in specifying, estimating, evaluating, comparing and interpreting the results of latent profile analyses. In addition, you have seen some ways in which you can expand the basic LPA with an auxiliary model. In the next R Lab, you will learn about latent class analysis (LCA), which is similar to LPA but is based on ordinal indicators."
  },
  {
    "objectID": "latentgrowthmodel.html#bonus-2-including-a-residual-covariance-structure",
    "href": "latentgrowthmodel.html#bonus-2-including-a-residual-covariance-structure",
    "title": "9  Latent Growth Modeling",
    "section": "9.9 Bonus 2: Including a Residual Covariance Structure",
    "text": "9.9 Bonus 2: Including a Residual Covariance Structure\nRelated, we can test if the residual covariances should be included in the model to account for any remaining associations between time points with different lags (after accounting for the main growth model). In the model below, covariances are structured such that those that have the same lag (e.g., adjacent time point) covary equivalently (by giving them a shared label). In addition, as the lag increases, we use a non-linear constraint to force the covariances to decrease (as more time passes, scores have less to do with each other).\n\nlgm_basis_eqc &lt;- '\ni =~ 1*psp1 + 1*psp2 + 1*psp3 + 1*psp4 + 1*psp5\ns =~ 0*psp1 + psp2 + psp3 + psp4 + 1*psp5\n\npsp1 ~~ a*psp1\npsp2 ~~ a*psp2\npsp3 ~~ a*psp3\npsp4 ~~ a*psp4\npsp5 ~~ a*psp5\n\n# lag-1 residual covariances\npsp1 ~~ b*psp2\npsp2 ~~ b*psp3\npsp3 ~~ b*psp4\npsp4 ~~ b*psp5\n\n# lag-2 residual covariances\npsp1 ~~ c*psp3\npsp2 ~~ c*psp4\npsp3 ~~ c*psp5\n\n# lag-3 residual covariances\npsp1 ~~ d*psp4\npsp2 ~~ d*psp5\n\n# lag-4 residual covariances\npsp1 ~~ e*psp5\n\n# constraints to apply the reducing residual covariance over time assumption\nc == b^2\nd == b^3\ne == b^4\n'\n\nfit_basis_eqc &lt;- growth(lgm_basis_eqc, data = diary, \n                     estimator = \"mlr\", missing = \"fiml\")\n\ncomp_eqc &lt;- compareFit(fit_basis_eq, fit_basis_eqc)\ncomp_eqc@nested\n\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan-&gt;unknown():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n              Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)  \nfit_basis_eqc 10 3518.7 3553.5 14.226                                \nfit_basis_eq  11 3526.5 3557.8 24.029     5.7598       1     0.0164 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuestion: Does the Chi-square difference test support the hypothesis of including a residual covariance structure?\n(Remember, the model with residual covariance structure is more complex than the model with just the residual variance structure, so we’re testing if making the model more complex is worth it or not.)\n\nsummary(fit_basis_eqc, std = T)\n\nlavaan 0.6-19 ended normally after 290 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n  Number of observations                           240\n  Number of missing patterns                        15\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                14.226       9.520\n  Degrees of freedom                                10          10\n  P-value (Chi-square)                           0.163       0.484\n  Scaling correction factor                                  1.494\n    Yuan-Bentler correction (Mplus variant)                       \n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  i =~                                                                  \n    psp1              1.000                               1.352    0.806\n    psp2              1.000                               1.352    0.730\n    psp3              1.000                               1.352    0.704\n    psp4              1.000                               1.352    0.699\n    psp5              1.000                               1.352    0.689\n  s =~                                                                  \n    psp1              0.000                               0.000    0.000\n    psp2              0.768    0.075   10.276    0.000    0.781    0.422\n    psp3              0.916    0.063   14.573    0.000    0.932    0.486\n    psp4              0.946    0.058   16.423    0.000    0.963    0.498\n    psp5              1.000                               1.018    0.519\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .psp1 ~~                                                               \n   .psp2       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp2 ~~                                                               \n   .psp3       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp3 ~~                                                               \n   .psp4       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp4 ~~                                                               \n   .psp5       (b)    0.201    0.110    1.819    0.069    0.201    0.203\n .psp1 ~~                                                               \n   .psp3       (c)    0.040    0.044    0.910    0.363    0.040    0.041\n .psp2 ~~                                                               \n   .psp4       (c)    0.040    0.044    0.910    0.363    0.040    0.041\n .psp3 ~~                                                               \n   .psp5       (c)    0.040    0.044    0.910    0.363    0.040    0.041\n .psp1 ~~                                                               \n   .psp4       (d)    0.008    0.013    0.606    0.544    0.008    0.008\n .psp2 ~~                                                               \n   .psp5       (d)    0.008    0.013    0.606    0.544    0.008    0.008\n .psp1 ~~                                                               \n   .psp5       (e)    0.002    0.004    0.455    0.649    0.002    0.002\n  i ~~                                                                  \n    s                -0.001    0.186   -0.004    0.997   -0.001   -0.001\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    i                 4.480    0.108   41.335    0.000    3.313    3.313\n    s                -1.014    0.110   -9.237    0.000   -0.996   -0.996\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .psp1       (a)    0.989    0.154    6.427    0.000    0.989    0.351\n   .psp2       (a)    0.989    0.154    6.427    0.000    0.989    0.289\n   .psp3       (a)    0.989    0.154    6.427    0.000    0.989    0.268\n   .psp4       (a)    0.989    0.154    6.427    0.000    0.989    0.264\n   .psp5       (a)    0.989    0.154    6.427    0.000    0.989    0.257\n    i                 1.828    0.242    7.553    0.000    1.000    1.000\n    s                 1.036    0.336    3.081    0.002    1.000    1.000\n\nConstraints:\n                                               |Slack|\n    c - (b^2)                                    0.000\n    d - (b^3)                                    0.000\n    e - (b^4)                                    0.000"
  }
]